{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erha500/IMLO-Open-Assessment/blob/main/IMLO_Open_Assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "MGJhK0Wy6U2-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as T\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1FLWsWbK-ylG"
      },
      "outputs": [],
      "source": [
        "train_transform_augment = v2.Compose([\n",
        "    v2.Resize([224,224]),\n",
        "    #v2.RandomPerspective(),\n",
        "    v2.RandomHorizontalFlip(0.5),\n",
        "    v2.RandomRotation(45),\n",
        "    #v2.RandomVerticalFlip(0.5)\n",
        "    #v2.RandomAutocontrast(),\n",
        "    #v2.GaussianBlur(kernel_size=3),\n",
        "    v2.ToTensor(),\n",
        "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_transform = v2.Compose([\n",
        "  v2.Resize([224,224]),\n",
        "  v2.ToTensor(),\n",
        "  v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "test_transform = v2.Compose([\n",
        "  v2.Resize([224,224]),\n",
        "  v2.ToTensor(),\n",
        "  v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWVmTrcs9QGM"
      },
      "source": [
        "Downloading Flowers102 dataset from datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "2AG1ERmI9WXU"
      },
      "outputs": [],
      "source": [
        "training_data_augment = datasets.Flowers102(root=\"dataset\", split=\"train\", transform=train_transform_augment, download=True)\n",
        "\n",
        "training_data = datasets.Flowers102(root=\"dataset\", split=\"train\", transform=train_transform, download=True)\n",
        "\n",
        "val_data = datasets.Flowers102(root=\"dataset\", split=\"val\", transform=test_transform, download=True)\n",
        "\n",
        "test_data = datasets.Flowers102(root=\"dataset\", split=\"test\", transform=test_transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "EiOOyavq-T-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ec95a9-6f06-458f-fdea-23847853a717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 3, 224, 224])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "#Create data loaders\n",
        "train_dataloader = DataLoader(training_data_augment, batch_size = batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "  print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "3fL6F9TLEdDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41aac79-f715-431f-877a-20b2bd82aca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): ReLU()\n",
            "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU()\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): ReLU()\n",
            "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (16): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (18): ReLU()\n",
            "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU()\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Flatten(start_dim=1, end_dim=-1)\n",
            "    (25): Linear(in_features=4608, out_features=1024, bias=True)\n",
            "    (26): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): ReLU()\n",
            "    (28): Dropout(p=0.15, inplace=False)\n",
            "    (29): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (30): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (31): ReLU()\n",
            "    (32): Dropout(p=0.15, inplace=False)\n",
            "    (33): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (34): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (35): ReLU()\n",
            "    (36): Dropout(p=0.15, inplace=False)\n",
            "    (37): Linear(in_features=256, out_features=102, bias=True)\n",
            "    (38): BatchNorm1d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU()\n",
            "    (40): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "#Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "      #Convolutional layers\n",
        "      nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "      nn.Conv2d(64,64, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "      nn.Conv2d(128,128, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(256),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "      nn.Conv2d(256,512, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(512),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      #Linear layers\n",
        "      nn.Flatten(),\n",
        "\n",
        "      nn.Linear(512 * 3 * 3, 1024),\n",
        "      nn.BatchNorm1d(1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.15),\n",
        "\n",
        "      nn.Linear(1024, 512),\n",
        "      nn.BatchNorm1d(512),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.15),\n",
        "\n",
        "      nn.Linear(512,256),\n",
        "      nn.BatchNorm1d(256),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.15),\n",
        "\n",
        "      nn.Linear(256,102),\n",
        "      nn.BatchNorm1d(102),\n",
        "      nn.ReLU(),\n",
        "\n",
        "      nn.LogSoftmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "9IvJsfvwE0VG"
      },
      "outputs": [],
      "source": [
        "#loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn = nn.NLLLoss()\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.005) #weight decay is L2 regularisation\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=5, factor=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "o4bMoWUAE1kO"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    #Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 5 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "y4Mf49itE3A-"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct) :>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    accuracy = 100 * correct\n",
        "    return accuracy, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Xr7VD7E3E5y1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "064074e8-2989-4d82-e8b6-03ddb2b4c191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            " ---------------------------------------\n",
            "loss: 4.951518 [   64/ 1020]\n",
            "loss: 4.780961 [  384/ 1020]\n",
            "loss: 4.659233 [  704/ 1020]\n",
            "loss: 4.515510 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 1.2%, Avg loss: 4.632182 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 2 \n",
            " ---------------------------------------\n",
            "loss: 4.499570 [   64/ 1020]\n",
            "loss: 4.112515 [  384/ 1020]\n",
            "loss: 4.212124 [  704/ 1020]\n",
            "loss: 4.327080 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 6.8%, Avg loss: 4.406884 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 3 \n",
            " ---------------------------------------\n",
            "loss: 4.107821 [   64/ 1020]\n",
            "loss: 3.682400 [  384/ 1020]\n",
            "loss: 3.774369 [  704/ 1020]\n",
            "loss: 3.870478 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 17.5%, Avg loss: 3.939646 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 4 \n",
            " ---------------------------------------\n",
            "loss: 3.738695 [   64/ 1020]\n",
            "loss: 3.571831 [  384/ 1020]\n",
            "loss: 3.809897 [  704/ 1020]\n",
            "loss: 3.742882 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 20.3%, Avg loss: 3.753361 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 5 \n",
            " ---------------------------------------\n",
            "loss: 3.493487 [   64/ 1020]\n",
            "loss: 3.694891 [  384/ 1020]\n",
            "loss: 3.452160 [  704/ 1020]\n",
            "loss: 3.509358 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.7%, Avg loss: 3.624938 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 6 \n",
            " ---------------------------------------\n",
            "loss: 3.470225 [   64/ 1020]\n",
            "loss: 3.281790 [  384/ 1020]\n",
            "loss: 3.340430 [  704/ 1020]\n",
            "loss: 3.479468 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.2%, Avg loss: 3.542117 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 7 \n",
            " ---------------------------------------\n",
            "loss: 3.046238 [   64/ 1020]\n",
            "loss: 2.885308 [  384/ 1020]\n",
            "loss: 3.125177 [  704/ 1020]\n",
            "loss: 3.274765 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.5%, Avg loss: 3.427127 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 8 \n",
            " ---------------------------------------\n",
            "loss: 3.262964 [   64/ 1020]\n",
            "loss: 3.143563 [  384/ 1020]\n",
            "loss: 2.822088 [  704/ 1020]\n",
            "loss: 2.879881 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.0%, Avg loss: 3.329065 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 9 \n",
            " ---------------------------------------\n",
            "loss: 2.752398 [   64/ 1020]\n",
            "loss: 2.668469 [  384/ 1020]\n",
            "loss: 2.962679 [  704/ 1020]\n",
            "loss: 3.113056 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.6%, Avg loss: 3.256402 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 10 \n",
            " ---------------------------------------\n",
            "loss: 2.872008 [   64/ 1020]\n",
            "loss: 2.789470 [  384/ 1020]\n",
            "loss: 2.444101 [  704/ 1020]\n",
            "loss: 2.787179 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.9%, Avg loss: 3.233357 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 11 \n",
            " ---------------------------------------\n",
            "loss: 2.558580 [   64/ 1020]\n",
            "loss: 2.695818 [  384/ 1020]\n",
            "loss: 2.736347 [  704/ 1020]\n",
            "loss: 2.622791 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.8%, Avg loss: 3.145920 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 12 \n",
            " ---------------------------------------\n",
            "loss: 2.558878 [   64/ 1020]\n",
            "loss: 2.674736 [  384/ 1020]\n",
            "loss: 2.533898 [  704/ 1020]\n",
            "loss: 2.511634 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.9%, Avg loss: 3.080107 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 13 \n",
            " ---------------------------------------\n",
            "loss: 2.544949 [   64/ 1020]\n",
            "loss: 2.519647 [  384/ 1020]\n",
            "loss: 2.615087 [  704/ 1020]\n",
            "loss: 2.597512 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.7%, Avg loss: 3.105972 \n",
            "\n",
            "Epoch 14 \n",
            " ---------------------------------------\n",
            "loss: 2.392297 [   64/ 1020]\n",
            "loss: 2.584714 [  384/ 1020]\n",
            "loss: 2.519339 [  704/ 1020]\n",
            "loss: 2.526832 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.0%, Avg loss: 3.044315 \n",
            "\n",
            "Epoch 15 \n",
            " ---------------------------------------\n",
            "loss: 2.280841 [   64/ 1020]\n",
            "loss: 2.324370 [  384/ 1020]\n",
            "loss: 2.346500 [  704/ 1020]\n",
            "loss: 2.371112 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 39.0%, Avg loss: 2.967406 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 16 \n",
            " ---------------------------------------\n",
            "loss: 2.198152 [   64/ 1020]\n",
            "loss: 2.356274 [  384/ 1020]\n",
            "loss: 2.269650 [  704/ 1020]\n",
            "loss: 2.295151 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 41.3%, Avg loss: 2.889997 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 17 \n",
            " ---------------------------------------\n",
            "loss: 1.956661 [   64/ 1020]\n",
            "loss: 2.259355 [  384/ 1020]\n",
            "loss: 2.368501 [  704/ 1020]\n",
            "loss: 2.218893 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.2%, Avg loss: 2.955691 \n",
            "\n",
            "Epoch 18 \n",
            " ---------------------------------------\n",
            "loss: 2.125893 [   64/ 1020]\n",
            "loss: 2.153989 [  384/ 1020]\n",
            "loss: 1.999177 [  704/ 1020]\n",
            "loss: 2.152223 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 42.7%, Avg loss: 2.867026 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 19 \n",
            " ---------------------------------------\n",
            "loss: 1.922145 [   64/ 1020]\n",
            "loss: 2.183445 [  384/ 1020]\n",
            "loss: 2.113640 [  704/ 1020]\n",
            "loss: 2.106892 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 40.4%, Avg loss: 2.889702 \n",
            "\n",
            "Epoch 20 \n",
            " ---------------------------------------\n",
            "loss: 2.102236 [   64/ 1020]\n",
            "loss: 1.732448 [  384/ 1020]\n",
            "loss: 2.029447 [  704/ 1020]\n",
            "loss: 1.934165 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 42.2%, Avg loss: 2.838552 \n",
            "\n",
            "Epoch 21 \n",
            " ---------------------------------------\n",
            "loss: 1.853052 [   64/ 1020]\n",
            "loss: 1.785795 [  384/ 1020]\n",
            "loss: 2.042227 [  704/ 1020]\n",
            "loss: 1.860095 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 42.9%, Avg loss: 2.812402 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 22 \n",
            " ---------------------------------------\n",
            "loss: 1.760563 [   64/ 1020]\n",
            "loss: 1.807587 [  384/ 1020]\n",
            "loss: 1.837845 [  704/ 1020]\n",
            "loss: 1.842048 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 43.7%, Avg loss: 2.774543 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 23 \n",
            " ---------------------------------------\n",
            "loss: 1.764625 [   64/ 1020]\n",
            "loss: 2.017573 [  384/ 1020]\n",
            "loss: 1.815920 [  704/ 1020]\n",
            "loss: 1.793437 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 43.2%, Avg loss: 2.780601 \n",
            "\n",
            "Epoch 24 \n",
            " ---------------------------------------\n",
            "loss: 1.684867 [   64/ 1020]\n",
            "loss: 1.638339 [  384/ 1020]\n",
            "loss: 1.875054 [  704/ 1020]\n",
            "loss: 1.686252 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 45.9%, Avg loss: 2.725538 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 25 \n",
            " ---------------------------------------\n",
            "loss: 1.682866 [   64/ 1020]\n",
            "loss: 1.652110 [  384/ 1020]\n",
            "loss: 1.693780 [  704/ 1020]\n",
            "loss: 1.861523 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.2%, Avg loss: 2.742214 \n",
            "\n",
            "Epoch 26 \n",
            " ---------------------------------------\n",
            "loss: 1.767858 [   64/ 1020]\n",
            "loss: 1.427838 [  384/ 1020]\n",
            "loss: 1.691138 [  704/ 1020]\n",
            "loss: 1.702065 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.9%, Avg loss: 2.696586 \n",
            "\n",
            "Epoch 27 \n",
            " ---------------------------------------\n",
            "loss: 1.750809 [   64/ 1020]\n",
            "loss: 1.556509 [  384/ 1020]\n",
            "loss: 1.586149 [  704/ 1020]\n",
            "loss: 1.692791 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.4%, Avg loss: 2.714633 \n",
            "\n",
            "Epoch 28 \n",
            " ---------------------------------------\n",
            "loss: 1.535848 [   64/ 1020]\n",
            "loss: 1.444085 [  384/ 1020]\n",
            "loss: 1.758588 [  704/ 1020]\n",
            "loss: 1.607584 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 46.5%, Avg loss: 2.651213 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 29 \n",
            " ---------------------------------------\n",
            "loss: 1.541021 [   64/ 1020]\n",
            "loss: 1.574290 [  384/ 1020]\n",
            "loss: 1.704593 [  704/ 1020]\n",
            "loss: 1.506521 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.3%, Avg loss: 2.679029 \n",
            "\n",
            "Epoch 30 \n",
            " ---------------------------------------\n",
            "loss: 1.540466 [   64/ 1020]\n",
            "loss: 1.449133 [  384/ 1020]\n",
            "loss: 1.539335 [  704/ 1020]\n",
            "loss: 1.445842 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.0%, Avg loss: 2.627983 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 31 \n",
            " ---------------------------------------\n",
            "loss: 1.484092 [   64/ 1020]\n",
            "loss: 1.443687 [  384/ 1020]\n",
            "loss: 1.364884 [  704/ 1020]\n",
            "loss: 1.515844 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 46.6%, Avg loss: 2.642106 \n",
            "\n",
            "Epoch 32 \n",
            " ---------------------------------------\n",
            "loss: 1.452305 [   64/ 1020]\n",
            "loss: 1.304967 [  384/ 1020]\n",
            "loss: 1.383206 [  704/ 1020]\n",
            "loss: 1.536865 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.2%, Avg loss: 2.581919 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 33 \n",
            " ---------------------------------------\n",
            "loss: 1.221059 [   64/ 1020]\n",
            "loss: 1.362933 [  384/ 1020]\n",
            "loss: 1.260385 [  704/ 1020]\n",
            "loss: 1.351779 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 49.1%, Avg loss: 2.540284 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 34 \n",
            " ---------------------------------------\n",
            "loss: 1.268236 [   64/ 1020]\n",
            "loss: 1.309314 [  384/ 1020]\n",
            "loss: 1.338802 [  704/ 1020]\n",
            "loss: 1.297329 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 49.5%, Avg loss: 2.571562 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 35 \n",
            " ---------------------------------------\n",
            "loss: 1.353182 [   64/ 1020]\n",
            "loss: 1.209278 [  384/ 1020]\n",
            "loss: 1.219436 [  704/ 1020]\n",
            "loss: 1.416497 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 50.1%, Avg loss: 2.525847 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 36 \n",
            " ---------------------------------------\n",
            "loss: 1.283877 [   64/ 1020]\n",
            "loss: 1.375097 [  384/ 1020]\n",
            "loss: 1.170654 [  704/ 1020]\n",
            "loss: 1.113409 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 48.4%, Avg loss: 2.538793 \n",
            "\n",
            "Epoch 37 \n",
            " ---------------------------------------\n",
            "loss: 1.150508 [   64/ 1020]\n",
            "loss: 1.263905 [  384/ 1020]\n",
            "loss: 1.380833 [  704/ 1020]\n",
            "loss: 1.209243 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 48.9%, Avg loss: 2.514866 \n",
            "\n",
            "Epoch 38 \n",
            " ---------------------------------------\n",
            "loss: 1.214058 [   64/ 1020]\n",
            "loss: 1.092884 [  384/ 1020]\n",
            "loss: 1.108455 [  704/ 1020]\n",
            "loss: 1.260133 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 48.8%, Avg loss: 2.495642 \n",
            "\n",
            "Epoch 39 \n",
            " ---------------------------------------\n",
            "loss: 1.018489 [   64/ 1020]\n",
            "loss: 0.992826 [  384/ 1020]\n",
            "loss: 1.153038 [  704/ 1020]\n",
            "loss: 1.319438 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 51.6%, Avg loss: 2.475036 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 40 \n",
            " ---------------------------------------\n",
            "loss: 1.155926 [   64/ 1020]\n",
            "loss: 1.032293 [  384/ 1020]\n",
            "loss: 1.276474 [  704/ 1020]\n",
            "loss: 1.197217 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 49.1%, Avg loss: 2.482188 \n",
            "\n",
            "Epoch 41 \n",
            " ---------------------------------------\n",
            "loss: 1.119767 [   64/ 1020]\n",
            "loss: 1.127555 [  384/ 1020]\n",
            "loss: 1.191446 [  704/ 1020]\n",
            "loss: 1.163736 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 50.7%, Avg loss: 2.491279 \n",
            "\n",
            "Epoch 42 \n",
            " ---------------------------------------\n",
            "loss: 1.057329 [   64/ 1020]\n",
            "loss: 0.984611 [  384/ 1020]\n",
            "loss: 1.293952 [  704/ 1020]\n",
            "loss: 1.148716 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 50.3%, Avg loss: 2.450922 \n",
            "\n",
            "Epoch 43 \n",
            " ---------------------------------------\n",
            "loss: 1.045134 [   64/ 1020]\n",
            "loss: 1.071941 [  384/ 1020]\n",
            "loss: 1.048033 [  704/ 1020]\n",
            "loss: 1.232975 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 50.5%, Avg loss: 2.444506 \n",
            "\n",
            "Epoch 44 \n",
            " ---------------------------------------\n",
            "loss: 1.188188 [   64/ 1020]\n",
            "loss: 1.181383 [  384/ 1020]\n",
            "loss: 1.052783 [  704/ 1020]\n",
            "loss: 1.043950 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 50.4%, Avg loss: 2.472576 \n",
            "\n",
            "Epoch 45 \n",
            " ---------------------------------------\n",
            "loss: 0.937861 [   64/ 1020]\n",
            "loss: 1.014740 [  384/ 1020]\n",
            "loss: 0.945252 [  704/ 1020]\n",
            "loss: 0.969836 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.6%, Avg loss: 2.433826 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 46 \n",
            " ---------------------------------------\n",
            "loss: 0.978184 [   64/ 1020]\n",
            "loss: 0.933103 [  384/ 1020]\n",
            "loss: 1.041046 [  704/ 1020]\n",
            "loss: 0.957786 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 49.7%, Avg loss: 2.465073 \n",
            "\n",
            "Epoch 47 \n",
            " ---------------------------------------\n",
            "loss: 1.089037 [   64/ 1020]\n",
            "loss: 0.991904 [  384/ 1020]\n",
            "loss: 0.978466 [  704/ 1020]\n",
            "loss: 1.001248 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.4%, Avg loss: 2.424510 \n",
            "\n",
            "Epoch 48 \n",
            " ---------------------------------------\n",
            "loss: 0.917985 [   64/ 1020]\n",
            "loss: 1.188913 [  384/ 1020]\n",
            "loss: 0.963072 [  704/ 1020]\n",
            "loss: 0.943939 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.4%, Avg loss: 2.411968 \n",
            "\n",
            "Epoch 49 \n",
            " ---------------------------------------\n",
            "loss: 0.923525 [   64/ 1020]\n",
            "loss: 0.983133 [  384/ 1020]\n",
            "loss: 0.911704 [  704/ 1020]\n",
            "loss: 0.933941 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 51.1%, Avg loss: 2.406811 \n",
            "\n",
            "Epoch 50 \n",
            " ---------------------------------------\n",
            "loss: 0.806569 [   64/ 1020]\n",
            "loss: 1.006178 [  384/ 1020]\n",
            "loss: 0.853259 [  704/ 1020]\n",
            "loss: 0.948853 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 51.1%, Avg loss: 2.412912 \n",
            "\n",
            "Epoch 51 \n",
            " ---------------------------------------\n",
            "loss: 1.070883 [   64/ 1020]\n",
            "loss: 0.913890 [  384/ 1020]\n",
            "loss: 0.925499 [  704/ 1020]\n",
            "loss: 0.874621 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.1%, Avg loss: 2.393437 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 52 \n",
            " ---------------------------------------\n",
            "loss: 0.807399 [   64/ 1020]\n",
            "loss: 0.964060 [  384/ 1020]\n",
            "loss: 0.875743 [  704/ 1020]\n",
            "loss: 0.887880 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 51.0%, Avg loss: 2.419487 \n",
            "\n",
            "Epoch 53 \n",
            " ---------------------------------------\n",
            "loss: 0.903948 [   64/ 1020]\n",
            "loss: 0.891765 [  384/ 1020]\n",
            "loss: 0.856088 [  704/ 1020]\n",
            "loss: 0.985706 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.0%, Avg loss: 2.332422 \n",
            "\n",
            "Epoch 54 \n",
            " ---------------------------------------\n",
            "loss: 0.872918 [   64/ 1020]\n",
            "loss: 1.003180 [  384/ 1020]\n",
            "loss: 0.821268 [  704/ 1020]\n",
            "loss: 0.891355 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.8%, Avg loss: 2.350371 \n",
            "\n",
            "Epoch 55 \n",
            " ---------------------------------------\n",
            "loss: 0.717478 [   64/ 1020]\n",
            "loss: 0.927457 [  384/ 1020]\n",
            "loss: 0.909916 [  704/ 1020]\n",
            "loss: 0.899356 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.3%, Avg loss: 2.357177 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 56 \n",
            " ---------------------------------------\n",
            "loss: 0.715479 [   64/ 1020]\n",
            "loss: 0.885346 [  384/ 1020]\n",
            "loss: 0.959456 [  704/ 1020]\n",
            "loss: 0.855871 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 51.7%, Avg loss: 2.354357 \n",
            "\n",
            "Epoch 57 \n",
            " ---------------------------------------\n",
            "loss: 0.799722 [   64/ 1020]\n",
            "loss: 0.921774 [  384/ 1020]\n",
            "loss: 0.902639 [  704/ 1020]\n",
            "loss: 0.922377 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.4%, Avg loss: 2.395618 \n",
            "\n",
            "Epoch 58 \n",
            " ---------------------------------------\n",
            "loss: 0.829131 [   64/ 1020]\n",
            "loss: 0.799331 [  384/ 1020]\n",
            "loss: 0.877962 [  704/ 1020]\n",
            "loss: 0.939739 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.1%, Avg loss: 2.350477 \n",
            "\n",
            "Epoch 59 \n",
            " ---------------------------------------\n",
            "loss: 0.796839 [   64/ 1020]\n",
            "loss: 0.744921 [  384/ 1020]\n",
            "loss: 0.764794 [  704/ 1020]\n",
            "loss: 0.850147 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.1%, Avg loss: 2.363541 \n",
            "\n",
            "Epoch 60 \n",
            " ---------------------------------------\n",
            "loss: 0.789436 [   64/ 1020]\n",
            "loss: 0.804236 [  384/ 1020]\n",
            "loss: 0.804643 [  704/ 1020]\n",
            "loss: 0.954673 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.7%, Avg loss: 2.314516 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 61 \n",
            " ---------------------------------------\n",
            "loss: 0.717669 [   64/ 1020]\n",
            "loss: 0.802543 [  384/ 1020]\n",
            "loss: 0.691237 [  704/ 1020]\n",
            "loss: 0.850437 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.6%, Avg loss: 2.313506 \n",
            "\n",
            "Epoch 62 \n",
            " ---------------------------------------\n",
            "loss: 0.669260 [   64/ 1020]\n",
            "loss: 0.657781 [  384/ 1020]\n",
            "loss: 0.770634 [  704/ 1020]\n",
            "loss: 0.763229 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.7%, Avg loss: 2.295405 \n",
            "\n",
            "Epoch 63 \n",
            " ---------------------------------------\n",
            "loss: 0.645117 [   64/ 1020]\n",
            "loss: 0.804207 [  384/ 1020]\n",
            "loss: 0.795230 [  704/ 1020]\n",
            "loss: 0.799449 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.8%, Avg loss: 2.297786 \n",
            "\n",
            "Epoch 64 \n",
            " ---------------------------------------\n",
            "loss: 0.588963 [   64/ 1020]\n",
            "loss: 0.888733 [  384/ 1020]\n",
            "loss: 0.834909 [  704/ 1020]\n",
            "loss: 0.693424 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.3%, Avg loss: 2.282459 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 65 \n",
            " ---------------------------------------\n",
            "loss: 0.893140 [   64/ 1020]\n",
            "loss: 0.688575 [  384/ 1020]\n",
            "loss: 0.802212 [  704/ 1020]\n",
            "loss: 0.562755 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.7%, Avg loss: 2.279969 \n",
            "\n",
            "Epoch 66 \n",
            " ---------------------------------------\n",
            "loss: 0.741379 [   64/ 1020]\n",
            "loss: 0.686549 [  384/ 1020]\n",
            "loss: 0.686970 [  704/ 1020]\n",
            "loss: 0.725804 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.3%, Avg loss: 2.264354 \n",
            "\n",
            "Epoch 67 \n",
            " ---------------------------------------\n",
            "loss: 0.643310 [   64/ 1020]\n",
            "loss: 0.821127 [  384/ 1020]\n",
            "loss: 0.833084 [  704/ 1020]\n",
            "loss: 0.692937 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.1%, Avg loss: 2.277204 \n",
            "\n",
            "Epoch 68 \n",
            " ---------------------------------------\n",
            "loss: 0.666210 [   64/ 1020]\n",
            "loss: 0.770569 [  384/ 1020]\n",
            "loss: 0.624197 [  704/ 1020]\n",
            "loss: 0.668377 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.2%, Avg loss: 2.266056 \n",
            "\n",
            "Epoch 69 \n",
            " ---------------------------------------\n",
            "loss: 0.619274 [   64/ 1020]\n",
            "loss: 0.797395 [  384/ 1020]\n",
            "loss: 0.670719 [  704/ 1020]\n",
            "loss: 0.801732 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.6%, Avg loss: 2.271577 \n",
            "\n",
            "Epoch 70 \n",
            " ---------------------------------------\n",
            "loss: 0.621358 [   64/ 1020]\n",
            "loss: 0.608930 [  384/ 1020]\n",
            "loss: 0.677221 [  704/ 1020]\n",
            "loss: 0.667070 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.7%, Avg loss: 2.279250 \n",
            "\n",
            "Epoch 71 \n",
            " ---------------------------------------\n",
            "loss: 0.701555 [   64/ 1020]\n",
            "loss: 0.772580 [  384/ 1020]\n",
            "loss: 0.881609 [  704/ 1020]\n",
            "loss: 0.691820 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.6%, Avg loss: 2.258817 \n",
            "\n",
            "Epoch 72 \n",
            " ---------------------------------------\n",
            "loss: 0.717333 [   64/ 1020]\n",
            "loss: 0.651318 [  384/ 1020]\n",
            "loss: 0.661050 [  704/ 1020]\n",
            "loss: 0.603400 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.7%, Avg loss: 2.268043 \n",
            "\n",
            "Epoch 73 \n",
            " ---------------------------------------\n",
            "loss: 0.711752 [   64/ 1020]\n",
            "loss: 0.663763 [  384/ 1020]\n",
            "loss: 0.583559 [  704/ 1020]\n",
            "loss: 0.646762 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.8%, Avg loss: 2.272409 \n",
            "\n",
            "Epoch 74 \n",
            " ---------------------------------------\n",
            "loss: 0.655716 [   64/ 1020]\n",
            "loss: 0.587891 [  384/ 1020]\n",
            "loss: 0.660816 [  704/ 1020]\n",
            "loss: 0.650271 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.0%, Avg loss: 2.268305 \n",
            "\n",
            "Epoch 75 \n",
            " ---------------------------------------\n",
            "loss: 0.732680 [   64/ 1020]\n",
            "loss: 0.648617 [  384/ 1020]\n",
            "loss: 0.586121 [  704/ 1020]\n",
            "loss: 0.661748 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.7%, Avg loss: 2.256604 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 76 \n",
            " ---------------------------------------\n",
            "loss: 0.748179 [   64/ 1020]\n",
            "loss: 0.728758 [  384/ 1020]\n",
            "loss: 0.694527 [  704/ 1020]\n",
            "loss: 0.695883 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.8%, Avg loss: 2.259861 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 77 \n",
            " ---------------------------------------\n",
            "loss: 0.684419 [   64/ 1020]\n",
            "loss: 0.778287 [  384/ 1020]\n",
            "loss: 0.663858 [  704/ 1020]\n",
            "loss: 0.680548 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.0%, Avg loss: 2.258460 \n",
            "\n",
            "Epoch 78 \n",
            " ---------------------------------------\n",
            "loss: 0.531839 [   64/ 1020]\n",
            "loss: 0.682121 [  384/ 1020]\n",
            "loss: 0.766048 [  704/ 1020]\n",
            "loss: 0.810214 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.3%, Avg loss: 2.265380 \n",
            "\n",
            "Epoch 79 \n",
            " ---------------------------------------\n",
            "loss: 0.627976 [   64/ 1020]\n",
            "loss: 0.553671 [  384/ 1020]\n",
            "loss: 0.710394 [  704/ 1020]\n",
            "loss: 0.723798 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.8%, Avg loss: 2.256153 \n",
            "\n",
            "Epoch 80 \n",
            " ---------------------------------------\n",
            "loss: 0.498959 [   64/ 1020]\n",
            "loss: 0.632950 [  384/ 1020]\n",
            "loss: 0.673585 [  704/ 1020]\n",
            "loss: 0.666865 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.8%, Avg loss: 2.255556 \n",
            "\n",
            "Epoch 81 \n",
            " ---------------------------------------\n",
            "loss: 0.715986 [   64/ 1020]\n",
            "loss: 0.756044 [  384/ 1020]\n",
            "loss: 0.646748 [  704/ 1020]\n",
            "loss: 0.644571 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.9%, Avg loss: 2.249512 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 82 \n",
            " ---------------------------------------\n",
            "loss: 0.788524 [   64/ 1020]\n",
            "loss: 0.701449 [  384/ 1020]\n",
            "loss: 0.572988 [  704/ 1020]\n",
            "loss: 0.715830 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.6%, Avg loss: 2.266390 \n",
            "\n",
            "Epoch 83 \n",
            " ---------------------------------------\n",
            "loss: 0.608219 [   64/ 1020]\n",
            "loss: 0.632755 [  384/ 1020]\n",
            "loss: 0.581129 [  704/ 1020]\n",
            "loss: 0.680600 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.0%, Avg loss: 2.266381 \n",
            "\n",
            "Epoch 84 \n",
            " ---------------------------------------\n",
            "loss: 0.614381 [   64/ 1020]\n",
            "loss: 0.607764 [  384/ 1020]\n",
            "loss: 0.554391 [  704/ 1020]\n",
            "loss: 0.631705 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.8%, Avg loss: 2.269118 \n",
            "\n",
            "Epoch 85 \n",
            " ---------------------------------------\n",
            "loss: 0.545793 [   64/ 1020]\n",
            "loss: 0.556131 [  384/ 1020]\n",
            "loss: 0.654121 [  704/ 1020]\n",
            "loss: 0.610378 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.7%, Avg loss: 2.227525 \n",
            "\n",
            "Epoch 86 \n",
            " ---------------------------------------\n",
            "loss: 0.534266 [   64/ 1020]\n",
            "loss: 0.536202 [  384/ 1020]\n",
            "loss: 0.626900 [  704/ 1020]\n",
            "loss: 0.583769 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.6%, Avg loss: 2.239286 \n",
            "\n",
            "Epoch 87 \n",
            " ---------------------------------------\n",
            "loss: 0.625046 [   64/ 1020]\n",
            "loss: 0.508174 [  384/ 1020]\n",
            "loss: 0.567178 [  704/ 1020]\n",
            "loss: 0.720249 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.3%, Avg loss: 2.244069 \n",
            "\n",
            "Epoch 88 \n",
            " ---------------------------------------\n",
            "loss: 0.544243 [   64/ 1020]\n",
            "loss: 0.637405 [  384/ 1020]\n",
            "loss: 0.526787 [  704/ 1020]\n",
            "loss: 0.578977 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.1%, Avg loss: 2.239742 \n",
            "\n",
            "Epoch 89 \n",
            " ---------------------------------------\n",
            "loss: 0.479930 [   64/ 1020]\n",
            "loss: 0.529195 [  384/ 1020]\n",
            "loss: 0.598346 [  704/ 1020]\n",
            "loss: 0.613891 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.5%, Avg loss: 2.252755 \n",
            "\n",
            "Epoch 90 \n",
            " ---------------------------------------\n",
            "loss: 0.533261 [   64/ 1020]\n",
            "loss: 0.514614 [  384/ 1020]\n",
            "loss: 0.616213 [  704/ 1020]\n",
            "loss: 0.587070 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.2%, Avg loss: 2.236258 \n",
            "\n",
            "Epoch 91 \n",
            " ---------------------------------------\n",
            "loss: 0.742466 [   64/ 1020]\n",
            "loss: 0.517915 [  384/ 1020]\n",
            "loss: 0.655922 [  704/ 1020]\n",
            "loss: 0.674927 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.5%, Avg loss: 2.226646 \n",
            "\n",
            "Epoch 92 \n",
            " ---------------------------------------\n",
            "loss: 0.479611 [   64/ 1020]\n",
            "loss: 0.665591 [  384/ 1020]\n",
            "loss: 0.608267 [  704/ 1020]\n",
            "loss: 0.491270 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.7%, Avg loss: 2.223864 \n",
            "\n",
            "Stopping early\n",
            "Testing -----------------------\n",
            "Test Error: \n",
            " Accuracy: 51.2%, Avg loss: 2.424788 \n",
            "\n",
            "Done!!!!\n"
          ]
        }
      ],
      "source": [
        "epochs = 250\n",
        "\n",
        "best_accuracy = 0\n",
        "patience = 10\n",
        "triggers = 0\n",
        "\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1} \\n ---------------------------------------\")\n",
        "\n",
        "  \"\"\"#train on original data\n",
        "  train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\"\"\"\n",
        "\n",
        "  #train on augmented data\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "\n",
        "  #testing on evaluation data\n",
        "  accuracy, test_loss = test(val_dataloader, model, loss_fn)\n",
        "\n",
        "  scheduler.step(test_loss)\n",
        "\n",
        "  if accuracy > best_accuracy:\n",
        "    best_accuracy = accuracy\n",
        "    triggers = 0\n",
        "    torch.save(model.state_dict(), \"model.pt\")\n",
        "    print(\"Saved model at current state\")\n",
        "  else:\n",
        "    triggers += 1\n",
        "\n",
        "  if triggers > patience:\n",
        "    print(\"Stopping early\")\n",
        "    break\n",
        "\n",
        "print(\"Testing -----------------------\")\n",
        "model.load_state_dict(torch.load(\"model.pt\"))\n",
        "model.eval()\n",
        "test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!!!!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNYzk7APHkKQgd6bjOPP71Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}