{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erha500/IMLO-Open-Assessment/blob/main/IMLO_Open_Assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "MGJhK0Wy6U2-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as T\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "1FLWsWbK-ylG"
      },
      "outputs": [],
      "source": [
        "train_transform_augment = v2.Compose([\n",
        "    v2.RandomResizedCrop([224,224], scale=[0.75,1.0], ratio=[1.0,1.0]),\n",
        "    v2.RandomPerspective(),\n",
        "    v2.RandomHorizontalFlip(0.5),\n",
        "    v2.RandomRotation(90),\n",
        "    #v2.RandomVerticalFlip(0.5)\n",
        "    v2.ToTensor(),\n",
        "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_transform = v2.Compose([\n",
        "  v2.Resize([224,224]),\n",
        "  v2.ToTensor(),\n",
        "  v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "test_transform = v2.Compose([\n",
        "  v2.Resize([224,224]),\n",
        "  v2.ToTensor(),\n",
        "  v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWVmTrcs9QGM"
      },
      "source": [
        "Downloading Flowers102 dataset from datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "2AG1ERmI9WXU"
      },
      "outputs": [],
      "source": [
        "#training_data_augment = datasets.Flowers102(root=\"dataset\", split=\"train\", transform=train_transform_augment, download=True)\n",
        "\n",
        "training_data = datasets.Flowers102(root=\"dataset\", split=\"train\", transform=train_transform, download=True)\n",
        "\n",
        "val_data = datasets.Flowers102(root=\"dataset\", split=\"val\", transform=test_transform, download=True)\n",
        "\n",
        "test_data = datasets.Flowers102(root=\"dataset\", split=\"test\", transform=test_transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "EiOOyavq-T-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aaeaca1-d0b1-494a-c788-53f88e0679aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 3, 224, 224])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "#Create data loaders\n",
        "#train_dataloader = DataLoader(training_data_augment, batch_size = batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "  print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "3fL6F9TLEdDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d43143a-0cbf-456b-c903-82f6042358c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU()\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU()\n",
            "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU()\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): Flatten(start_dim=1, end_dim=-1)\n",
            "    (17): Linear(in_features=25088, out_features=512, bias=True)\n",
            "    (18): ReLU()\n",
            "    (19): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (20): ReLU()\n",
            "    (21): Linear(in_features=256, out_features=102, bias=True)\n",
            "    (22): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "#Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "      nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.BatchNorm2d(16),\n",
        "      nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.BatchNorm2d(32),\n",
        "      nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(128 * 14 * 14, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512, 256),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(256,102),\n",
        "      nn.LogSoftmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "9IvJsfvwE0VG"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "o4bMoWUAE1kO"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    #Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 5 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "y4Mf49itE3A-"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct) :>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Xr7VD7E3E5y1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0075b05-39a7-47a6-e320-75bdbbf2610f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            " ---------------------------------------\n",
            "loss: 4.662923 [   64/ 1020]\n",
            "loss: 5.213340 [  384/ 1020]\n",
            "loss: 5.085704 [  704/ 1020]\n",
            "loss: 5.002332 [  960/ 1020]\n",
            "loss: 4.552147 [   64/ 1020]\n",
            "loss: 4.538687 [  384/ 1020]\n",
            "loss: 4.525755 [  704/ 1020]\n",
            "loss: 4.389920 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 5.5%, Avg loss: 4.305128 \n",
            "\n",
            "Epoch 2 \n",
            " ---------------------------------------\n",
            "loss: 4.452215 [   64/ 1020]\n",
            "loss: 4.576705 [  384/ 1020]\n",
            "loss: 4.681792 [  704/ 1020]\n",
            "loss: 4.690444 [  960/ 1020]\n",
            "loss: 4.310209 [   64/ 1020]\n",
            "loss: 4.087029 [  384/ 1020]\n",
            "loss: 3.880483 [  704/ 1020]\n",
            "loss: 3.988247 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 9.1%, Avg loss: 3.887142 \n",
            "\n",
            "Epoch 3 \n",
            " ---------------------------------------\n",
            "loss: 4.091994 [   64/ 1020]\n",
            "loss: 3.917314 [  384/ 1020]\n",
            "loss: 4.765267 [  704/ 1020]\n",
            "loss: 3.958474 [  960/ 1020]\n",
            "loss: 3.783574 [   64/ 1020]\n",
            "loss: 3.959542 [  384/ 1020]\n",
            "loss: 3.843003 [  704/ 1020]\n",
            "loss: 3.616722 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 11.8%, Avg loss: 3.854474 \n",
            "\n",
            "Epoch 4 \n",
            " ---------------------------------------\n",
            "loss: 3.439471 [   64/ 1020]\n",
            "loss: 3.258859 [  384/ 1020]\n",
            "loss: 3.408020 [  704/ 1020]\n",
            "loss: 3.484202 [  960/ 1020]\n",
            "loss: 3.190367 [   64/ 1020]\n",
            "loss: 3.258512 [  384/ 1020]\n",
            "loss: 3.726438 [  704/ 1020]\n",
            "loss: 3.616997 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 15.1%, Avg loss: 3.730733 \n",
            "\n",
            "Epoch 5 \n",
            " ---------------------------------------\n",
            "loss: 2.985548 [   64/ 1020]\n",
            "loss: 2.470906 [  384/ 1020]\n",
            "loss: 2.309453 [  704/ 1020]\n",
            "loss: 3.284633 [  960/ 1020]\n",
            "loss: 3.478463 [   64/ 1020]\n",
            "loss: 3.454701 [  384/ 1020]\n",
            "loss: 3.160957 [  704/ 1020]\n",
            "loss: 3.389026 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 17.5%, Avg loss: 3.576854 \n",
            "\n",
            "Epoch 6 \n",
            " ---------------------------------------\n",
            "loss: 2.087501 [   64/ 1020]\n",
            "loss: 1.982511 [  384/ 1020]\n",
            "loss: 1.515893 [  704/ 1020]\n",
            "loss: 1.902600 [  960/ 1020]\n",
            "loss: 3.730239 [   64/ 1020]\n",
            "loss: 3.107344 [  384/ 1020]\n",
            "loss: 2.936125 [  704/ 1020]\n",
            "loss: 2.685402 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 22.6%, Avg loss: 3.535437 \n",
            "\n",
            "Epoch 7 \n",
            " ---------------------------------------\n",
            "loss: 1.215890 [   64/ 1020]\n",
            "loss: 1.168522 [  384/ 1020]\n",
            "loss: 1.053867 [  704/ 1020]\n",
            "loss: 0.959433 [  960/ 1020]\n",
            "loss: 2.883984 [   64/ 1020]\n",
            "loss: 2.902374 [  384/ 1020]\n",
            "loss: 2.197093 [  704/ 1020]\n",
            "loss: 2.898396 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.2%, Avg loss: 3.533792 \n",
            "\n",
            "Epoch 8 \n",
            " ---------------------------------------\n",
            "loss: 0.722616 [   64/ 1020]\n",
            "loss: 0.794177 [  384/ 1020]\n",
            "loss: 0.602293 [  704/ 1020]\n",
            "loss: 0.355437 [  960/ 1020]\n",
            "loss: 2.677785 [   64/ 1020]\n",
            "loss: 2.297323 [  384/ 1020]\n",
            "loss: 2.268628 [  704/ 1020]\n",
            "loss: 2.474367 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.7%, Avg loss: 3.681716 \n",
            "\n",
            "Epoch 9 \n",
            " ---------------------------------------\n",
            "loss: 0.572432 [   64/ 1020]\n",
            "loss: 0.472021 [  384/ 1020]\n",
            "loss: 0.734145 [  704/ 1020]\n",
            "loss: 0.457555 [  960/ 1020]\n",
            "loss: 2.822317 [   64/ 1020]\n",
            "loss: 2.412294 [  384/ 1020]\n",
            "loss: 1.898403 [  704/ 1020]\n",
            "loss: 2.649062 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.5%, Avg loss: 3.823946 \n",
            "\n",
            "Epoch 10 \n",
            " ---------------------------------------\n",
            "loss: 0.343310 [   64/ 1020]\n",
            "loss: 0.303550 [  384/ 1020]\n",
            "loss: 0.338679 [  704/ 1020]\n",
            "loss: 0.204904 [  960/ 1020]\n",
            "loss: 2.598725 [   64/ 1020]\n",
            "loss: 2.079327 [  384/ 1020]\n",
            "loss: 1.907470 [  704/ 1020]\n",
            "loss: 2.110516 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.9%, Avg loss: 3.735545 \n",
            "\n",
            "Epoch 11 \n",
            " ---------------------------------------\n",
            "loss: 0.228379 [   64/ 1020]\n",
            "loss: 0.296447 [  384/ 1020]\n",
            "loss: 0.253465 [  704/ 1020]\n",
            "loss: 0.179263 [  960/ 1020]\n",
            "loss: 2.886362 [   64/ 1020]\n",
            "loss: 1.691415 [  384/ 1020]\n",
            "loss: 1.813271 [  704/ 1020]\n",
            "loss: 2.086252 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.9%, Avg loss: 4.004272 \n",
            "\n",
            "Epoch 12 \n",
            " ---------------------------------------\n",
            "loss: 0.152113 [   64/ 1020]\n",
            "loss: 0.132506 [  384/ 1020]\n",
            "loss: 0.284715 [  704/ 1020]\n",
            "loss: 0.201154 [  960/ 1020]\n",
            "loss: 1.995403 [   64/ 1020]\n",
            "loss: 1.717806 [  384/ 1020]\n",
            "loss: 1.869817 [  704/ 1020]\n",
            "loss: 1.779703 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.9%, Avg loss: 4.144195 \n",
            "\n",
            "Epoch 13 \n",
            " ---------------------------------------\n",
            "loss: 0.119333 [   64/ 1020]\n",
            "loss: 0.132844 [  384/ 1020]\n",
            "loss: 0.305893 [  704/ 1020]\n",
            "loss: 0.125408 [  960/ 1020]\n",
            "loss: 1.642702 [   64/ 1020]\n",
            "loss: 1.477071 [  384/ 1020]\n",
            "loss: 1.559830 [  704/ 1020]\n",
            "loss: 1.563486 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.2%, Avg loss: 4.111541 \n",
            "\n",
            "Epoch 14 \n",
            " ---------------------------------------\n",
            "loss: 0.065816 [   64/ 1020]\n",
            "loss: 0.278427 [  384/ 1020]\n",
            "loss: 0.153087 [  704/ 1020]\n",
            "loss: 0.041815 [  960/ 1020]\n",
            "loss: 2.100240 [   64/ 1020]\n",
            "loss: 1.822180 [  384/ 1020]\n",
            "loss: 1.909029 [  704/ 1020]\n",
            "loss: 1.968458 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.2%, Avg loss: 4.131350 \n",
            "\n",
            "Epoch 15 \n",
            " ---------------------------------------\n",
            "loss: 0.097524 [   64/ 1020]\n",
            "loss: 0.140268 [  384/ 1020]\n",
            "loss: 0.240423 [  704/ 1020]\n",
            "loss: 0.155692 [  960/ 1020]\n",
            "loss: 1.592746 [   64/ 1020]\n",
            "loss: 1.824640 [  384/ 1020]\n",
            "loss: 1.633199 [  704/ 1020]\n",
            "loss: 1.512511 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.9%, Avg loss: 4.311852 \n",
            "\n",
            "Epoch 16 \n",
            " ---------------------------------------\n",
            "loss: 0.136219 [   64/ 1020]\n",
            "loss: 0.056318 [  384/ 1020]\n",
            "loss: 0.181184 [  704/ 1020]\n",
            "loss: 0.030440 [  960/ 1020]\n",
            "loss: 1.820288 [   64/ 1020]\n",
            "loss: 1.384359 [  384/ 1020]\n",
            "loss: 1.209926 [  704/ 1020]\n",
            "loss: 1.560318 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.6%, Avg loss: 4.358080 \n",
            "\n",
            "Epoch 17 \n",
            " ---------------------------------------\n",
            "loss: 0.039303 [   64/ 1020]\n",
            "loss: 0.210161 [  384/ 1020]\n",
            "loss: 0.056019 [  704/ 1020]\n",
            "loss: 0.179544 [  960/ 1020]\n",
            "loss: 1.685985 [   64/ 1020]\n",
            "loss: 1.378199 [  384/ 1020]\n",
            "loss: 1.316223 [  704/ 1020]\n",
            "loss: 1.264511 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.2%, Avg loss: 4.456120 \n",
            "\n",
            "Epoch 18 \n",
            " ---------------------------------------\n",
            "loss: 0.142202 [   64/ 1020]\n",
            "loss: 0.096309 [  384/ 1020]\n",
            "loss: 0.133042 [  704/ 1020]\n",
            "loss: 0.037512 [  960/ 1020]\n",
            "loss: 1.612952 [   64/ 1020]\n",
            "loss: 1.219752 [  384/ 1020]\n",
            "loss: 1.429367 [  704/ 1020]\n",
            "loss: 1.389603 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.9%, Avg loss: 4.588957 \n",
            "\n",
            "Epoch 19 \n",
            " ---------------------------------------\n",
            "loss: 0.113999 [   64/ 1020]\n",
            "loss: 0.022151 [  384/ 1020]\n",
            "loss: 0.146446 [  704/ 1020]\n",
            "loss: 0.139246 [  960/ 1020]\n",
            "loss: 1.404456 [   64/ 1020]\n",
            "loss: 1.451129 [  384/ 1020]\n",
            "loss: 1.171646 [  704/ 1020]\n",
            "loss: 1.298708 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.3%, Avg loss: 4.398391 \n",
            "\n",
            "Epoch 20 \n",
            " ---------------------------------------\n",
            "loss: 0.027141 [   64/ 1020]\n",
            "loss: 0.018765 [  384/ 1020]\n",
            "loss: 0.069004 [  704/ 1020]\n",
            "loss: 0.014422 [  960/ 1020]\n",
            "loss: 1.536983 [   64/ 1020]\n",
            "loss: 0.848767 [  384/ 1020]\n",
            "loss: 0.856452 [  704/ 1020]\n",
            "loss: 1.312164 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.8%, Avg loss: 4.549958 \n",
            "\n",
            "Epoch 21 \n",
            " ---------------------------------------\n",
            "loss: 0.087757 [   64/ 1020]\n",
            "loss: 0.044402 [  384/ 1020]\n",
            "loss: 0.030838 [  704/ 1020]\n",
            "loss: 0.066690 [  960/ 1020]\n",
            "loss: 1.025828 [   64/ 1020]\n",
            "loss: 1.739655 [  384/ 1020]\n",
            "loss: 1.538821 [  704/ 1020]\n",
            "loss: 0.765406 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.5%, Avg loss: 4.739410 \n",
            "\n",
            "Epoch 22 \n",
            " ---------------------------------------\n",
            "loss: 0.044729 [   64/ 1020]\n",
            "loss: 0.138671 [  384/ 1020]\n",
            "loss: 0.084922 [  704/ 1020]\n",
            "loss: 0.117837 [  960/ 1020]\n",
            "loss: 1.134488 [   64/ 1020]\n",
            "loss: 0.726060 [  384/ 1020]\n",
            "loss: 1.089662 [  704/ 1020]\n",
            "loss: 1.008741 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.2%, Avg loss: 4.668926 \n",
            "\n",
            "Epoch 23 \n",
            " ---------------------------------------\n",
            "loss: 0.027343 [   64/ 1020]\n",
            "loss: 0.008235 [  384/ 1020]\n",
            "loss: 0.034029 [  704/ 1020]\n",
            "loss: 0.055396 [  960/ 1020]\n",
            "loss: 1.481854 [   64/ 1020]\n",
            "loss: 0.738584 [  384/ 1020]\n",
            "loss: 1.300779 [  704/ 1020]\n",
            "loss: 1.028030 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.9%, Avg loss: 4.639466 \n",
            "\n",
            "Epoch 24 \n",
            " ---------------------------------------\n",
            "loss: 0.053407 [   64/ 1020]\n",
            "loss: 0.098069 [  384/ 1020]\n",
            "loss: 0.026597 [  704/ 1020]\n",
            "loss: 0.105896 [  960/ 1020]\n",
            "loss: 1.033489 [   64/ 1020]\n",
            "loss: 1.124099 [  384/ 1020]\n",
            "loss: 1.024971 [  704/ 1020]\n",
            "loss: 1.041288 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.5%, Avg loss: 5.136853 \n",
            "\n",
            "Epoch 25 \n",
            " ---------------------------------------\n",
            "loss: 0.053481 [   64/ 1020]\n",
            "loss: 0.082585 [  384/ 1020]\n",
            "loss: 0.117798 [  704/ 1020]\n",
            "loss: 0.016536 [  960/ 1020]\n",
            "loss: 0.819662 [   64/ 1020]\n",
            "loss: 0.983140 [  384/ 1020]\n",
            "loss: 0.862531 [  704/ 1020]\n",
            "loss: 1.044167 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.5%, Avg loss: 4.965881 \n",
            "\n",
            "Epoch 26 \n",
            " ---------------------------------------\n",
            "loss: 0.017499 [   64/ 1020]\n",
            "loss: 0.035950 [  384/ 1020]\n",
            "loss: 0.029142 [  704/ 1020]\n",
            "loss: 0.023829 [  960/ 1020]\n",
            "loss: 1.148350 [   64/ 1020]\n",
            "loss: 0.876724 [  384/ 1020]\n",
            "loss: 0.933815 [  704/ 1020]\n",
            "loss: 0.660971 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.6%, Avg loss: 5.376666 \n",
            "\n",
            "Epoch 27 \n",
            " ---------------------------------------\n",
            "loss: 0.013567 [   64/ 1020]\n",
            "loss: 0.175624 [  384/ 1020]\n",
            "loss: 0.036299 [  704/ 1020]\n",
            "loss: 0.051984 [  960/ 1020]\n",
            "loss: 0.780303 [   64/ 1020]\n",
            "loss: 1.062918 [  384/ 1020]\n",
            "loss: 0.501238 [  704/ 1020]\n",
            "loss: 0.652562 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.4%, Avg loss: 5.245098 \n",
            "\n",
            "Epoch 28 \n",
            " ---------------------------------------\n",
            "loss: 0.057048 [   64/ 1020]\n",
            "loss: 0.160217 [  384/ 1020]\n",
            "loss: 0.024769 [  704/ 1020]\n",
            "loss: 0.067223 [  960/ 1020]\n",
            "loss: 0.975295 [   64/ 1020]\n",
            "loss: 0.630341 [  384/ 1020]\n",
            "loss: 0.412328 [  704/ 1020]\n",
            "loss: 1.148430 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.7%, Avg loss: 5.186235 \n",
            "\n",
            "Epoch 29 \n",
            " ---------------------------------------\n",
            "loss: 0.023830 [   64/ 1020]\n",
            "loss: 0.109974 [  384/ 1020]\n",
            "loss: 0.021515 [  704/ 1020]\n",
            "loss: 0.077999 [  960/ 1020]\n",
            "loss: 0.884125 [   64/ 1020]\n",
            "loss: 0.732443 [  384/ 1020]\n",
            "loss: 0.511298 [  704/ 1020]\n",
            "loss: 0.791620 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.3%, Avg loss: 5.592052 \n",
            "\n",
            "Epoch 30 \n",
            " ---------------------------------------\n",
            "loss: 0.054151 [   64/ 1020]\n",
            "loss: 0.023236 [  384/ 1020]\n",
            "loss: 0.114723 [  704/ 1020]\n",
            "loss: 0.036637 [  960/ 1020]\n",
            "loss: 0.783481 [   64/ 1020]\n",
            "loss: 0.515743 [  384/ 1020]\n",
            "loss: 0.740366 [  704/ 1020]\n",
            "loss: 1.226884 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.4%, Avg loss: 5.635265 \n",
            "\n",
            "Epoch 31 \n",
            " ---------------------------------------\n",
            "loss: 0.014756 [   64/ 1020]\n",
            "loss: 0.146216 [  384/ 1020]\n",
            "loss: 0.092375 [  704/ 1020]\n",
            "loss: 0.072305 [  960/ 1020]\n",
            "loss: 1.483509 [   64/ 1020]\n",
            "loss: 0.982106 [  384/ 1020]\n",
            "loss: 1.211093 [  704/ 1020]\n",
            "loss: 0.911543 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.7%, Avg loss: 6.019163 \n",
            "\n",
            "Epoch 32 \n",
            " ---------------------------------------\n",
            "loss: 0.057716 [   64/ 1020]\n",
            "loss: 0.017373 [  384/ 1020]\n",
            "loss: 0.161981 [  704/ 1020]\n",
            "loss: 0.017172 [  960/ 1020]\n",
            "loss: 0.748674 [   64/ 1020]\n",
            "loss: 0.753462 [  384/ 1020]\n",
            "loss: 0.668940 [  704/ 1020]\n",
            "loss: 0.986057 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.8%, Avg loss: 5.554650 \n",
            "\n",
            "Epoch 33 \n",
            " ---------------------------------------\n",
            "loss: 0.017206 [   64/ 1020]\n",
            "loss: 0.008355 [  384/ 1020]\n",
            "loss: 0.076918 [  704/ 1020]\n",
            "loss: 0.092082 [  960/ 1020]\n",
            "loss: 1.010149 [   64/ 1020]\n",
            "loss: 0.604607 [  384/ 1020]\n",
            "loss: 0.744997 [  704/ 1020]\n",
            "loss: 0.991628 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.3%, Avg loss: 5.335386 \n",
            "\n",
            "Epoch 34 \n",
            " ---------------------------------------\n",
            "loss: 0.028111 [   64/ 1020]\n",
            "loss: 0.037220 [  384/ 1020]\n",
            "loss: 0.114229 [  704/ 1020]\n",
            "loss: 0.123985 [  960/ 1020]\n",
            "loss: 1.008935 [   64/ 1020]\n",
            "loss: 0.751686 [  384/ 1020]\n",
            "loss: 0.328290 [  704/ 1020]\n",
            "loss: 0.523897 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.3%, Avg loss: 5.632398 \n",
            "\n",
            "Epoch 35 \n",
            " ---------------------------------------\n",
            "loss: 0.020341 [   64/ 1020]\n",
            "loss: 0.034916 [  384/ 1020]\n",
            "loss: 0.037262 [  704/ 1020]\n",
            "loss: 0.098768 [  960/ 1020]\n",
            "loss: 0.709988 [   64/ 1020]\n",
            "loss: 0.646144 [  384/ 1020]\n",
            "loss: 0.938179 [  704/ 1020]\n",
            "loss: 0.652862 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.8%, Avg loss: 5.786631 \n",
            "\n",
            "Epoch 36 \n",
            " ---------------------------------------\n",
            "loss: 0.011089 [   64/ 1020]\n",
            "loss: 0.005415 [  384/ 1020]\n",
            "loss: 0.004757 [  704/ 1020]\n",
            "loss: 0.018164 [  960/ 1020]\n",
            "loss: 0.811946 [   64/ 1020]\n",
            "loss: 0.674780 [  384/ 1020]\n",
            "loss: 0.352465 [  704/ 1020]\n",
            "loss: 0.677192 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.5%, Avg loss: 5.524352 \n",
            "\n",
            "Epoch 37 \n",
            " ---------------------------------------\n",
            "loss: 0.027973 [   64/ 1020]\n",
            "loss: 0.003449 [  384/ 1020]\n",
            "loss: 0.019825 [  704/ 1020]\n",
            "loss: 0.007568 [  960/ 1020]\n",
            "loss: 1.067801 [   64/ 1020]\n",
            "loss: 0.752103 [  384/ 1020]\n",
            "loss: 0.523940 [  704/ 1020]\n",
            "loss: 0.365682 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.1%, Avg loss: 5.910680 \n",
            "\n",
            "Epoch 38 \n",
            " ---------------------------------------\n",
            "loss: 0.038534 [   64/ 1020]\n",
            "loss: 0.068724 [  384/ 1020]\n",
            "loss: 0.005424 [  704/ 1020]\n",
            "loss: 0.103406 [  960/ 1020]\n",
            "loss: 0.722258 [   64/ 1020]\n",
            "loss: 0.406728 [  384/ 1020]\n",
            "loss: 0.618630 [  704/ 1020]\n",
            "loss: 0.642859 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.1%, Avg loss: 5.954462 \n",
            "\n",
            "Epoch 39 \n",
            " ---------------------------------------\n",
            "loss: 0.040357 [   64/ 1020]\n",
            "loss: 0.001361 [  384/ 1020]\n",
            "loss: 0.011376 [  704/ 1020]\n",
            "loss: 0.068898 [  960/ 1020]\n",
            "loss: 0.749516 [   64/ 1020]\n",
            "loss: 0.587168 [  384/ 1020]\n",
            "loss: 0.583333 [  704/ 1020]\n",
            "loss: 0.861244 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.5%, Avg loss: 6.041321 \n",
            "\n",
            "Epoch 40 \n",
            " ---------------------------------------\n",
            "loss: 0.057928 [   64/ 1020]\n",
            "loss: 0.038238 [  384/ 1020]\n",
            "loss: 0.001621 [  704/ 1020]\n",
            "loss: 0.068280 [  960/ 1020]\n",
            "loss: 0.621501 [   64/ 1020]\n",
            "loss: 0.593703 [  384/ 1020]\n",
            "loss: 0.580003 [  704/ 1020]\n",
            "loss: 0.379813 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.7%, Avg loss: 6.155885 \n",
            "\n",
            "Epoch 41 \n",
            " ---------------------------------------\n",
            "loss: 0.004556 [   64/ 1020]\n",
            "loss: 0.020508 [  384/ 1020]\n",
            "loss: 0.025850 [  704/ 1020]\n",
            "loss: 0.059834 [  960/ 1020]\n",
            "loss: 0.579274 [   64/ 1020]\n",
            "loss: 0.519465 [  384/ 1020]\n",
            "loss: 0.636488 [  704/ 1020]\n",
            "loss: 0.591341 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.1%, Avg loss: 6.398994 \n",
            "\n",
            "Epoch 42 \n",
            " ---------------------------------------\n",
            "loss: 0.005400 [   64/ 1020]\n",
            "loss: 0.027787 [  384/ 1020]\n",
            "loss: 0.002723 [  704/ 1020]\n",
            "loss: 0.025136 [  960/ 1020]\n",
            "loss: 1.110850 [   64/ 1020]\n",
            "loss: 0.704384 [  384/ 1020]\n",
            "loss: 0.685072 [  704/ 1020]\n",
            "loss: 0.687697 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.9%, Avg loss: 5.700792 \n",
            "\n",
            "Epoch 43 \n",
            " ---------------------------------------\n",
            "loss: 0.069869 [   64/ 1020]\n",
            "loss: 0.035199 [  384/ 1020]\n",
            "loss: 0.036769 [  704/ 1020]\n",
            "loss: 0.056331 [  960/ 1020]\n",
            "loss: 1.011873 [   64/ 1020]\n",
            "loss: 0.443573 [  384/ 1020]\n",
            "loss: 0.723324 [  704/ 1020]\n",
            "loss: 0.390346 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.4%, Avg loss: 6.282182 \n",
            "\n",
            "Epoch 44 \n",
            " ---------------------------------------\n",
            "loss: 0.034662 [   64/ 1020]\n",
            "loss: 0.052264 [  384/ 1020]\n",
            "loss: 0.006074 [  704/ 1020]\n",
            "loss: 0.032056 [  960/ 1020]\n",
            "loss: 0.777258 [   64/ 1020]\n",
            "loss: 0.351491 [  384/ 1020]\n",
            "loss: 0.713879 [  704/ 1020]\n",
            "loss: 0.568322 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.8%, Avg loss: 6.077608 \n",
            "\n",
            "Epoch 45 \n",
            " ---------------------------------------\n",
            "loss: 0.005127 [   64/ 1020]\n",
            "loss: 0.000926 [  384/ 1020]\n",
            "loss: 0.036446 [  704/ 1020]\n",
            "loss: 0.095644 [  960/ 1020]\n",
            "loss: 0.649443 [   64/ 1020]\n",
            "loss: 0.307428 [  384/ 1020]\n",
            "loss: 0.475123 [  704/ 1020]\n",
            "loss: 0.359902 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.6%, Avg loss: 5.944488 \n",
            "\n",
            "Epoch 46 \n",
            " ---------------------------------------\n",
            "loss: 0.035337 [   64/ 1020]\n",
            "loss: 0.004343 [  384/ 1020]\n",
            "loss: 0.149361 [  704/ 1020]\n",
            "loss: 0.025614 [  960/ 1020]\n",
            "loss: 0.616337 [   64/ 1020]\n",
            "loss: 0.627212 [  384/ 1020]\n",
            "loss: 0.497648 [  704/ 1020]\n",
            "loss: 0.460267 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.0%, Avg loss: 6.512272 \n",
            "\n",
            "Epoch 47 \n",
            " ---------------------------------------\n",
            "loss: 0.019427 [   64/ 1020]\n",
            "loss: 0.008533 [  384/ 1020]\n",
            "loss: 0.010204 [  704/ 1020]\n",
            "loss: 0.011093 [  960/ 1020]\n",
            "loss: 0.762148 [   64/ 1020]\n",
            "loss: 0.427424 [  384/ 1020]\n",
            "loss: 0.473680 [  704/ 1020]\n",
            "loss: 0.362514 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.0%, Avg loss: 6.417414 \n",
            "\n",
            "Epoch 48 \n",
            " ---------------------------------------\n",
            "loss: 0.002379 [   64/ 1020]\n",
            "loss: 0.031362 [  384/ 1020]\n",
            "loss: 0.026956 [  704/ 1020]\n",
            "loss: 0.016754 [  960/ 1020]\n",
            "loss: 0.650674 [   64/ 1020]\n",
            "loss: 0.206943 [  384/ 1020]\n",
            "loss: 0.179459 [  704/ 1020]\n",
            "loss: 0.387590 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.8%, Avg loss: 6.133797 \n",
            "\n",
            "Epoch 49 \n",
            " ---------------------------------------\n",
            "loss: 0.004414 [   64/ 1020]\n",
            "loss: 0.047904 [  384/ 1020]\n",
            "loss: 0.020965 [  704/ 1020]\n",
            "loss: 0.091725 [  960/ 1020]\n",
            "loss: 0.616474 [   64/ 1020]\n",
            "loss: 0.339452 [  384/ 1020]\n",
            "loss: 0.615254 [  704/ 1020]\n",
            "loss: 0.561059 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.3%, Avg loss: 6.651647 \n",
            "\n",
            "Epoch 50 \n",
            " ---------------------------------------\n",
            "loss: 0.007795 [   64/ 1020]\n",
            "loss: 0.016134 [  384/ 1020]\n",
            "loss: 0.012641 [  704/ 1020]\n",
            "loss: 0.002397 [  960/ 1020]\n",
            "loss: 0.651382 [   64/ 1020]\n",
            "loss: 0.194815 [  384/ 1020]\n",
            "loss: 0.585483 [  704/ 1020]\n",
            "loss: 0.355044 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.1%, Avg loss: 6.588289 \n",
            "\n",
            "Epoch 51 \n",
            " ---------------------------------------\n",
            "loss: 0.019016 [   64/ 1020]\n",
            "loss: 0.001671 [  384/ 1020]\n",
            "loss: 0.009985 [  704/ 1020]\n",
            "loss: 0.003781 [  960/ 1020]\n",
            "loss: 0.332359 [   64/ 1020]\n",
            "loss: 0.299798 [  384/ 1020]\n",
            "loss: 0.434247 [  704/ 1020]\n",
            "loss: 0.333986 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.6%, Avg loss: 6.969399 \n",
            "\n",
            "Epoch 52 \n",
            " ---------------------------------------\n",
            "loss: 0.045987 [   64/ 1020]\n",
            "loss: 0.071991 [  384/ 1020]\n",
            "loss: 0.006035 [  704/ 1020]\n",
            "loss: 0.000393 [  960/ 1020]\n",
            "loss: 0.714783 [   64/ 1020]\n",
            "loss: 0.718436 [  384/ 1020]\n",
            "loss: 0.457892 [  704/ 1020]\n",
            "loss: 0.282627 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.4%, Avg loss: 6.349348 \n",
            "\n",
            "Epoch 53 \n",
            " ---------------------------------------\n",
            "loss: 0.003868 [   64/ 1020]\n",
            "loss: 0.045434 [  384/ 1020]\n",
            "loss: 0.513774 [  704/ 1020]\n",
            "loss: 0.009469 [  960/ 1020]\n",
            "loss: 0.413530 [   64/ 1020]\n",
            "loss: 0.429989 [  384/ 1020]\n",
            "loss: 0.234878 [  704/ 1020]\n",
            "loss: 0.493317 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.7%, Avg loss: 6.507645 \n",
            "\n",
            "Epoch 54 \n",
            " ---------------------------------------\n",
            "loss: 0.004139 [   64/ 1020]\n",
            "loss: 0.000727 [  384/ 1020]\n",
            "loss: 0.000504 [  704/ 1020]\n",
            "loss: 0.005425 [  960/ 1020]\n",
            "loss: 0.191807 [   64/ 1020]\n",
            "loss: 0.280032 [  384/ 1020]\n",
            "loss: 0.809527 [  704/ 1020]\n",
            "loss: 0.228413 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.2%, Avg loss: 6.672734 \n",
            "\n",
            "Epoch 55 \n",
            " ---------------------------------------\n",
            "loss: 0.000903 [   64/ 1020]\n",
            "loss: 0.016388 [  384/ 1020]\n",
            "loss: 0.045838 [  704/ 1020]\n",
            "loss: 0.039918 [  960/ 1020]\n",
            "loss: 0.635412 [   64/ 1020]\n",
            "loss: 0.234063 [  384/ 1020]\n",
            "loss: 0.355764 [  704/ 1020]\n",
            "loss: 0.194721 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.9%, Avg loss: 7.005214 \n",
            "\n",
            "Epoch 56 \n",
            " ---------------------------------------\n",
            "loss: 0.002291 [   64/ 1020]\n",
            "loss: 0.016951 [  384/ 1020]\n",
            "loss: 0.242596 [  704/ 1020]\n",
            "loss: 0.007852 [  960/ 1020]\n",
            "loss: 0.407220 [   64/ 1020]\n",
            "loss: 0.305421 [  384/ 1020]\n",
            "loss: 0.426413 [  704/ 1020]\n",
            "loss: 0.154933 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.7%, Avg loss: 6.997820 \n",
            "\n",
            "Epoch 57 \n",
            " ---------------------------------------\n",
            "loss: 0.013325 [   64/ 1020]\n",
            "loss: 0.083798 [  384/ 1020]\n",
            "loss: 0.099174 [  704/ 1020]\n",
            "loss: 0.014990 [  960/ 1020]\n",
            "loss: 0.683605 [   64/ 1020]\n",
            "loss: 0.176494 [  384/ 1020]\n",
            "loss: 0.402209 [  704/ 1020]\n",
            "loss: 0.318447 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.7%, Avg loss: 6.836794 \n",
            "\n",
            "Epoch 58 \n",
            " ---------------------------------------\n",
            "loss: 0.005128 [   64/ 1020]\n",
            "loss: 0.012298 [  384/ 1020]\n",
            "loss: 0.015171 [  704/ 1020]\n",
            "loss: 0.475192 [  960/ 1020]\n",
            "loss: 0.266926 [   64/ 1020]\n",
            "loss: 0.282383 [  384/ 1020]\n",
            "loss: 0.285436 [  704/ 1020]\n",
            "loss: 0.199854 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.3%, Avg loss: 7.057201 \n",
            "\n",
            "Epoch 59 \n",
            " ---------------------------------------\n",
            "loss: 0.017358 [   64/ 1020]\n",
            "loss: 0.000439 [  384/ 1020]\n",
            "loss: 0.000118 [  704/ 1020]\n",
            "loss: 0.106596 [  960/ 1020]\n",
            "loss: 0.334707 [   64/ 1020]\n",
            "loss: 0.213521 [  384/ 1020]\n",
            "loss: 0.377288 [  704/ 1020]\n",
            "loss: 0.454137 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.7%, Avg loss: 6.954374 \n",
            "\n",
            "Epoch 60 \n",
            " ---------------------------------------\n",
            "loss: 0.001023 [   64/ 1020]\n",
            "loss: 0.000332 [  384/ 1020]\n",
            "loss: 0.014523 [  704/ 1020]\n",
            "loss: 0.025048 [  960/ 1020]\n",
            "loss: 0.383140 [   64/ 1020]\n",
            "loss: 0.209052 [  384/ 1020]\n",
            "loss: 0.448191 [  704/ 1020]\n",
            "loss: 0.243400 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 39.0%, Avg loss: 6.825038 \n",
            "\n",
            "Epoch 61 \n",
            " ---------------------------------------\n",
            "loss: 0.014771 [   64/ 1020]\n",
            "loss: 0.000600 [  384/ 1020]\n",
            "loss: 0.001507 [  704/ 1020]\n",
            "loss: 0.000421 [  960/ 1020]\n",
            "loss: 0.219221 [   64/ 1020]\n",
            "loss: 0.151008 [  384/ 1020]\n",
            "loss: 0.295491 [  704/ 1020]\n",
            "loss: 0.409912 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.7%, Avg loss: 6.802939 \n",
            "\n",
            "Epoch 62 \n",
            " ---------------------------------------\n",
            "loss: 0.000865 [   64/ 1020]\n",
            "loss: 0.003661 [  384/ 1020]\n",
            "loss: 0.000261 [  704/ 1020]\n",
            "loss: 0.012338 [  960/ 1020]\n",
            "loss: 0.415002 [   64/ 1020]\n",
            "loss: 0.174604 [  384/ 1020]\n",
            "loss: 0.220650 [  704/ 1020]\n",
            "loss: 0.240866 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.4%, Avg loss: 6.866801 \n",
            "\n",
            "Epoch 63 \n",
            " ---------------------------------------\n",
            "loss: 0.002269 [   64/ 1020]\n",
            "loss: 0.000134 [  384/ 1020]\n",
            "loss: 0.024486 [  704/ 1020]\n",
            "loss: 0.002014 [  960/ 1020]\n",
            "loss: 0.507717 [   64/ 1020]\n",
            "loss: 0.135343 [  384/ 1020]\n",
            "loss: 0.231450 [  704/ 1020]\n",
            "loss: 0.286313 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.8%, Avg loss: 6.845992 \n",
            "\n",
            "Epoch 64 \n",
            " ---------------------------------------\n",
            "loss: 0.023699 [   64/ 1020]\n",
            "loss: 0.032894 [  384/ 1020]\n",
            "loss: 0.016874 [  704/ 1020]\n",
            "loss: 0.002879 [  960/ 1020]\n",
            "loss: 0.457470 [   64/ 1020]\n",
            "loss: 0.478959 [  384/ 1020]\n",
            "loss: 0.173794 [  704/ 1020]\n",
            "loss: 0.250750 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.5%, Avg loss: 7.251480 \n",
            "\n",
            "Epoch 65 \n",
            " ---------------------------------------\n",
            "loss: 0.009453 [   64/ 1020]\n",
            "loss: 0.071524 [  384/ 1020]\n",
            "loss: 0.141428 [  704/ 1020]\n",
            "loss: 0.021569 [  960/ 1020]\n",
            "loss: 0.146262 [   64/ 1020]\n",
            "loss: 0.259569 [  384/ 1020]\n",
            "loss: 0.229911 [  704/ 1020]\n",
            "loss: 0.342152 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.1%, Avg loss: 7.675608 \n",
            "\n",
            "Epoch 66 \n",
            " ---------------------------------------\n",
            "loss: 0.019363 [   64/ 1020]\n",
            "loss: 0.003506 [  384/ 1020]\n",
            "loss: 0.118618 [  704/ 1020]\n",
            "loss: 0.002776 [  960/ 1020]\n",
            "loss: 0.685524 [   64/ 1020]\n",
            "loss: 0.163612 [  384/ 1020]\n",
            "loss: 0.280309 [  704/ 1020]\n",
            "loss: 0.424204 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.0%, Avg loss: 7.164195 \n",
            "\n",
            "Epoch 67 \n",
            " ---------------------------------------\n",
            "loss: 0.004777 [   64/ 1020]\n",
            "loss: 0.000948 [  384/ 1020]\n",
            "loss: 0.032507 [  704/ 1020]\n",
            "loss: 0.064033 [  960/ 1020]\n",
            "loss: 0.642446 [   64/ 1020]\n",
            "loss: 0.381958 [  384/ 1020]\n",
            "loss: 0.256233 [  704/ 1020]\n",
            "loss: 0.451447 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.8%, Avg loss: 7.198822 \n",
            "\n",
            "Epoch 68 \n",
            " ---------------------------------------\n",
            "loss: 0.001725 [   64/ 1020]\n",
            "loss: 0.001781 [  384/ 1020]\n",
            "loss: 0.000143 [  704/ 1020]\n",
            "loss: 0.012508 [  960/ 1020]\n",
            "loss: 0.783494 [   64/ 1020]\n",
            "loss: 0.269477 [  384/ 1020]\n",
            "loss: 0.078704 [  704/ 1020]\n",
            "loss: 0.347956 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.0%, Avg loss: 7.023649 \n",
            "\n",
            "Epoch 69 \n",
            " ---------------------------------------\n",
            "loss: 0.018087 [   64/ 1020]\n",
            "loss: 0.001045 [  384/ 1020]\n",
            "loss: 0.183108 [  704/ 1020]\n",
            "loss: 0.071593 [  960/ 1020]\n",
            "loss: 0.354181 [   64/ 1020]\n",
            "loss: 0.193087 [  384/ 1020]\n",
            "loss: 0.325583 [  704/ 1020]\n",
            "loss: 0.169396 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.5%, Avg loss: 7.861706 \n",
            "\n",
            "Epoch 70 \n",
            " ---------------------------------------\n",
            "loss: 0.000167 [   64/ 1020]\n",
            "loss: 0.002804 [  384/ 1020]\n",
            "loss: 0.000545 [  704/ 1020]\n",
            "loss: 0.003077 [  960/ 1020]\n",
            "loss: 0.327270 [   64/ 1020]\n",
            "loss: 0.251252 [  384/ 1020]\n",
            "loss: 0.333564 [  704/ 1020]\n",
            "loss: 0.260241 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.1%, Avg loss: 7.536063 \n",
            "\n",
            "Epoch 71 \n",
            " ---------------------------------------\n",
            "loss: 0.002811 [   64/ 1020]\n",
            "loss: 0.000490 [  384/ 1020]\n",
            "loss: 0.048735 [  704/ 1020]\n",
            "loss: 0.000918 [  960/ 1020]\n",
            "loss: 0.485370 [   64/ 1020]\n",
            "loss: 0.701441 [  384/ 1020]\n",
            "loss: 0.363492 [  704/ 1020]\n",
            "loss: 0.188923 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.0%, Avg loss: 7.982430 \n",
            "\n",
            "Epoch 72 \n",
            " ---------------------------------------\n",
            "loss: 0.008947 [   64/ 1020]\n",
            "loss: 0.118154 [  384/ 1020]\n",
            "loss: 0.002580 [  704/ 1020]\n",
            "loss: 0.008108 [  960/ 1020]\n",
            "loss: 0.195424 [   64/ 1020]\n",
            "loss: 0.229356 [  384/ 1020]\n",
            "loss: 0.234078 [  704/ 1020]\n",
            "loss: 0.248433 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.1%, Avg loss: 7.172556 \n",
            "\n",
            "Epoch 73 \n",
            " ---------------------------------------\n",
            "loss: 0.001393 [   64/ 1020]\n",
            "loss: 0.001561 [  384/ 1020]\n",
            "loss: 0.002194 [  704/ 1020]\n",
            "loss: 0.003111 [  960/ 1020]\n",
            "loss: 0.281995 [   64/ 1020]\n",
            "loss: 0.313046 [  384/ 1020]\n",
            "loss: 0.445846 [  704/ 1020]\n",
            "loss: 0.240035 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.8%, Avg loss: 7.731489 \n",
            "\n",
            "Epoch 74 \n",
            " ---------------------------------------\n",
            "loss: 0.000427 [   64/ 1020]\n",
            "loss: 0.020013 [  384/ 1020]\n",
            "loss: 0.000349 [  704/ 1020]\n",
            "loss: 0.008319 [  960/ 1020]\n",
            "loss: 0.295594 [   64/ 1020]\n",
            "loss: 0.324764 [  384/ 1020]\n",
            "loss: 0.237076 [  704/ 1020]\n",
            "loss: 0.477789 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 39.3%, Avg loss: 6.921856 \n",
            "\n",
            "Epoch 75 \n",
            " ---------------------------------------\n",
            "loss: 0.004440 [   64/ 1020]\n",
            "loss: 0.001658 [  384/ 1020]\n",
            "loss: 0.005743 [  704/ 1020]\n",
            "loss: 0.037692 [  960/ 1020]\n",
            "loss: 0.225421 [   64/ 1020]\n",
            "loss: 0.234364 [  384/ 1020]\n",
            "loss: 0.247466 [  704/ 1020]\n",
            "loss: 0.131391 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.2%, Avg loss: 7.306945 \n",
            "\n",
            "Epoch 76 \n",
            " ---------------------------------------\n",
            "loss: 0.001388 [   64/ 1020]\n",
            "loss: 0.011241 [  384/ 1020]\n",
            "loss: 0.002485 [  704/ 1020]\n",
            "loss: 0.001215 [  960/ 1020]\n",
            "loss: 0.397949 [   64/ 1020]\n",
            "loss: 0.116521 [  384/ 1020]\n",
            "loss: 0.395510 [  704/ 1020]\n",
            "loss: 0.280433 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.2%, Avg loss: 7.984239 \n",
            "\n",
            "Epoch 77 \n",
            " ---------------------------------------\n",
            "loss: 0.001961 [   64/ 1020]\n",
            "loss: 0.012912 [  384/ 1020]\n",
            "loss: 0.143608 [  704/ 1020]\n",
            "loss: 0.000291 [  960/ 1020]\n",
            "loss: 0.417459 [   64/ 1020]\n",
            "loss: 0.126606 [  384/ 1020]\n",
            "loss: 0.039622 [  704/ 1020]\n",
            "loss: 0.477328 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.8%, Avg loss: 7.426166 \n",
            "\n",
            "Epoch 78 \n",
            " ---------------------------------------\n",
            "loss: 0.013444 [   64/ 1020]\n",
            "loss: 0.001133 [  384/ 1020]\n",
            "loss: 0.000491 [  704/ 1020]\n",
            "loss: 0.024789 [  960/ 1020]\n",
            "loss: 0.349974 [   64/ 1020]\n",
            "loss: 0.323623 [  384/ 1020]\n",
            "loss: 0.194756 [  704/ 1020]\n",
            "loss: 0.300755 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.8%, Avg loss: 8.163475 \n",
            "\n",
            "Epoch 79 \n",
            " ---------------------------------------\n",
            "loss: 0.008383 [   64/ 1020]\n",
            "loss: 0.001314 [  384/ 1020]\n",
            "loss: 0.053346 [  704/ 1020]\n",
            "loss: 0.049029 [  960/ 1020]\n",
            "loss: 0.269270 [   64/ 1020]\n",
            "loss: 0.168796 [  384/ 1020]\n",
            "loss: 0.468503 [  704/ 1020]\n",
            "loss: 0.381559 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.2%, Avg loss: 7.894184 \n",
            "\n",
            "Epoch 80 \n",
            " ---------------------------------------\n",
            "loss: 0.036096 [   64/ 1020]\n",
            "loss: 0.003305 [  384/ 1020]\n",
            "loss: 0.001729 [  704/ 1020]\n",
            "loss: 0.003134 [  960/ 1020]\n",
            "loss: 0.793351 [   64/ 1020]\n",
            "loss: 0.244641 [  384/ 1020]\n",
            "loss: 0.257000 [  704/ 1020]\n",
            "loss: 0.201013 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.1%, Avg loss: 7.644905 \n",
            "\n",
            "Epoch 81 \n",
            " ---------------------------------------\n",
            "loss: 0.001220 [   64/ 1020]\n",
            "loss: 0.009137 [  384/ 1020]\n",
            "loss: 0.000080 [  704/ 1020]\n",
            "loss: 0.017720 [  960/ 1020]\n",
            "loss: 0.322390 [   64/ 1020]\n",
            "loss: 0.326941 [  384/ 1020]\n",
            "loss: 0.269690 [  704/ 1020]\n",
            "loss: 0.352387 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.6%, Avg loss: 7.699780 \n",
            "\n",
            "Epoch 82 \n",
            " ---------------------------------------\n",
            "loss: 0.003846 [   64/ 1020]\n",
            "loss: 0.024477 [  384/ 1020]\n",
            "loss: 0.000635 [  704/ 1020]\n",
            "loss: 0.002908 [  960/ 1020]\n",
            "loss: 0.535250 [   64/ 1020]\n",
            "loss: 0.093733 [  384/ 1020]\n",
            "loss: 0.346196 [  704/ 1020]\n",
            "loss: 0.332585 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.7%, Avg loss: 7.303049 \n",
            "\n",
            "Epoch 83 \n",
            " ---------------------------------------\n",
            "loss: 0.002526 [   64/ 1020]\n",
            "loss: 0.013188 [  384/ 1020]\n",
            "loss: 0.003628 [  704/ 1020]\n",
            "loss: 0.012255 [  960/ 1020]\n",
            "loss: 0.312290 [   64/ 1020]\n",
            "loss: 0.469827 [  384/ 1020]\n",
            "loss: 0.376310 [  704/ 1020]\n",
            "loss: 0.352302 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.1%, Avg loss: 7.539283 \n",
            "\n",
            "Epoch 84 \n",
            " ---------------------------------------\n",
            "loss: 0.003700 [   64/ 1020]\n",
            "loss: 0.086054 [  384/ 1020]\n",
            "loss: 0.002625 [  704/ 1020]\n",
            "loss: 0.011570 [  960/ 1020]\n",
            "loss: 0.341606 [   64/ 1020]\n",
            "loss: 0.322912 [  384/ 1020]\n",
            "loss: 0.314877 [  704/ 1020]\n",
            "loss: 0.141525 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.4%, Avg loss: 7.478143 \n",
            "\n",
            "Epoch 85 \n",
            " ---------------------------------------\n",
            "loss: 0.003073 [   64/ 1020]\n",
            "loss: 0.000883 [  384/ 1020]\n",
            "loss: 0.000446 [  704/ 1020]\n",
            "loss: 0.043985 [  960/ 1020]\n",
            "loss: 0.651011 [   64/ 1020]\n",
            "loss: 0.323124 [  384/ 1020]\n",
            "loss: 0.215822 [  704/ 1020]\n",
            "loss: 0.270226 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.3%, Avg loss: 7.682855 \n",
            "\n",
            "Epoch 86 \n",
            " ---------------------------------------\n",
            "loss: 0.114195 [   64/ 1020]\n",
            "loss: 0.000061 [  384/ 1020]\n",
            "loss: 0.000275 [  704/ 1020]\n",
            "loss: 0.017546 [  960/ 1020]\n",
            "loss: 0.476411 [   64/ 1020]\n",
            "loss: 0.112283 [  384/ 1020]\n",
            "loss: 0.729805 [  704/ 1020]\n",
            "loss: 0.058940 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.6%, Avg loss: 7.451066 \n",
            "\n",
            "Epoch 87 \n",
            " ---------------------------------------\n",
            "loss: 0.003258 [   64/ 1020]\n",
            "loss: 0.002064 [  384/ 1020]\n",
            "loss: 0.002035 [  704/ 1020]\n",
            "loss: 0.001213 [  960/ 1020]\n",
            "loss: 0.446159 [   64/ 1020]\n",
            "loss: 0.344740 [  384/ 1020]\n",
            "loss: 0.211349 [  704/ 1020]\n",
            "loss: 0.168376 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.5%, Avg loss: 7.820799 \n",
            "\n",
            "Epoch 88 \n",
            " ---------------------------------------\n",
            "loss: 0.000522 [   64/ 1020]\n",
            "loss: 0.000448 [  384/ 1020]\n",
            "loss: 0.000733 [  704/ 1020]\n",
            "loss: 0.027962 [  960/ 1020]\n",
            "loss: 0.475619 [   64/ 1020]\n",
            "loss: 0.211867 [  384/ 1020]\n",
            "loss: 0.171704 [  704/ 1020]\n",
            "loss: 0.299223 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.6%, Avg loss: 8.096844 \n",
            "\n",
            "Epoch 89 \n",
            " ---------------------------------------\n",
            "loss: 0.013236 [   64/ 1020]\n",
            "loss: 0.002485 [  384/ 1020]\n",
            "loss: 0.000090 [  704/ 1020]\n",
            "loss: 0.000713 [  960/ 1020]\n",
            "loss: 0.534376 [   64/ 1020]\n",
            "loss: 0.152592 [  384/ 1020]\n",
            "loss: 0.207318 [  704/ 1020]\n",
            "loss: 0.051957 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.7%, Avg loss: 7.949655 \n",
            "\n",
            "Epoch 90 \n",
            " ---------------------------------------\n",
            "loss: 0.055985 [   64/ 1020]\n",
            "loss: 0.002425 [  384/ 1020]\n",
            "loss: 0.003500 [  704/ 1020]\n",
            "loss: 0.000168 [  960/ 1020]\n",
            "loss: 0.469784 [   64/ 1020]\n",
            "loss: 0.309505 [  384/ 1020]\n",
            "loss: 0.442026 [  704/ 1020]\n",
            "loss: 0.172175 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.4%, Avg loss: 8.226198 \n",
            "\n",
            "Epoch 91 \n",
            " ---------------------------------------\n",
            "loss: 0.002770 [   64/ 1020]\n",
            "loss: 0.000346 [  384/ 1020]\n",
            "loss: 0.052065 [  704/ 1020]\n",
            "loss: 0.000155 [  960/ 1020]\n",
            "loss: 0.237799 [   64/ 1020]\n",
            "loss: 0.117108 [  384/ 1020]\n",
            "loss: 0.122413 [  704/ 1020]\n",
            "loss: 0.099429 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.4%, Avg loss: 7.638011 \n",
            "\n",
            "Epoch 92 \n",
            " ---------------------------------------\n",
            "loss: 0.033004 [   64/ 1020]\n",
            "loss: 0.032628 [  384/ 1020]\n",
            "loss: 0.026686 [  704/ 1020]\n",
            "loss: 0.000600 [  960/ 1020]\n",
            "loss: 0.233328 [   64/ 1020]\n",
            "loss: 0.080643 [  384/ 1020]\n",
            "loss: 0.103338 [  704/ 1020]\n",
            "loss: 0.175197 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.5%, Avg loss: 8.130730 \n",
            "\n",
            "Epoch 93 \n",
            " ---------------------------------------\n",
            "loss: 0.000258 [   64/ 1020]\n",
            "loss: 0.050248 [  384/ 1020]\n",
            "loss: 0.000318 [  704/ 1020]\n",
            "loss: 0.000848 [  960/ 1020]\n",
            "loss: 0.422943 [   64/ 1020]\n",
            "loss: 0.123906 [  384/ 1020]\n",
            "loss: 0.167169 [  704/ 1020]\n",
            "loss: 0.556105 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.5%, Avg loss: 9.884171 \n",
            "\n",
            "Epoch 94 \n",
            " ---------------------------------------\n",
            "loss: 0.003556 [   64/ 1020]\n",
            "loss: 0.000487 [  384/ 1020]\n",
            "loss: 0.210683 [  704/ 1020]\n",
            "loss: 0.009209 [  960/ 1020]\n",
            "loss: 0.463660 [   64/ 1020]\n",
            "loss: 0.326490 [  384/ 1020]\n",
            "loss: 0.445570 [  704/ 1020]\n",
            "loss: 0.526041 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.2%, Avg loss: 8.689213 \n",
            "\n",
            "Epoch 95 \n",
            " ---------------------------------------\n",
            "loss: 0.012493 [   64/ 1020]\n",
            "loss: 0.076687 [  384/ 1020]\n",
            "loss: 0.001881 [  704/ 1020]\n",
            "loss: 0.008578 [  960/ 1020]\n",
            "loss: 0.211764 [   64/ 1020]\n",
            "loss: 0.260999 [  384/ 1020]\n",
            "loss: 0.534804 [  704/ 1020]\n",
            "loss: 0.433083 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.5%, Avg loss: 8.529108 \n",
            "\n",
            "Epoch 96 \n",
            " ---------------------------------------\n",
            "loss: 0.000263 [   64/ 1020]\n",
            "loss: 0.114804 [  384/ 1020]\n",
            "loss: 0.003719 [  704/ 1020]\n",
            "loss: 0.005661 [  960/ 1020]\n",
            "loss: 0.782295 [   64/ 1020]\n",
            "loss: 0.157273 [  384/ 1020]\n",
            "loss: 0.221030 [  704/ 1020]\n",
            "loss: 0.299726 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.0%, Avg loss: 8.463274 \n",
            "\n",
            "Epoch 97 \n",
            " ---------------------------------------\n",
            "loss: 0.000163 [   64/ 1020]\n",
            "loss: 0.020038 [  384/ 1020]\n",
            "loss: 0.000070 [  704/ 1020]\n",
            "loss: 0.049464 [  960/ 1020]\n",
            "loss: 0.278748 [   64/ 1020]\n",
            "loss: 0.337383 [  384/ 1020]\n",
            "loss: 0.152912 [  704/ 1020]\n",
            "loss: 0.250121 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.1%, Avg loss: 8.044529 \n",
            "\n",
            "Epoch 98 \n",
            " ---------------------------------------\n",
            "loss: 0.000665 [   64/ 1020]\n",
            "loss: 0.008437 [  384/ 1020]\n",
            "loss: 0.042281 [  704/ 1020]\n",
            "loss: 0.001254 [  960/ 1020]\n",
            "loss: 0.685857 [   64/ 1020]\n",
            "loss: 0.371013 [  384/ 1020]\n",
            "loss: 0.351586 [  704/ 1020]\n",
            "loss: 0.298857 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.1%, Avg loss: 8.603525 \n",
            "\n",
            "Epoch 99 \n",
            " ---------------------------------------\n",
            "loss: 0.000864 [   64/ 1020]\n",
            "loss: 0.000017 [  384/ 1020]\n",
            "loss: 0.001263 [  704/ 1020]\n",
            "loss: 0.000524 [  960/ 1020]\n",
            "loss: 0.285734 [   64/ 1020]\n",
            "loss: 0.305686 [  384/ 1020]\n",
            "loss: 0.294541 [  704/ 1020]\n",
            "loss: 0.225328 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 39.0%, Avg loss: 7.851805 \n",
            "\n",
            "Epoch 100 \n",
            " ---------------------------------------\n",
            "loss: 0.000344 [   64/ 1020]\n",
            "loss: 0.013294 [  384/ 1020]\n",
            "loss: 0.000476 [  704/ 1020]\n",
            "loss: 0.045049 [  960/ 1020]\n",
            "loss: 0.280895 [   64/ 1020]\n",
            "loss: 0.360417 [  384/ 1020]\n",
            "loss: 0.214572 [  704/ 1020]\n",
            "loss: 0.179984 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.8%, Avg loss: 8.184532 \n",
            "\n",
            "Testing -----------------------\n",
            "Test Error: \n",
            " Accuracy: 33.0%, Avg loss: 8.948302 \n",
            "\n",
            "Done!!!!\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1} \\n ---------------------------------------\")\n",
        "\n",
        "  #train on original data\n",
        "  train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "\n",
        "  #train on augmented data\n",
        "  training_data_augment = datasets.Flowers102(root=\"dataset\", split=\"train\", transform=train_transform_augment, download=True)\n",
        "  train_dataloader = DataLoader(training_data_augment, batch_size = batch_size, shuffle=True)\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "\n",
        "  #testing on evaluation data\n",
        "  test(val_dataloader, model, loss_fn)\n",
        "\n",
        "print(\"Testing -----------------------\")\n",
        "test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!!!!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNwycQE0g0QKvJ1lRg/YAL3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}