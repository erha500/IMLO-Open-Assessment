{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erha500/IMLO-Open-Assessment/blob/main/IMLO_Open_Assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "MGJhK0Wy6U2-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as T\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1FLWsWbK-ylG"
      },
      "outputs": [],
      "source": [
        "train_transform = v2.Compose([\n",
        "    v2.RandomResizedCrop([320,320], scale=[0.25,1.0], ratio=[1.0,1.0]),\n",
        "    #v2.RandomPerspective(),\n",
        "    v2.RandomHorizontalFlip(0.5),\n",
        "    #v2.RandomRotation(180),\n",
        "    #v2.RandomVerticalFlip(0.5)\n",
        "    v2.ToTensor(),\n",
        "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = v2.Compose([\n",
        "  v2.Resize([320,320]),\n",
        "  v2.ToTensor(),\n",
        "  v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWVmTrcs9QGM"
      },
      "source": [
        "Downloading Flowers102 dataset from datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "2AG1ERmI9WXU"
      },
      "outputs": [],
      "source": [
        "training_data = datasets.Flowers102(root=\"dataset\", split=\"train\", transform=train_transform, download=True)\n",
        "\n",
        "test_data = datasets.Flowers102(root=\"dataset\", split=\"val\", transform=test_transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "EiOOyavq-T-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f13940-66b2-4920-b693-6aed7f3fa88d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 3, 320, 320])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "#Create data loaders\n",
        "train_dataloader = DataLoader(training_data, batch_size = batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "  print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "3fL6F9TLEdDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f95c5c4-62f8-4be8-d947-d8420cd0841f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU()\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU()\n",
            "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU()\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): Flatten(start_dim=1, end_dim=-1)\n",
            "    (17): Linear(in_features=51200, out_features=1024, bias=True)\n",
            "    (18): ReLU()\n",
            "    (19): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (20): ReLU()\n",
            "    (21): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (22): ReLU()\n",
            "    (23): Linear(in_features=256, out_features=102, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "#Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "      nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.BatchNorm2d(16),\n",
        "      nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.BatchNorm2d(32),\n",
        "      nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(128 * 20 * 20, 1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(1024, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512,256),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(256,102)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "9IvJsfvwE0VG"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "o4bMoWUAE1kO"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    #Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 5 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "y4Mf49itE3A-"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct) :>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Xr7VD7E3E5y1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5204f0b-f6cc-43c4-e5f9-e53bb55f9c5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            " ---------------------------------------\n",
            "loss: 4.634152 [   64/ 1020]\n",
            "loss: 4.822711 [  384/ 1020]\n",
            "loss: 4.264150 [  704/ 1020]\n",
            "loss: 4.292282 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 2.3%, Avg loss: 4.473249 \n",
            "\n",
            "Epoch 2 \n",
            " ---------------------------------------\n",
            "loss: 4.062533 [   64/ 1020]\n",
            "loss: 3.786417 [  384/ 1020]\n",
            "loss: 3.726582 [  704/ 1020]\n",
            "loss: 3.905186 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 9.5%, Avg loss: 3.919056 \n",
            "\n",
            "Epoch 3 \n",
            " ---------------------------------------\n",
            "loss: 3.304902 [   64/ 1020]\n",
            "loss: 3.436098 [  384/ 1020]\n",
            "loss: 3.453639 [  704/ 1020]\n",
            "loss: 3.565342 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 16.6%, Avg loss: 3.512873 \n",
            "\n",
            "Epoch 4 \n",
            " ---------------------------------------\n",
            "loss: 3.067523 [   64/ 1020]\n",
            "loss: 3.564644 [  384/ 1020]\n",
            "loss: 3.166676 [  704/ 1020]\n",
            "loss: 2.968545 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 17.4%, Avg loss: 3.514882 \n",
            "\n",
            "Epoch 5 \n",
            " ---------------------------------------\n",
            "loss: 3.025302 [   64/ 1020]\n",
            "loss: 3.039860 [  384/ 1020]\n",
            "loss: 2.766489 [  704/ 1020]\n",
            "loss: 3.700099 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 15.7%, Avg loss: 3.520667 \n",
            "\n",
            "Epoch 6 \n",
            " ---------------------------------------\n",
            "loss: 2.723758 [   64/ 1020]\n",
            "loss: 3.056973 [  384/ 1020]\n",
            "loss: 2.815131 [  704/ 1020]\n",
            "loss: 3.124548 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 19.2%, Avg loss: 3.336083 \n",
            "\n",
            "Epoch 7 \n",
            " ---------------------------------------\n",
            "loss: 2.621557 [   64/ 1020]\n",
            "loss: 2.791429 [  384/ 1020]\n",
            "loss: 2.783309 [  704/ 1020]\n",
            "loss: 2.907430 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 19.3%, Avg loss: 3.282802 \n",
            "\n",
            "Epoch 8 \n",
            " ---------------------------------------\n",
            "loss: 2.378330 [   64/ 1020]\n",
            "loss: 2.363801 [  384/ 1020]\n",
            "loss: 2.922789 [  704/ 1020]\n",
            "loss: 2.933924 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 22.5%, Avg loss: 3.149317 \n",
            "\n",
            "Epoch 9 \n",
            " ---------------------------------------\n",
            "loss: 2.414158 [   64/ 1020]\n",
            "loss: 2.738576 [  384/ 1020]\n",
            "loss: 3.034477 [  704/ 1020]\n",
            "loss: 2.873005 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 18.8%, Avg loss: 3.361790 \n",
            "\n",
            "Epoch 10 \n",
            " ---------------------------------------\n",
            "loss: 2.347857 [   64/ 1020]\n",
            "loss: 2.351289 [  384/ 1020]\n",
            "loss: 2.871994 [  704/ 1020]\n",
            "loss: 2.906773 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 21.7%, Avg loss: 3.312375 \n",
            "\n",
            "Epoch 11 \n",
            " ---------------------------------------\n",
            "loss: 2.340400 [   64/ 1020]\n",
            "loss: 2.583712 [  384/ 1020]\n",
            "loss: 2.714436 [  704/ 1020]\n",
            "loss: 2.761391 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 18.7%, Avg loss: 3.356770 \n",
            "\n",
            "Epoch 12 \n",
            " ---------------------------------------\n",
            "loss: 2.619948 [   64/ 1020]\n",
            "loss: 2.802809 [  384/ 1020]\n",
            "loss: 3.034954 [  704/ 1020]\n",
            "loss: 3.109191 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 19.2%, Avg loss: 3.386143 \n",
            "\n",
            "Epoch 13 \n",
            " ---------------------------------------\n",
            "loss: 2.346298 [   64/ 1020]\n",
            "loss: 2.246225 [  384/ 1020]\n",
            "loss: 2.744398 [  704/ 1020]\n",
            "loss: 2.137524 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 21.5%, Avg loss: 3.387524 \n",
            "\n",
            "Epoch 14 \n",
            " ---------------------------------------\n",
            "loss: 2.260620 [   64/ 1020]\n",
            "loss: 2.500699 [  384/ 1020]\n",
            "loss: 2.382915 [  704/ 1020]\n",
            "loss: 2.922654 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 24.2%, Avg loss: 3.187213 \n",
            "\n",
            "Epoch 15 \n",
            " ---------------------------------------\n",
            "loss: 2.310730 [   64/ 1020]\n",
            "loss: 2.522889 [  384/ 1020]\n",
            "loss: 2.478387 [  704/ 1020]\n",
            "loss: 2.715459 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.6%, Avg loss: 3.263739 \n",
            "\n",
            "Epoch 16 \n",
            " ---------------------------------------\n",
            "loss: 2.478163 [   64/ 1020]\n",
            "loss: 2.563474 [  384/ 1020]\n",
            "loss: 1.971338 [  704/ 1020]\n",
            "loss: 2.663759 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 22.9%, Avg loss: 3.246177 \n",
            "\n",
            "Epoch 17 \n",
            " ---------------------------------------\n",
            "loss: 2.293597 [   64/ 1020]\n",
            "loss: 2.300969 [  384/ 1020]\n",
            "loss: 2.853021 [  704/ 1020]\n",
            "loss: 2.543379 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 24.9%, Avg loss: 3.215448 \n",
            "\n",
            "Epoch 18 \n",
            " ---------------------------------------\n",
            "loss: 2.060884 [   64/ 1020]\n",
            "loss: 2.590083 [  384/ 1020]\n",
            "loss: 2.142019 [  704/ 1020]\n",
            "loss: 2.494899 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 24.8%, Avg loss: 3.228691 \n",
            "\n",
            "Epoch 19 \n",
            " ---------------------------------------\n",
            "loss: 1.964578 [   64/ 1020]\n",
            "loss: 2.301806 [  384/ 1020]\n",
            "loss: 2.071219 [  704/ 1020]\n",
            "loss: 2.546149 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 22.9%, Avg loss: 3.322926 \n",
            "\n",
            "Epoch 20 \n",
            " ---------------------------------------\n",
            "loss: 2.212879 [   64/ 1020]\n",
            "loss: 2.353687 [  384/ 1020]\n",
            "loss: 2.251388 [  704/ 1020]\n",
            "loss: 2.189492 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.8%, Avg loss: 3.189319 \n",
            "\n",
            "Epoch 21 \n",
            " ---------------------------------------\n",
            "loss: 1.795152 [   64/ 1020]\n",
            "loss: 2.022092 [  384/ 1020]\n",
            "loss: 2.147651 [  704/ 1020]\n",
            "loss: 2.447618 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 24.8%, Avg loss: 3.219303 \n",
            "\n",
            "Epoch 22 \n",
            " ---------------------------------------\n",
            "loss: 1.934442 [   64/ 1020]\n",
            "loss: 2.037141 [  384/ 1020]\n",
            "loss: 2.280462 [  704/ 1020]\n",
            "loss: 2.347756 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.2%, Avg loss: 3.175015 \n",
            "\n",
            "Epoch 23 \n",
            " ---------------------------------------\n",
            "loss: 1.878431 [   64/ 1020]\n",
            "loss: 1.921878 [  384/ 1020]\n",
            "loss: 2.521842 [  704/ 1020]\n",
            "loss: 2.247842 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 24.3%, Avg loss: 3.301888 \n",
            "\n",
            "Epoch 24 \n",
            " ---------------------------------------\n",
            "loss: 1.877236 [   64/ 1020]\n",
            "loss: 2.157757 [  384/ 1020]\n",
            "loss: 2.284708 [  704/ 1020]\n",
            "loss: 2.260734 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.6%, Avg loss: 3.345776 \n",
            "\n",
            "Epoch 25 \n",
            " ---------------------------------------\n",
            "loss: 1.873420 [   64/ 1020]\n",
            "loss: 2.042396 [  384/ 1020]\n",
            "loss: 2.277590 [  704/ 1020]\n",
            "loss: 2.415020 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.4%, Avg loss: 3.088271 \n",
            "\n",
            "Epoch 26 \n",
            " ---------------------------------------\n",
            "loss: 1.813087 [   64/ 1020]\n",
            "loss: 1.936289 [  384/ 1020]\n",
            "loss: 1.935577 [  704/ 1020]\n",
            "loss: 2.401207 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.0%, Avg loss: 3.218507 \n",
            "\n",
            "Epoch 27 \n",
            " ---------------------------------------\n",
            "loss: 1.831630 [   64/ 1020]\n",
            "loss: 1.729133 [  384/ 1020]\n",
            "loss: 2.260319 [  704/ 1020]\n",
            "loss: 2.208135 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.6%, Avg loss: 3.236722 \n",
            "\n",
            "Epoch 28 \n",
            " ---------------------------------------\n",
            "loss: 1.913339 [   64/ 1020]\n",
            "loss: 1.770735 [  384/ 1020]\n",
            "loss: 2.167030 [  704/ 1020]\n",
            "loss: 2.113235 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 20.1%, Avg loss: 3.645462 \n",
            "\n",
            "Epoch 29 \n",
            " ---------------------------------------\n",
            "loss: 2.202585 [   64/ 1020]\n",
            "loss: 1.833158 [  384/ 1020]\n",
            "loss: 2.072565 [  704/ 1020]\n",
            "loss: 1.954006 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.5%, Avg loss: 3.371988 \n",
            "\n",
            "Epoch 30 \n",
            " ---------------------------------------\n",
            "loss: 1.703410 [   64/ 1020]\n",
            "loss: 2.039910 [  384/ 1020]\n",
            "loss: 2.176844 [  704/ 1020]\n",
            "loss: 2.248094 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.5%, Avg loss: 3.160714 \n",
            "\n",
            "Epoch 31 \n",
            " ---------------------------------------\n",
            "loss: 1.400576 [   64/ 1020]\n",
            "loss: 1.577390 [  384/ 1020]\n",
            "loss: 1.725008 [  704/ 1020]\n",
            "loss: 1.829785 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.9%, Avg loss: 3.149810 \n",
            "\n",
            "Epoch 32 \n",
            " ---------------------------------------\n",
            "loss: 1.561580 [   64/ 1020]\n",
            "loss: 1.829645 [  384/ 1020]\n",
            "loss: 1.760338 [  704/ 1020]\n",
            "loss: 1.871599 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.3%, Avg loss: 3.257553 \n",
            "\n",
            "Epoch 33 \n",
            " ---------------------------------------\n",
            "loss: 1.588781 [   64/ 1020]\n",
            "loss: 1.702753 [  384/ 1020]\n",
            "loss: 2.247144 [  704/ 1020]\n",
            "loss: 1.832875 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.0%, Avg loss: 3.200947 \n",
            "\n",
            "Epoch 34 \n",
            " ---------------------------------------\n",
            "loss: 1.776331 [   64/ 1020]\n",
            "loss: 1.600778 [  384/ 1020]\n",
            "loss: 1.682658 [  704/ 1020]\n",
            "loss: 1.705609 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.3%, Avg loss: 3.295127 \n",
            "\n",
            "Epoch 35 \n",
            " ---------------------------------------\n",
            "loss: 1.695480 [   64/ 1020]\n",
            "loss: 1.592838 [  384/ 1020]\n",
            "loss: 2.048744 [  704/ 1020]\n",
            "loss: 1.996622 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.1%, Avg loss: 3.388696 \n",
            "\n",
            "Epoch 36 \n",
            " ---------------------------------------\n",
            "loss: 1.976052 [   64/ 1020]\n",
            "loss: 1.648510 [  384/ 1020]\n",
            "loss: 2.235746 [  704/ 1020]\n",
            "loss: 1.913925 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.0%, Avg loss: 3.409115 \n",
            "\n",
            "Epoch 37 \n",
            " ---------------------------------------\n",
            "loss: 1.574162 [   64/ 1020]\n",
            "loss: 1.794101 [  384/ 1020]\n",
            "loss: 1.534542 [  704/ 1020]\n",
            "loss: 1.758033 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.2%, Avg loss: 3.302891 \n",
            "\n",
            "Epoch 38 \n",
            " ---------------------------------------\n",
            "loss: 1.512902 [   64/ 1020]\n",
            "loss: 1.728028 [  384/ 1020]\n",
            "loss: 1.813967 [  704/ 1020]\n",
            "loss: 1.541674 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.2%, Avg loss: 3.124326 \n",
            "\n",
            "Epoch 39 \n",
            " ---------------------------------------\n",
            "loss: 1.536732 [   64/ 1020]\n",
            "loss: 1.540938 [  384/ 1020]\n",
            "loss: 1.539531 [  704/ 1020]\n",
            "loss: 1.856581 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.0%, Avg loss: 3.276885 \n",
            "\n",
            "Epoch 40 \n",
            " ---------------------------------------\n",
            "loss: 2.048285 [   64/ 1020]\n",
            "loss: 1.819800 [  384/ 1020]\n",
            "loss: 1.758215 [  704/ 1020]\n",
            "loss: 1.825059 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.4%, Avg loss: 3.468036 \n",
            "\n",
            "Epoch 41 \n",
            " ---------------------------------------\n",
            "loss: 1.379902 [   64/ 1020]\n",
            "loss: 1.691256 [  384/ 1020]\n",
            "loss: 1.760134 [  704/ 1020]\n",
            "loss: 1.768535 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.2%, Avg loss: 3.299394 \n",
            "\n",
            "Epoch 42 \n",
            " ---------------------------------------\n",
            "loss: 1.371933 [   64/ 1020]\n",
            "loss: 1.329655 [  384/ 1020]\n",
            "loss: 1.652139 [  704/ 1020]\n",
            "loss: 1.724783 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.5%, Avg loss: 3.302378 \n",
            "\n",
            "Epoch 43 \n",
            " ---------------------------------------\n",
            "loss: 1.541545 [   64/ 1020]\n",
            "loss: 1.546658 [  384/ 1020]\n",
            "loss: 1.729333 [  704/ 1020]\n",
            "loss: 1.635198 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.4%, Avg loss: 3.366586 \n",
            "\n",
            "Epoch 44 \n",
            " ---------------------------------------\n",
            "loss: 1.784699 [   64/ 1020]\n",
            "loss: 1.596672 [  384/ 1020]\n",
            "loss: 1.405550 [  704/ 1020]\n",
            "loss: 1.999896 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.0%, Avg loss: 3.404668 \n",
            "\n",
            "Epoch 45 \n",
            " ---------------------------------------\n",
            "loss: 1.105875 [   64/ 1020]\n",
            "loss: 1.772712 [  384/ 1020]\n",
            "loss: 1.776118 [  704/ 1020]\n",
            "loss: 1.890135 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.1%, Avg loss: 3.399856 \n",
            "\n",
            "Epoch 46 \n",
            " ---------------------------------------\n",
            "loss: 1.639970 [   64/ 1020]\n",
            "loss: 1.520174 [  384/ 1020]\n",
            "loss: 1.521437 [  704/ 1020]\n",
            "loss: 1.759132 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.0%, Avg loss: 3.293470 \n",
            "\n",
            "Epoch 47 \n",
            " ---------------------------------------\n",
            "loss: 1.193952 [   64/ 1020]\n",
            "loss: 1.554486 [  384/ 1020]\n",
            "loss: 1.309598 [  704/ 1020]\n",
            "loss: 1.637302 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.4%, Avg loss: 3.174082 \n",
            "\n",
            "Epoch 48 \n",
            " ---------------------------------------\n",
            "loss: 1.292423 [   64/ 1020]\n",
            "loss: 1.778556 [  384/ 1020]\n",
            "loss: 1.658783 [  704/ 1020]\n",
            "loss: 1.577506 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.9%, Avg loss: 3.395454 \n",
            "\n",
            "Epoch 49 \n",
            " ---------------------------------------\n",
            "loss: 1.399117 [   64/ 1020]\n",
            "loss: 1.446733 [  384/ 1020]\n",
            "loss: 1.914062 [  704/ 1020]\n",
            "loss: 1.829189 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.6%, Avg loss: 3.314851 \n",
            "\n",
            "Epoch 50 \n",
            " ---------------------------------------\n",
            "loss: 1.652260 [   64/ 1020]\n",
            "loss: 1.207839 [  384/ 1020]\n",
            "loss: 1.701310 [  704/ 1020]\n",
            "loss: 1.370703 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.0%, Avg loss: 3.265635 \n",
            "\n",
            "Epoch 51 \n",
            " ---------------------------------------\n",
            "loss: 1.269928 [   64/ 1020]\n",
            "loss: 1.378724 [  384/ 1020]\n",
            "loss: 1.585876 [  704/ 1020]\n",
            "loss: 1.816048 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.6%, Avg loss: 3.592347 \n",
            "\n",
            "Epoch 52 \n",
            " ---------------------------------------\n",
            "loss: 1.543775 [   64/ 1020]\n",
            "loss: 1.400444 [  384/ 1020]\n",
            "loss: 1.504145 [  704/ 1020]\n",
            "loss: 1.455122 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.6%, Avg loss: 3.352659 \n",
            "\n",
            "Epoch 53 \n",
            " ---------------------------------------\n",
            "loss: 1.228371 [   64/ 1020]\n",
            "loss: 1.169201 [  384/ 1020]\n",
            "loss: 1.488673 [  704/ 1020]\n",
            "loss: 1.607589 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.1%, Avg loss: 3.212962 \n",
            "\n",
            "Epoch 54 \n",
            " ---------------------------------------\n",
            "loss: 1.387878 [   64/ 1020]\n",
            "loss: 1.257159 [  384/ 1020]\n",
            "loss: 1.322016 [  704/ 1020]\n",
            "loss: 1.511622 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.9%, Avg loss: 3.432374 \n",
            "\n",
            "Epoch 55 \n",
            " ---------------------------------------\n",
            "loss: 1.145889 [   64/ 1020]\n",
            "loss: 1.314116 [  384/ 1020]\n",
            "loss: 1.651151 [  704/ 1020]\n",
            "loss: 1.513438 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.2%, Avg loss: 3.431441 \n",
            "\n",
            "Epoch 56 \n",
            " ---------------------------------------\n",
            "loss: 1.468367 [   64/ 1020]\n",
            "loss: 1.490014 [  384/ 1020]\n",
            "loss: 1.326903 [  704/ 1020]\n",
            "loss: 1.716152 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.7%, Avg loss: 3.715775 \n",
            "\n",
            "Epoch 57 \n",
            " ---------------------------------------\n",
            "loss: 1.549231 [   64/ 1020]\n",
            "loss: 1.279264 [  384/ 1020]\n",
            "loss: 1.483889 [  704/ 1020]\n",
            "loss: 1.441709 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.1%, Avg loss: 3.170223 \n",
            "\n",
            "Epoch 58 \n",
            " ---------------------------------------\n",
            "loss: 1.276492 [   64/ 1020]\n",
            "loss: 1.170927 [  384/ 1020]\n",
            "loss: 1.222854 [  704/ 1020]\n",
            "loss: 1.410282 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.8%, Avg loss: 3.206848 \n",
            "\n",
            "Epoch 59 \n",
            " ---------------------------------------\n",
            "loss: 1.223106 [   64/ 1020]\n",
            "loss: 1.572434 [  384/ 1020]\n",
            "loss: 1.300941 [  704/ 1020]\n",
            "loss: 1.499647 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.6%, Avg loss: 3.587557 \n",
            "\n",
            "Epoch 60 \n",
            " ---------------------------------------\n",
            "loss: 1.246111 [   64/ 1020]\n",
            "loss: 1.472497 [  384/ 1020]\n",
            "loss: 1.189160 [  704/ 1020]\n",
            "loss: 1.192431 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.1%, Avg loss: 3.429469 \n",
            "\n",
            "Epoch 61 \n",
            " ---------------------------------------\n",
            "loss: 1.363922 [   64/ 1020]\n",
            "loss: 0.994683 [  384/ 1020]\n",
            "loss: 1.364730 [  704/ 1020]\n",
            "loss: 1.448108 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.5%, Avg loss: 3.252716 \n",
            "\n",
            "Epoch 62 \n",
            " ---------------------------------------\n",
            "loss: 1.499638 [   64/ 1020]\n",
            "loss: 0.890083 [  384/ 1020]\n",
            "loss: 1.149296 [  704/ 1020]\n",
            "loss: 1.327599 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.4%, Avg loss: 3.258414 \n",
            "\n",
            "Epoch 63 \n",
            " ---------------------------------------\n",
            "loss: 1.071859 [   64/ 1020]\n",
            "loss: 1.316201 [  384/ 1020]\n",
            "loss: 1.081495 [  704/ 1020]\n",
            "loss: 1.496658 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.0%, Avg loss: 3.519114 \n",
            "\n",
            "Epoch 64 \n",
            " ---------------------------------------\n",
            "loss: 1.312874 [   64/ 1020]\n",
            "loss: 1.164210 [  384/ 1020]\n",
            "loss: 1.083268 [  704/ 1020]\n",
            "loss: 1.259389 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.9%, Avg loss: 3.415035 \n",
            "\n",
            "Epoch 65 \n",
            " ---------------------------------------\n",
            "loss: 1.116471 [   64/ 1020]\n",
            "loss: 0.971813 [  384/ 1020]\n",
            "loss: 1.319751 [  704/ 1020]\n",
            "loss: 1.364122 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.8%, Avg loss: 3.577380 \n",
            "\n",
            "Epoch 66 \n",
            " ---------------------------------------\n",
            "loss: 1.366721 [   64/ 1020]\n",
            "loss: 1.126907 [  384/ 1020]\n",
            "loss: 1.650955 [  704/ 1020]\n",
            "loss: 1.336089 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.6%, Avg loss: 3.659300 \n",
            "\n",
            "Epoch 67 \n",
            " ---------------------------------------\n",
            "loss: 1.073220 [   64/ 1020]\n",
            "loss: 1.172730 [  384/ 1020]\n",
            "loss: 1.206199 [  704/ 1020]\n",
            "loss: 1.508952 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.9%, Avg loss: 3.324095 \n",
            "\n",
            "Epoch 68 \n",
            " ---------------------------------------\n",
            "loss: 0.947762 [   64/ 1020]\n",
            "loss: 1.030219 [  384/ 1020]\n",
            "loss: 1.219481 [  704/ 1020]\n",
            "loss: 1.079265 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.0%, Avg loss: 3.361340 \n",
            "\n",
            "Epoch 69 \n",
            " ---------------------------------------\n",
            "loss: 0.997771 [   64/ 1020]\n",
            "loss: 1.271479 [  384/ 1020]\n",
            "loss: 1.205745 [  704/ 1020]\n",
            "loss: 1.285988 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.4%, Avg loss: 3.380840 \n",
            "\n",
            "Epoch 70 \n",
            " ---------------------------------------\n",
            "loss: 1.111598 [   64/ 1020]\n",
            "loss: 1.257483 [  384/ 1020]\n",
            "loss: 1.194439 [  704/ 1020]\n",
            "loss: 1.380043 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.0%, Avg loss: 3.478428 \n",
            "\n",
            "Epoch 71 \n",
            " ---------------------------------------\n",
            "loss: 0.786896 [   64/ 1020]\n",
            "loss: 1.197230 [  384/ 1020]\n",
            "loss: 0.939001 [  704/ 1020]\n",
            "loss: 1.074740 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.5%, Avg loss: 3.519881 \n",
            "\n",
            "Epoch 72 \n",
            " ---------------------------------------\n",
            "loss: 1.057527 [   64/ 1020]\n",
            "loss: 0.872779 [  384/ 1020]\n",
            "loss: 1.464995 [  704/ 1020]\n",
            "loss: 1.389259 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.3%, Avg loss: 3.359614 \n",
            "\n",
            "Epoch 73 \n",
            " ---------------------------------------\n",
            "loss: 1.024060 [   64/ 1020]\n",
            "loss: 1.126385 [  384/ 1020]\n",
            "loss: 1.358100 [  704/ 1020]\n",
            "loss: 1.344311 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.1%, Avg loss: 3.731592 \n",
            "\n",
            "Epoch 74 \n",
            " ---------------------------------------\n",
            "loss: 0.914000 [   64/ 1020]\n",
            "loss: 1.157292 [  384/ 1020]\n",
            "loss: 1.220134 [  704/ 1020]\n",
            "loss: 1.410984 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.5%, Avg loss: 3.408885 \n",
            "\n",
            "Epoch 75 \n",
            " ---------------------------------------\n",
            "loss: 1.231334 [   64/ 1020]\n",
            "loss: 1.037801 [  384/ 1020]\n",
            "loss: 1.236589 [  704/ 1020]\n",
            "loss: 1.067728 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.4%, Avg loss: 3.452996 \n",
            "\n",
            "Epoch 76 \n",
            " ---------------------------------------\n",
            "loss: 1.086846 [   64/ 1020]\n",
            "loss: 1.003538 [  384/ 1020]\n",
            "loss: 1.211380 [  704/ 1020]\n",
            "loss: 1.047470 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.0%, Avg loss: 3.572444 \n",
            "\n",
            "Epoch 77 \n",
            " ---------------------------------------\n",
            "loss: 0.795974 [   64/ 1020]\n",
            "loss: 1.070383 [  384/ 1020]\n",
            "loss: 1.060164 [  704/ 1020]\n",
            "loss: 1.158917 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.0%, Avg loss: 3.338340 \n",
            "\n",
            "Epoch 78 \n",
            " ---------------------------------------\n",
            "loss: 0.841730 [   64/ 1020]\n",
            "loss: 1.031907 [  384/ 1020]\n",
            "loss: 0.746542 [  704/ 1020]\n",
            "loss: 1.157590 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.4%, Avg loss: 3.644831 \n",
            "\n",
            "Epoch 79 \n",
            " ---------------------------------------\n",
            "loss: 0.864851 [   64/ 1020]\n",
            "loss: 1.062626 [  384/ 1020]\n",
            "loss: 0.837337 [  704/ 1020]\n",
            "loss: 1.371669 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.1%, Avg loss: 3.700662 \n",
            "\n",
            "Epoch 80 \n",
            " ---------------------------------------\n",
            "loss: 0.908948 [   64/ 1020]\n",
            "loss: 1.316047 [  384/ 1020]\n",
            "loss: 1.189600 [  704/ 1020]\n",
            "loss: 1.065860 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.1%, Avg loss: 3.426429 \n",
            "\n",
            "Epoch 81 \n",
            " ---------------------------------------\n",
            "loss: 1.336268 [   64/ 1020]\n",
            "loss: 1.237244 [  384/ 1020]\n",
            "loss: 1.182328 [  704/ 1020]\n",
            "loss: 1.426423 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.9%, Avg loss: 3.498240 \n",
            "\n",
            "Epoch 82 \n",
            " ---------------------------------------\n",
            "loss: 1.064940 [   64/ 1020]\n",
            "loss: 1.140375 [  384/ 1020]\n",
            "loss: 1.606018 [  704/ 1020]\n",
            "loss: 1.027207 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.6%, Avg loss: 3.588627 \n",
            "\n",
            "Epoch 83 \n",
            " ---------------------------------------\n",
            "loss: 1.148660 [   64/ 1020]\n",
            "loss: 1.143771 [  384/ 1020]\n",
            "loss: 1.122913 [  704/ 1020]\n",
            "loss: 0.875977 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.0%, Avg loss: 3.387674 \n",
            "\n",
            "Epoch 84 \n",
            " ---------------------------------------\n",
            "loss: 0.636555 [   64/ 1020]\n",
            "loss: 1.010370 [  384/ 1020]\n",
            "loss: 1.091902 [  704/ 1020]\n",
            "loss: 1.009363 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.5%, Avg loss: 3.461396 \n",
            "\n",
            "Epoch 85 \n",
            " ---------------------------------------\n",
            "loss: 0.950167 [   64/ 1020]\n",
            "loss: 0.949761 [  384/ 1020]\n",
            "loss: 1.066183 [  704/ 1020]\n",
            "loss: 0.877174 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.7%, Avg loss: 3.301532 \n",
            "\n",
            "Epoch 86 \n",
            " ---------------------------------------\n",
            "loss: 0.766127 [   64/ 1020]\n",
            "loss: 1.363524 [  384/ 1020]\n",
            "loss: 1.212323 [  704/ 1020]\n",
            "loss: 1.101694 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.6%, Avg loss: 3.461187 \n",
            "\n",
            "Epoch 87 \n",
            " ---------------------------------------\n",
            "loss: 0.863983 [   64/ 1020]\n",
            "loss: 1.146474 [  384/ 1020]\n",
            "loss: 1.124717 [  704/ 1020]\n",
            "loss: 0.680108 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.4%, Avg loss: 3.517532 \n",
            "\n",
            "Epoch 88 \n",
            " ---------------------------------------\n",
            "loss: 0.810914 [   64/ 1020]\n",
            "loss: 0.829169 [  384/ 1020]\n",
            "loss: 0.830553 [  704/ 1020]\n",
            "loss: 1.162915 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.2%, Avg loss: 3.535139 \n",
            "\n",
            "Epoch 89 \n",
            " ---------------------------------------\n",
            "loss: 0.715054 [   64/ 1020]\n",
            "loss: 0.754038 [  384/ 1020]\n",
            "loss: 1.210387 [  704/ 1020]\n",
            "loss: 0.778265 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.0%, Avg loss: 3.466288 \n",
            "\n",
            "Epoch 90 \n",
            " ---------------------------------------\n",
            "loss: 0.629008 [   64/ 1020]\n",
            "loss: 0.772952 [  384/ 1020]\n",
            "loss: 0.888973 [  704/ 1020]\n",
            "loss: 1.017919 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.2%, Avg loss: 3.692062 \n",
            "\n",
            "Epoch 91 \n",
            " ---------------------------------------\n",
            "loss: 0.570431 [   64/ 1020]\n",
            "loss: 0.844695 [  384/ 1020]\n",
            "loss: 1.009493 [  704/ 1020]\n",
            "loss: 1.157425 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.6%, Avg loss: 3.538732 \n",
            "\n",
            "Epoch 92 \n",
            " ---------------------------------------\n",
            "loss: 0.903775 [   64/ 1020]\n",
            "loss: 0.855306 [  384/ 1020]\n",
            "loss: 0.845712 [  704/ 1020]\n",
            "loss: 1.130875 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.0%, Avg loss: 3.524547 \n",
            "\n",
            "Epoch 93 \n",
            " ---------------------------------------\n",
            "loss: 0.939862 [   64/ 1020]\n",
            "loss: 0.987111 [  384/ 1020]\n",
            "loss: 0.672741 [  704/ 1020]\n",
            "loss: 0.840514 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.5%, Avg loss: 3.431918 \n",
            "\n",
            "Epoch 94 \n",
            " ---------------------------------------\n",
            "loss: 0.925867 [   64/ 1020]\n",
            "loss: 1.163084 [  384/ 1020]\n",
            "loss: 1.069117 [  704/ 1020]\n",
            "loss: 1.284834 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.6%, Avg loss: 3.328761 \n",
            "\n",
            "Epoch 95 \n",
            " ---------------------------------------\n",
            "loss: 0.678057 [   64/ 1020]\n",
            "loss: 0.921358 [  384/ 1020]\n",
            "loss: 0.986651 [  704/ 1020]\n",
            "loss: 0.842480 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.5%, Avg loss: 3.606166 \n",
            "\n",
            "Epoch 96 \n",
            " ---------------------------------------\n",
            "loss: 0.795820 [   64/ 1020]\n",
            "loss: 0.950559 [  384/ 1020]\n",
            "loss: 0.955288 [  704/ 1020]\n",
            "loss: 0.821535 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.5%, Avg loss: 3.459991 \n",
            "\n",
            "Epoch 97 \n",
            " ---------------------------------------\n",
            "loss: 0.849202 [   64/ 1020]\n",
            "loss: 1.197010 [  384/ 1020]\n",
            "loss: 0.929105 [  704/ 1020]\n",
            "loss: 1.047468 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.0%, Avg loss: 3.501281 \n",
            "\n",
            "Epoch 98 \n",
            " ---------------------------------------\n",
            "loss: 0.577162 [   64/ 1020]\n",
            "loss: 0.911827 [  384/ 1020]\n",
            "loss: 1.079425 [  704/ 1020]\n",
            "loss: 0.749105 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.5%, Avg loss: 3.633892 \n",
            "\n",
            "Epoch 99 \n",
            " ---------------------------------------\n",
            "loss: 0.718806 [   64/ 1020]\n",
            "loss: 0.786324 [  384/ 1020]\n",
            "loss: 0.807265 [  704/ 1020]\n",
            "loss: 0.902172 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.5%, Avg loss: 3.652963 \n",
            "\n",
            "Epoch 100 \n",
            " ---------------------------------------\n",
            "loss: 0.610464 [   64/ 1020]\n",
            "loss: 0.946194 [  384/ 1020]\n",
            "loss: 1.041191 [  704/ 1020]\n",
            "loss: 0.953716 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.1%, Avg loss: 3.550736 \n",
            "\n",
            "Done!!!!\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1} \\n ---------------------------------------\")\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "  test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!!!!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyN+sl8MgnnLXJQChKjg0Ly7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}