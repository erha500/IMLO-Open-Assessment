{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erha500/IMLO-Open-Assessment/blob/main/IMLO_Open_Assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MGJhK0Wy6U2-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as T\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1FLWsWbK-ylG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f13a93-4753-4f35-8e99-f6bf41e0d3ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\erhan\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_transform = v2.Compose([\n",
        "    v2.RandomResizedCrop([224,224], scale=[0.25,1.0], ratio=[1.0,1.0]),\n",
        "    v2.RandomPerspective(),\n",
        "    v2.RandomHorizontalFlip(0.5),\n",
        "    v2.RandomRotation(90),\n",
        "    #v2.RandomVerticalFlip(0.5)\n",
        "    v2.ToTensor(),\n",
        "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = v2.Compose([\n",
        "  v2.Resize([224,224]),\n",
        "  v2.ToTensor(),\n",
        "  v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWVmTrcs9QGM"
      },
      "source": [
        "Downloading Flowers102 dataset from datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2AG1ERmI9WXU"
      },
      "outputs": [],
      "source": [
        "#training_data = datasets.Flowers102(root=\"dataset\", split=\"train\", transform=train_transform, download=True)\n",
        "\n",
        "val_data = datasets.Flowers102(root=\"dataset\", split=\"val\", transform=test_transform, download=True)\n",
        "\n",
        "test_data = datasets.Flowers102(root=\"dataset\", split=\"test\", transform=test_transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EiOOyavq-T-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d105ca6c-adcf-42b7-df60-e4e591a7d97c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 3, 224, 224])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "#Create data loaders\n",
        "#train_dataloader = DataLoader(training_data, batch_size = batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "  print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3fL6F9TLEdDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ece9a5-aa42-4d38-e038-cc35deb0c392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU()\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU()\n",
            "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU()\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): Flatten(start_dim=1, end_dim=-1)\n",
            "    (17): Linear(in_features=25088, out_features=1024, bias=True)\n",
            "    (18): ReLU()\n",
            "    (19): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (20): ReLU()\n",
            "    (21): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (22): ReLU()\n",
            "    (23): Linear(in_features=256, out_features=102, bias=True)\n",
            "    (24): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "#Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "      nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.BatchNorm2d(16),\n",
        "      nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.BatchNorm2d(32),\n",
        "      nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(128 * 14 * 14, 1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(1024, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512,256),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(256,102),\n",
        "      nn.LogSoftmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9IvJsfvwE0VG"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "o4bMoWUAE1kO"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    #Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 5 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "y4Mf49itE3A-"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct) :>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Xr7VD7E3E5y1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a8b395-5234-476a-dce8-798e377635d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            " ---------------------------------------\n",
            "loss: 4.633262 [   64/ 1020]\n",
            "loss: 4.575636 [  384/ 1020]\n",
            "loss: 4.573678 [  704/ 1020]\n",
            "loss: 4.266449 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 2.2%, Avg loss: 4.581033 \n",
            "\n",
            "Epoch 2 \n",
            " ---------------------------------------\n",
            "loss: 4.329619 [   64/ 1020]\n",
            "loss: 4.114266 [  384/ 1020]\n",
            "loss: 3.928805 [  704/ 1020]\n",
            "loss: 3.835431 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 7.2%, Avg loss: 4.046039 \n",
            "\n",
            "Epoch 3 \n",
            " ---------------------------------------\n",
            "loss: 3.849914 [   64/ 1020]\n",
            "loss: 4.009758 [  384/ 1020]\n",
            "loss: 3.824996 [  704/ 1020]\n",
            "loss: 3.527446 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 12.6%, Avg loss: 3.749678 \n",
            "\n",
            "Epoch 4 \n",
            " ---------------------------------------\n",
            "loss: 3.629075 [   64/ 1020]\n",
            "loss: 3.612241 [  384/ 1020]\n",
            "loss: 3.464042 [  704/ 1020]\n",
            "loss: 3.589995 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 14.8%, Avg loss: 3.467619 \n",
            "\n",
            "Epoch 5 \n",
            " ---------------------------------------\n",
            "loss: 3.037247 [   64/ 1020]\n",
            "loss: 3.509634 [  384/ 1020]\n",
            "loss: 3.345223 [  704/ 1020]\n",
            "loss: 3.485370 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 13.8%, Avg loss: 3.563937 \n",
            "\n",
            "Epoch 6 \n",
            " ---------------------------------------\n",
            "loss: 3.129894 [   64/ 1020]\n",
            "loss: 3.360267 [  384/ 1020]\n",
            "loss: 3.432181 [  704/ 1020]\n",
            "loss: 3.319771 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 15.2%, Avg loss: 3.660810 \n",
            "\n",
            "Epoch 7 \n",
            " ---------------------------------------\n",
            "loss: 2.966726 [   64/ 1020]\n",
            "loss: 2.813373 [  384/ 1020]\n",
            "loss: 3.186029 [  704/ 1020]\n",
            "loss: 2.849732 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 17.1%, Avg loss: 3.568866 \n",
            "\n",
            "Epoch 8 \n",
            " ---------------------------------------\n",
            "loss: 2.636862 [   64/ 1020]\n",
            "loss: 2.760060 [  384/ 1020]\n",
            "loss: 3.129261 [  704/ 1020]\n",
            "loss: 2.946376 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 18.8%, Avg loss: 3.343511 \n",
            "\n",
            "Epoch 9 \n",
            " ---------------------------------------\n",
            "loss: 2.768420 [   64/ 1020]\n",
            "loss: 2.899639 [  384/ 1020]\n",
            "loss: 2.531404 [  704/ 1020]\n",
            "loss: 2.890857 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 19.8%, Avg loss: 3.385265 \n",
            "\n",
            "Epoch 10 \n",
            " ---------------------------------------\n",
            "loss: 2.438467 [   64/ 1020]\n",
            "loss: 2.507481 [  384/ 1020]\n",
            "loss: 2.818763 [  704/ 1020]\n",
            "loss: 2.795369 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.6%, Avg loss: 3.206481 \n",
            "\n",
            "Epoch 11 \n",
            " ---------------------------------------\n",
            "loss: 2.286822 [   64/ 1020]\n",
            "loss: 2.899192 [  384/ 1020]\n",
            "loss: 2.491064 [  704/ 1020]\n",
            "loss: 2.843698 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 22.9%, Avg loss: 3.186925 \n",
            "\n",
            "Epoch 12 \n",
            " ---------------------------------------\n",
            "loss: 2.324681 [   64/ 1020]\n",
            "loss: 2.744712 [  384/ 1020]\n",
            "loss: 2.495888 [  704/ 1020]\n",
            "loss: 2.896543 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.6%, Avg loss: 3.399792 \n",
            "\n",
            "Epoch 13 \n",
            " ---------------------------------------\n",
            "loss: 2.194761 [   64/ 1020]\n",
            "loss: 2.422638 [  384/ 1020]\n",
            "loss: 2.066023 [  704/ 1020]\n",
            "loss: 2.314249 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.1%, Avg loss: 3.214167 \n",
            "\n",
            "Epoch 14 \n",
            " ---------------------------------------\n",
            "loss: 2.095200 [   64/ 1020]\n",
            "loss: 2.357657 [  384/ 1020]\n",
            "loss: 2.534511 [  704/ 1020]\n",
            "loss: 2.410411 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.0%, Avg loss: 3.368793 \n",
            "\n",
            "Epoch 15 \n",
            " ---------------------------------------\n",
            "loss: 2.028294 [   64/ 1020]\n",
            "loss: 2.461278 [  384/ 1020]\n",
            "loss: 2.688510 [  704/ 1020]\n",
            "loss: 2.679779 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 24.2%, Avg loss: 3.533856 \n",
            "\n",
            "Epoch 16 \n",
            " ---------------------------------------\n",
            "loss: 2.349865 [   64/ 1020]\n",
            "loss: 2.558671 [  384/ 1020]\n",
            "loss: 2.193719 [  704/ 1020]\n",
            "loss: 2.512252 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.7%, Avg loss: 3.272322 \n",
            "\n",
            "Epoch 17 \n",
            " ---------------------------------------\n",
            "loss: 2.231426 [   64/ 1020]\n",
            "loss: 2.067680 [  384/ 1020]\n",
            "loss: 2.570506 [  704/ 1020]\n",
            "loss: 2.086649 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.1%, Avg loss: 3.212466 \n",
            "\n",
            "Epoch 18 \n",
            " ---------------------------------------\n",
            "loss: 1.746132 [   64/ 1020]\n",
            "loss: 2.147092 [  384/ 1020]\n",
            "loss: 2.362060 [  704/ 1020]\n",
            "loss: 2.382231 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.6%, Avg loss: 3.363670 \n",
            "\n",
            "Epoch 19 \n",
            " ---------------------------------------\n",
            "loss: 1.742082 [   64/ 1020]\n",
            "loss: 2.143777 [  384/ 1020]\n",
            "loss: 2.304032 [  704/ 1020]\n",
            "loss: 1.918550 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.1%, Avg loss: 3.510666 \n",
            "\n",
            "Epoch 20 \n",
            " ---------------------------------------\n",
            "loss: 2.234985 [   64/ 1020]\n",
            "loss: 1.844754 [  384/ 1020]\n",
            "loss: 2.200207 [  704/ 1020]\n",
            "loss: 1.912525 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.8%, Avg loss: 3.493837 \n",
            "\n",
            "Epoch 21 \n",
            " ---------------------------------------\n",
            "loss: 1.967887 [   64/ 1020]\n",
            "loss: 1.979764 [  384/ 1020]\n",
            "loss: 2.171640 [  704/ 1020]\n",
            "loss: 1.735197 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.8%, Avg loss: 3.244050 \n",
            "\n",
            "Epoch 22 \n",
            " ---------------------------------------\n",
            "loss: 1.853315 [   64/ 1020]\n",
            "loss: 1.701153 [  384/ 1020]\n",
            "loss: 1.937597 [  704/ 1020]\n",
            "loss: 1.873344 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.8%, Avg loss: 3.582538 \n",
            "\n",
            "Epoch 23 \n",
            " ---------------------------------------\n",
            "loss: 1.984787 [   64/ 1020]\n",
            "loss: 1.463505 [  384/ 1020]\n",
            "loss: 1.746742 [  704/ 1020]\n",
            "loss: 1.767169 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.8%, Avg loss: 3.607664 \n",
            "\n",
            "Epoch 24 \n",
            " ---------------------------------------\n",
            "loss: 1.311024 [   64/ 1020]\n",
            "loss: 1.959755 [  384/ 1020]\n",
            "loss: 1.848642 [  704/ 1020]\n",
            "loss: 2.319483 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.6%, Avg loss: 3.675281 \n",
            "\n",
            "Epoch 25 \n",
            " ---------------------------------------\n",
            "loss: 1.592369 [   64/ 1020]\n",
            "loss: 1.670960 [  384/ 1020]\n",
            "loss: 2.197410 [  704/ 1020]\n",
            "loss: 1.379843 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.6%, Avg loss: 3.859364 \n",
            "\n",
            "Epoch 26 \n",
            " ---------------------------------------\n",
            "loss: 1.501551 [   64/ 1020]\n",
            "loss: 1.403477 [  384/ 1020]\n",
            "loss: 1.762799 [  704/ 1020]\n",
            "loss: 2.179300 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.3%, Avg loss: 3.738448 \n",
            "\n",
            "Epoch 27 \n",
            " ---------------------------------------\n",
            "loss: 1.598478 [   64/ 1020]\n",
            "loss: 1.967483 [  384/ 1020]\n",
            "loss: 1.752841 [  704/ 1020]\n",
            "loss: 2.067013 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.7%, Avg loss: 3.514888 \n",
            "\n",
            "Epoch 28 \n",
            " ---------------------------------------\n",
            "loss: 1.388576 [   64/ 1020]\n",
            "loss: 1.770665 [  384/ 1020]\n",
            "loss: 1.806546 [  704/ 1020]\n",
            "loss: 1.666772 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.9%, Avg loss: 3.939716 \n",
            "\n",
            "Epoch 29 \n",
            " ---------------------------------------\n",
            "loss: 1.748383 [   64/ 1020]\n",
            "loss: 1.756965 [  384/ 1020]\n",
            "loss: 1.465505 [  704/ 1020]\n",
            "loss: 1.562721 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.5%, Avg loss: 4.081216 \n",
            "\n",
            "Epoch 30 \n",
            " ---------------------------------------\n",
            "loss: 1.254372 [   64/ 1020]\n",
            "loss: 1.867628 [  384/ 1020]\n",
            "loss: 1.533630 [  704/ 1020]\n",
            "loss: 2.521559 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.0%, Avg loss: 4.414168 \n",
            "\n",
            "Epoch 31 \n",
            " ---------------------------------------\n",
            "loss: 1.185962 [   64/ 1020]\n",
            "loss: 1.665614 [  384/ 1020]\n",
            "loss: 1.645311 [  704/ 1020]\n",
            "loss: 1.874736 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.7%, Avg loss: 3.829607 \n",
            "\n",
            "Epoch 32 \n",
            " ---------------------------------------\n",
            "loss: 1.226141 [   64/ 1020]\n",
            "loss: 1.415117 [  384/ 1020]\n",
            "loss: 1.499729 [  704/ 1020]\n",
            "loss: 1.691537 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.3%, Avg loss: 4.113351 \n",
            "\n",
            "Epoch 33 \n",
            " ---------------------------------------\n",
            "loss: 1.530523 [   64/ 1020]\n",
            "loss: 1.524634 [  384/ 1020]\n",
            "loss: 1.651944 [  704/ 1020]\n",
            "loss: 1.953389 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.0%, Avg loss: 3.773782 \n",
            "\n",
            "Epoch 34 \n",
            " ---------------------------------------\n",
            "loss: 1.151294 [   64/ 1020]\n",
            "loss: 1.524826 [  384/ 1020]\n",
            "loss: 1.905421 [  704/ 1020]\n",
            "loss: 1.876065 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.1%, Avg loss: 4.454736 \n",
            "\n",
            "Epoch 35 \n",
            " ---------------------------------------\n",
            "loss: 1.694507 [   64/ 1020]\n",
            "loss: 0.849227 [  384/ 1020]\n",
            "loss: 1.470816 [  704/ 1020]\n",
            "loss: 1.460323 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.6%, Avg loss: 4.095348 \n",
            "\n",
            "Epoch 36 \n",
            " ---------------------------------------\n",
            "loss: 1.243248 [   64/ 1020]\n",
            "loss: 1.634777 [  384/ 1020]\n",
            "loss: 1.548509 [  704/ 1020]\n",
            "loss: 1.338028 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.4%, Avg loss: 4.023682 \n",
            "\n",
            "Epoch 37 \n",
            " ---------------------------------------\n",
            "loss: 0.955123 [   64/ 1020]\n",
            "loss: 1.178044 [  384/ 1020]\n",
            "loss: 1.529212 [  704/ 1020]\n",
            "loss: 1.497830 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.9%, Avg loss: 4.296858 \n",
            "\n",
            "Epoch 38 \n",
            " ---------------------------------------\n",
            "loss: 1.205042 [   64/ 1020]\n",
            "loss: 0.911036 [  384/ 1020]\n",
            "loss: 0.994929 [  704/ 1020]\n",
            "loss: 1.056900 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.8%, Avg loss: 4.399051 \n",
            "\n",
            "Epoch 39 \n",
            " ---------------------------------------\n",
            "loss: 1.025339 [   64/ 1020]\n",
            "loss: 1.275355 [  384/ 1020]\n",
            "loss: 1.586716 [  704/ 1020]\n",
            "loss: 1.369366 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.5%, Avg loss: 4.211468 \n",
            "\n",
            "Epoch 40 \n",
            " ---------------------------------------\n",
            "loss: 1.163108 [   64/ 1020]\n",
            "loss: 1.380261 [  384/ 1020]\n",
            "loss: 1.726377 [  704/ 1020]\n",
            "loss: 1.214205 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.0%, Avg loss: 4.083385 \n",
            "\n",
            "Epoch 41 \n",
            " ---------------------------------------\n",
            "loss: 1.443315 [   64/ 1020]\n",
            "loss: 1.131550 [  384/ 1020]\n",
            "loss: 1.254524 [  704/ 1020]\n",
            "loss: 1.703485 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.1%, Avg loss: 4.741048 \n",
            "\n",
            "Epoch 42 \n",
            " ---------------------------------------\n",
            "loss: 1.079445 [   64/ 1020]\n",
            "loss: 1.345442 [  384/ 1020]\n",
            "loss: 1.147804 [  704/ 1020]\n",
            "loss: 1.728144 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.0%, Avg loss: 4.367174 \n",
            "\n",
            "Epoch 43 \n",
            " ---------------------------------------\n",
            "loss: 0.984208 [   64/ 1020]\n",
            "loss: 0.996356 [  384/ 1020]\n",
            "loss: 1.280673 [  704/ 1020]\n",
            "loss: 0.988881 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.7%, Avg loss: 4.094239 \n",
            "\n",
            "Epoch 44 \n",
            " ---------------------------------------\n",
            "loss: 0.749971 [   64/ 1020]\n",
            "loss: 0.993798 [  384/ 1020]\n",
            "loss: 0.884565 [  704/ 1020]\n",
            "loss: 1.353123 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.1%, Avg loss: 4.503843 \n",
            "\n",
            "Epoch 45 \n",
            " ---------------------------------------\n",
            "loss: 1.024153 [   64/ 1020]\n",
            "loss: 1.143734 [  384/ 1020]\n",
            "loss: 1.373458 [  704/ 1020]\n",
            "loss: 1.203067 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.4%, Avg loss: 4.658522 \n",
            "\n",
            "Epoch 46 \n",
            " ---------------------------------------\n",
            "loss: 1.126994 [   64/ 1020]\n",
            "loss: 1.291159 [  384/ 1020]\n",
            "loss: 1.267623 [  704/ 1020]\n",
            "loss: 0.951142 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.9%, Avg loss: 4.742267 \n",
            "\n",
            "Epoch 47 \n",
            " ---------------------------------------\n",
            "loss: 1.077298 [   64/ 1020]\n",
            "loss: 1.288798 [  384/ 1020]\n",
            "loss: 1.355392 [  704/ 1020]\n",
            "loss: 1.044975 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.4%, Avg loss: 4.363277 \n",
            "\n",
            "Epoch 48 \n",
            " ---------------------------------------\n",
            "loss: 0.961717 [   64/ 1020]\n",
            "loss: 1.315431 [  384/ 1020]\n",
            "loss: 0.858617 [  704/ 1020]\n",
            "loss: 1.211033 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.3%, Avg loss: 4.437824 \n",
            "\n",
            "Epoch 49 \n",
            " ---------------------------------------\n",
            "loss: 0.887022 [   64/ 1020]\n",
            "loss: 0.861552 [  384/ 1020]\n",
            "loss: 1.067741 [  704/ 1020]\n",
            "loss: 0.872691 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.4%, Avg loss: 4.617113 \n",
            "\n",
            "Epoch 50 \n",
            " ---------------------------------------\n",
            "loss: 0.990386 [   64/ 1020]\n",
            "loss: 1.080095 [  384/ 1020]\n",
            "loss: 0.796398 [  704/ 1020]\n",
            "loss: 1.012790 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.2%, Avg loss: 4.454645 \n",
            "\n",
            "Epoch 51 \n",
            " ---------------------------------------\n",
            "loss: 0.851712 [   64/ 1020]\n",
            "loss: 0.653684 [  384/ 1020]\n",
            "loss: 0.775597 [  704/ 1020]\n",
            "loss: 0.975093 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.6%, Avg loss: 5.103762 \n",
            "\n",
            "Epoch 52 \n",
            " ---------------------------------------\n",
            "loss: 0.790874 [   64/ 1020]\n",
            "loss: 0.742819 [  384/ 1020]\n",
            "loss: 0.955888 [  704/ 1020]\n",
            "loss: 1.099232 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.8%, Avg loss: 4.966133 \n",
            "\n",
            "Epoch 53 \n",
            " ---------------------------------------\n",
            "loss: 0.933696 [   64/ 1020]\n",
            "loss: 0.886636 [  384/ 1020]\n",
            "loss: 0.991928 [  704/ 1020]\n",
            "loss: 0.794157 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.7%, Avg loss: 4.731571 \n",
            "\n",
            "Epoch 54 \n",
            " ---------------------------------------\n",
            "loss: 0.476818 [   64/ 1020]\n",
            "loss: 1.492293 [  384/ 1020]\n",
            "loss: 0.926053 [  704/ 1020]\n",
            "loss: 0.891219 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.1%, Avg loss: 4.576261 \n",
            "\n",
            "Epoch 55 \n",
            " ---------------------------------------\n",
            "loss: 1.012272 [   64/ 1020]\n",
            "loss: 1.091149 [  384/ 1020]\n",
            "loss: 0.822319 [  704/ 1020]\n",
            "loss: 0.859370 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.1%, Avg loss: 4.502162 \n",
            "\n",
            "Epoch 56 \n",
            " ---------------------------------------\n",
            "loss: 0.689554 [   64/ 1020]\n",
            "loss: 0.906866 [  384/ 1020]\n",
            "loss: 0.744193 [  704/ 1020]\n",
            "loss: 0.923212 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.6%, Avg loss: 5.031473 \n",
            "\n",
            "Epoch 57 \n",
            " ---------------------------------------\n",
            "loss: 0.694418 [   64/ 1020]\n",
            "loss: 0.770955 [  384/ 1020]\n",
            "loss: 0.767328 [  704/ 1020]\n",
            "loss: 1.085787 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.1%, Avg loss: 5.021471 \n",
            "\n",
            "Epoch 58 \n",
            " ---------------------------------------\n",
            "loss: 0.951585 [   64/ 1020]\n",
            "loss: 0.684399 [  384/ 1020]\n",
            "loss: 0.993916 [  704/ 1020]\n",
            "loss: 1.072777 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.9%, Avg loss: 4.944503 \n",
            "\n",
            "Epoch 59 \n",
            " ---------------------------------------\n",
            "loss: 0.769461 [   64/ 1020]\n",
            "loss: 1.051774 [  384/ 1020]\n",
            "loss: 1.207834 [  704/ 1020]\n",
            "loss: 0.980846 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.6%, Avg loss: 4.752475 \n",
            "\n",
            "Epoch 60 \n",
            " ---------------------------------------\n",
            "loss: 1.030800 [   64/ 1020]\n",
            "loss: 0.575762 [  384/ 1020]\n",
            "loss: 0.901383 [  704/ 1020]\n",
            "loss: 1.079856 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.5%, Avg loss: 5.155001 \n",
            "\n",
            "Epoch 61 \n",
            " ---------------------------------------\n",
            "loss: 0.787907 [   64/ 1020]\n",
            "loss: 0.656850 [  384/ 1020]\n",
            "loss: 0.857928 [  704/ 1020]\n",
            "loss: 0.815714 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.9%, Avg loss: 5.090654 \n",
            "\n",
            "Epoch 62 \n",
            " ---------------------------------------\n",
            "loss: 0.520330 [   64/ 1020]\n",
            "loss: 0.985588 [  384/ 1020]\n",
            "loss: 1.216942 [  704/ 1020]\n",
            "loss: 1.272343 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.8%, Avg loss: 5.159474 \n",
            "\n",
            "Epoch 63 \n",
            " ---------------------------------------\n",
            "loss: 0.515749 [   64/ 1020]\n",
            "loss: 0.914381 [  384/ 1020]\n",
            "loss: 0.884294 [  704/ 1020]\n",
            "loss: 0.992634 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.6%, Avg loss: 4.928268 \n",
            "\n",
            "Epoch 64 \n",
            " ---------------------------------------\n",
            "loss: 0.720427 [   64/ 1020]\n",
            "loss: 1.025462 [  384/ 1020]\n",
            "loss: 0.779369 [  704/ 1020]\n",
            "loss: 1.105505 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.0%, Avg loss: 5.501030 \n",
            "\n",
            "Epoch 65 \n",
            " ---------------------------------------\n",
            "loss: 0.636595 [   64/ 1020]\n",
            "loss: 0.988210 [  384/ 1020]\n",
            "loss: 0.995390 [  704/ 1020]\n",
            "loss: 1.164553 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.8%, Avg loss: 5.189948 \n",
            "\n",
            "Epoch 66 \n",
            " ---------------------------------------\n",
            "loss: 0.829046 [   64/ 1020]\n",
            "loss: 0.684959 [  384/ 1020]\n",
            "loss: 0.613124 [  704/ 1020]\n",
            "loss: 1.267225 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.6%, Avg loss: 5.206872 \n",
            "\n",
            "Epoch 67 \n",
            " ---------------------------------------\n",
            "loss: 0.392097 [   64/ 1020]\n",
            "loss: 0.773612 [  384/ 1020]\n",
            "loss: 0.836254 [  704/ 1020]\n",
            "loss: 0.927234 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.0%, Avg loss: 5.284882 \n",
            "\n",
            "Epoch 68 \n",
            " ---------------------------------------\n",
            "loss: 0.763576 [   64/ 1020]\n",
            "loss: 0.574915 [  384/ 1020]\n",
            "loss: 0.910276 [  704/ 1020]\n",
            "loss: 0.818874 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.4%, Avg loss: 5.315760 \n",
            "\n",
            "Epoch 69 \n",
            " ---------------------------------------\n",
            "loss: 0.864979 [   64/ 1020]\n",
            "loss: 0.861782 [  384/ 1020]\n",
            "loss: 1.122025 [  704/ 1020]\n",
            "loss: 0.871417 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.1%, Avg loss: 5.293043 \n",
            "\n",
            "Epoch 70 \n",
            " ---------------------------------------\n",
            "loss: 0.817610 [   64/ 1020]\n",
            "loss: 0.844547 [  384/ 1020]\n",
            "loss: 0.918873 [  704/ 1020]\n",
            "loss: 1.202723 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.6%, Avg loss: 5.326950 \n",
            "\n",
            "Epoch 71 \n",
            " ---------------------------------------\n",
            "loss: 0.807756 [   64/ 1020]\n",
            "loss: 0.619019 [  384/ 1020]\n",
            "loss: 0.762241 [  704/ 1020]\n",
            "loss: 1.101569 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.3%, Avg loss: 5.346121 \n",
            "\n",
            "Epoch 72 \n",
            " ---------------------------------------\n",
            "loss: 0.423484 [   64/ 1020]\n",
            "loss: 0.641122 [  384/ 1020]\n",
            "loss: 1.095121 [  704/ 1020]\n",
            "loss: 0.916931 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.4%, Avg loss: 5.382734 \n",
            "\n",
            "Epoch 73 \n",
            " ---------------------------------------\n",
            "loss: 0.785776 [   64/ 1020]\n",
            "loss: 0.792170 [  384/ 1020]\n",
            "loss: 0.882043 [  704/ 1020]\n",
            "loss: 0.805923 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.9%, Avg loss: 5.564634 \n",
            "\n",
            "Epoch 74 \n",
            " ---------------------------------------\n",
            "loss: 0.586334 [   64/ 1020]\n",
            "loss: 0.630024 [  384/ 1020]\n",
            "loss: 0.896330 [  704/ 1020]\n",
            "loss: 0.651777 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.9%, Avg loss: 5.695469 \n",
            "\n",
            "Epoch 75 \n",
            " ---------------------------------------\n",
            "loss: 1.089225 [   64/ 1020]\n",
            "loss: 0.671611 [  384/ 1020]\n",
            "loss: 0.728600 [  704/ 1020]\n",
            "loss: 0.576597 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.2%, Avg loss: 5.609135 \n",
            "\n",
            "Epoch 76 \n",
            " ---------------------------------------\n",
            "loss: 0.539268 [   64/ 1020]\n",
            "loss: 0.546195 [  384/ 1020]\n",
            "loss: 0.754546 [  704/ 1020]\n",
            "loss: 0.577903 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.5%, Avg loss: 5.475260 \n",
            "\n",
            "Epoch 77 \n",
            " ---------------------------------------\n",
            "loss: 0.382562 [   64/ 1020]\n",
            "loss: 0.542209 [  384/ 1020]\n",
            "loss: 0.546236 [  704/ 1020]\n",
            "loss: 0.757881 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.1%, Avg loss: 5.585955 \n",
            "\n",
            "Epoch 78 \n",
            " ---------------------------------------\n",
            "loss: 0.495422 [   64/ 1020]\n",
            "loss: 0.980457 [  384/ 1020]\n",
            "loss: 0.719914 [  704/ 1020]\n",
            "loss: 0.496544 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.0%, Avg loss: 5.490387 \n",
            "\n",
            "Epoch 79 \n",
            " ---------------------------------------\n",
            "loss: 0.503581 [   64/ 1020]\n",
            "loss: 0.801156 [  384/ 1020]\n",
            "loss: 0.776996 [  704/ 1020]\n",
            "loss: 0.524887 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.8%, Avg loss: 5.515289 \n",
            "\n",
            "Epoch 80 \n",
            " ---------------------------------------\n",
            "loss: 0.739546 [   64/ 1020]\n",
            "loss: 0.688144 [  384/ 1020]\n",
            "loss: 0.526468 [  704/ 1020]\n",
            "loss: 0.682085 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.8%, Avg loss: 5.204226 \n",
            "\n",
            "Epoch 81 \n",
            " ---------------------------------------\n",
            "loss: 0.437473 [   64/ 1020]\n",
            "loss: 1.048123 [  384/ 1020]\n",
            "loss: 1.414230 [  704/ 1020]\n",
            "loss: 0.563873 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.2%, Avg loss: 5.979273 \n",
            "\n",
            "Epoch 82 \n",
            " ---------------------------------------\n",
            "loss: 0.420140 [   64/ 1020]\n",
            "loss: 0.535367 [  384/ 1020]\n",
            "loss: 0.522069 [  704/ 1020]\n",
            "loss: 0.947436 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.3%, Avg loss: 5.701926 \n",
            "\n",
            "Epoch 83 \n",
            " ---------------------------------------\n",
            "loss: 0.605168 [   64/ 1020]\n",
            "loss: 0.682145 [  384/ 1020]\n",
            "loss: 0.687847 [  704/ 1020]\n",
            "loss: 0.771085 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.5%, Avg loss: 5.725953 \n",
            "\n",
            "Epoch 84 \n",
            " ---------------------------------------\n",
            "loss: 0.478253 [   64/ 1020]\n",
            "loss: 0.331848 [  384/ 1020]\n",
            "loss: 0.868093 [  704/ 1020]\n",
            "loss: 0.631309 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.2%, Avg loss: 5.661352 \n",
            "\n",
            "Epoch 85 \n",
            " ---------------------------------------\n",
            "loss: 0.400248 [   64/ 1020]\n",
            "loss: 0.825245 [  384/ 1020]\n",
            "loss: 0.458117 [  704/ 1020]\n",
            "loss: 0.902094 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.0%, Avg loss: 5.522128 \n",
            "\n",
            "Epoch 86 \n",
            " ---------------------------------------\n",
            "loss: 0.540410 [   64/ 1020]\n",
            "loss: 1.149572 [  384/ 1020]\n",
            "loss: 0.664764 [  704/ 1020]\n",
            "loss: 0.487666 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.4%, Avg loss: 5.729010 \n",
            "\n",
            "Epoch 87 \n",
            " ---------------------------------------\n",
            "loss: 0.387755 [   64/ 1020]\n",
            "loss: 0.431806 [  384/ 1020]\n",
            "loss: 0.424873 [  704/ 1020]\n",
            "loss: 0.794524 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.2%, Avg loss: 5.545387 \n",
            "\n",
            "Epoch 88 \n",
            " ---------------------------------------\n",
            "loss: 0.581564 [   64/ 1020]\n",
            "loss: 0.635475 [  384/ 1020]\n",
            "loss: 0.432326 [  704/ 1020]\n",
            "loss: 1.025128 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.4%, Avg loss: 5.837122 \n",
            "\n",
            "Epoch 89 \n",
            " ---------------------------------------\n",
            "loss: 0.741390 [   64/ 1020]\n",
            "loss: 0.568829 [  384/ 1020]\n",
            "loss: 0.839542 [  704/ 1020]\n",
            "loss: 0.297969 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.4%, Avg loss: 5.576119 \n",
            "\n",
            "Epoch 90 \n",
            " ---------------------------------------\n",
            "loss: 0.419633 [   64/ 1020]\n",
            "loss: 0.561179 [  384/ 1020]\n",
            "loss: 0.921108 [  704/ 1020]\n",
            "loss: 1.019254 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.5%, Avg loss: 5.794547 \n",
            "\n",
            "Epoch 91 \n",
            " ---------------------------------------\n",
            "loss: 1.128481 [   64/ 1020]\n",
            "loss: 0.608102 [  384/ 1020]\n",
            "loss: 0.806439 [  704/ 1020]\n",
            "loss: 0.726550 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.4%, Avg loss: 5.884889 \n",
            "\n",
            "Epoch 92 \n",
            " ---------------------------------------\n",
            "loss: 0.573336 [   64/ 1020]\n",
            "loss: 1.023750 [  384/ 1020]\n",
            "loss: 0.417025 [  704/ 1020]\n",
            "loss: 0.952171 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.8%, Avg loss: 5.622458 \n",
            "\n",
            "Epoch 93 \n",
            " ---------------------------------------\n",
            "loss: 0.556210 [   64/ 1020]\n",
            "loss: 0.627594 [  384/ 1020]\n",
            "loss: 0.683313 [  704/ 1020]\n",
            "loss: 0.506648 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.5%, Avg loss: 5.922488 \n",
            "\n",
            "Epoch 94 \n",
            " ---------------------------------------\n",
            "loss: 0.330481 [   64/ 1020]\n",
            "loss: 0.454633 [  384/ 1020]\n",
            "loss: 0.694904 [  704/ 1020]\n",
            "loss: 0.808125 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.9%, Avg loss: 5.733954 \n",
            "\n",
            "Epoch 95 \n",
            " ---------------------------------------\n",
            "loss: 0.610085 [   64/ 1020]\n",
            "loss: 0.609053 [  384/ 1020]\n",
            "loss: 0.856758 [  704/ 1020]\n",
            "loss: 0.404085 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.8%, Avg loss: 6.373558 \n",
            "\n",
            "Epoch 96 \n",
            " ---------------------------------------\n",
            "loss: 0.477906 [   64/ 1020]\n",
            "loss: 0.729152 [  384/ 1020]\n",
            "loss: 0.613222 [  704/ 1020]\n",
            "loss: 0.488472 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.7%, Avg loss: 5.745318 \n",
            "\n",
            "Epoch 97 \n",
            " ---------------------------------------\n",
            "loss: 0.611388 [   64/ 1020]\n",
            "loss: 0.657568 [  384/ 1020]\n",
            "loss: 0.540891 [  704/ 1020]\n",
            "loss: 0.505075 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.1%, Avg loss: 5.754498 \n",
            "\n",
            "Epoch 98 \n",
            " ---------------------------------------\n",
            "loss: 0.529060 [   64/ 1020]\n",
            "loss: 0.624060 [  384/ 1020]\n",
            "loss: 0.457240 [  704/ 1020]\n",
            "loss: 0.581912 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.6%, Avg loss: 6.128145 \n",
            "\n",
            "Epoch 99 \n",
            " ---------------------------------------\n",
            "loss: 0.316269 [   64/ 1020]\n",
            "loss: 0.176165 [  384/ 1020]\n",
            "loss: 0.356514 [  704/ 1020]\n",
            "loss: 0.418996 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.0%, Avg loss: 6.026338 \n",
            "\n",
            "Epoch 100 \n",
            " ---------------------------------------\n",
            "loss: 0.303126 [   64/ 1020]\n",
            "loss: 0.664565 [  384/ 1020]\n",
            "loss: 1.253755 [  704/ 1020]\n",
            "loss: 0.421956 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.6%, Avg loss: 6.550289 \n",
            "\n",
            "Epoch 101 \n",
            " ---------------------------------------\n",
            "loss: 0.485263 [   64/ 1020]\n",
            "loss: 0.647621 [  384/ 1020]\n",
            "loss: 0.529589 [  704/ 1020]\n",
            "loss: 0.555241 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.1%, Avg loss: 6.238565 \n",
            "\n",
            "Epoch 102 \n",
            " ---------------------------------------\n",
            "loss: 0.647867 [   64/ 1020]\n",
            "loss: 0.456518 [  384/ 1020]\n",
            "loss: 0.357865 [  704/ 1020]\n",
            "loss: 0.399375 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.6%, Avg loss: 6.144037 \n",
            "\n",
            "Epoch 103 \n",
            " ---------------------------------------\n",
            "loss: 0.660849 [   64/ 1020]\n",
            "loss: 0.476665 [  384/ 1020]\n",
            "loss: 0.503134 [  704/ 1020]\n",
            "loss: 0.377538 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.7%, Avg loss: 6.128952 \n",
            "\n",
            "Epoch 104 \n",
            " ---------------------------------------\n",
            "loss: 0.186420 [   64/ 1020]\n",
            "loss: 0.455115 [  384/ 1020]\n",
            "loss: 0.624359 [  704/ 1020]\n",
            "loss: 0.594030 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.0%, Avg loss: 6.053448 \n",
            "\n",
            "Epoch 105 \n",
            " ---------------------------------------\n",
            "loss: 0.496806 [   64/ 1020]\n",
            "loss: 0.372251 [  384/ 1020]\n",
            "loss: 0.137429 [  704/ 1020]\n",
            "loss: 0.671918 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.6%, Avg loss: 6.188589 \n",
            "\n",
            "Epoch 106 \n",
            " ---------------------------------------\n",
            "loss: 0.583898 [   64/ 1020]\n",
            "loss: 0.167774 [  384/ 1020]\n",
            "loss: 0.222117 [  704/ 1020]\n",
            "loss: 0.547540 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.3%, Avg loss: 6.147989 \n",
            "\n",
            "Epoch 107 \n",
            " ---------------------------------------\n",
            "loss: 0.533376 [   64/ 1020]\n",
            "loss: 0.645975 [  384/ 1020]\n",
            "loss: 0.545287 [  704/ 1020]\n",
            "loss: 0.730306 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.7%, Avg loss: 6.191878 \n",
            "\n",
            "Epoch 108 \n",
            " ---------------------------------------\n",
            "loss: 0.385074 [   64/ 1020]\n",
            "loss: 0.543912 [  384/ 1020]\n",
            "loss: 0.777967 [  704/ 1020]\n",
            "loss: 1.100705 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.7%, Avg loss: 6.221693 \n",
            "\n",
            "Epoch 109 \n",
            " ---------------------------------------\n",
            "loss: 0.803761 [   64/ 1020]\n",
            "loss: 0.433240 [  384/ 1020]\n",
            "loss: 0.648792 [  704/ 1020]\n",
            "loss: 0.603175 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.5%, Avg loss: 6.334577 \n",
            "\n",
            "Epoch 110 \n",
            " ---------------------------------------\n",
            "loss: 0.328042 [   64/ 1020]\n",
            "loss: 0.433268 [  384/ 1020]\n",
            "loss: 0.662816 [  704/ 1020]\n",
            "loss: 0.279139 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.0%, Avg loss: 6.413214 \n",
            "\n",
            "Epoch 111 \n",
            " ---------------------------------------\n",
            "loss: 0.444975 [   64/ 1020]\n",
            "loss: 0.434475 [  384/ 1020]\n",
            "loss: 1.262920 [  704/ 1020]\n",
            "loss: 0.620583 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.8%, Avg loss: 6.886180 \n",
            "\n",
            "Epoch 112 \n",
            " ---------------------------------------\n",
            "loss: 0.294010 [   64/ 1020]\n",
            "loss: 0.426756 [  384/ 1020]\n",
            "loss: 0.633956 [  704/ 1020]\n",
            "loss: 0.503507 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.1%, Avg loss: 5.935486 \n",
            "\n",
            "Epoch 113 \n",
            " ---------------------------------------\n",
            "loss: 0.450807 [   64/ 1020]\n",
            "loss: 0.471141 [  384/ 1020]\n",
            "loss: 0.494366 [  704/ 1020]\n",
            "loss: 0.448647 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.6%, Avg loss: 5.900376 \n",
            "\n",
            "Epoch 114 \n",
            " ---------------------------------------\n",
            "loss: 0.351872 [   64/ 1020]\n",
            "loss: 0.373426 [  384/ 1020]\n",
            "loss: 0.630112 [  704/ 1020]\n",
            "loss: 0.583640 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.7%, Avg loss: 6.093098 \n",
            "\n",
            "Epoch 115 \n",
            " ---------------------------------------\n",
            "loss: 0.406837 [   64/ 1020]\n",
            "loss: 0.459985 [  384/ 1020]\n",
            "loss: 0.418626 [  704/ 1020]\n",
            "loss: 1.128632 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.1%, Avg loss: 6.209537 \n",
            "\n",
            "Epoch 116 \n",
            " ---------------------------------------\n",
            "loss: 0.458507 [   64/ 1020]\n",
            "loss: 0.585539 [  384/ 1020]\n",
            "loss: 0.823131 [  704/ 1020]\n",
            "loss: 0.507532 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.0%, Avg loss: 6.029335 \n",
            "\n",
            "Epoch 117 \n",
            " ---------------------------------------\n",
            "loss: 0.634372 [   64/ 1020]\n",
            "loss: 0.324956 [  384/ 1020]\n",
            "loss: 0.454016 [  704/ 1020]\n",
            "loss: 0.475294 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.3%, Avg loss: 5.894436 \n",
            "\n",
            "Epoch 118 \n",
            " ---------------------------------------\n",
            "loss: 0.361373 [   64/ 1020]\n",
            "loss: 0.667144 [  384/ 1020]\n",
            "loss: 0.428504 [  704/ 1020]\n",
            "loss: 0.389431 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.6%, Avg loss: 6.080319 \n",
            "\n",
            "Epoch 119 \n",
            " ---------------------------------------\n",
            "loss: 0.507307 [   64/ 1020]\n",
            "loss: 0.997308 [  384/ 1020]\n",
            "loss: 0.306300 [  704/ 1020]\n",
            "loss: 0.421097 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.8%, Avg loss: 6.073098 \n",
            "\n",
            "Epoch 120 \n",
            " ---------------------------------------\n",
            "loss: 0.427548 [   64/ 1020]\n",
            "loss: 0.460006 [  384/ 1020]\n",
            "loss: 0.556217 [  704/ 1020]\n",
            "loss: 0.593412 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.5%, Avg loss: 6.224272 \n",
            "\n",
            "Epoch 121 \n",
            " ---------------------------------------\n",
            "loss: 0.555838 [   64/ 1020]\n",
            "loss: 0.437690 [  384/ 1020]\n",
            "loss: 0.271502 [  704/ 1020]\n",
            "loss: 0.283610 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.9%, Avg loss: 6.450605 \n",
            "\n",
            "Epoch 122 \n",
            " ---------------------------------------\n",
            "loss: 0.430453 [   64/ 1020]\n",
            "loss: 0.355533 [  384/ 1020]\n",
            "loss: 0.572706 [  704/ 1020]\n",
            "loss: 0.412715 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.8%, Avg loss: 6.547604 \n",
            "\n",
            "Epoch 123 \n",
            " ---------------------------------------\n",
            "loss: 0.329449 [   64/ 1020]\n",
            "loss: 0.204726 [  384/ 1020]\n",
            "loss: 0.404438 [  704/ 1020]\n",
            "loss: 0.753104 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.7%, Avg loss: 6.584940 \n",
            "\n",
            "Epoch 124 \n",
            " ---------------------------------------\n",
            "loss: 0.551489 [   64/ 1020]\n",
            "loss: 0.384114 [  384/ 1020]\n",
            "loss: 0.599027 [  704/ 1020]\n",
            "loss: 0.483011 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.9%, Avg loss: 6.689090 \n",
            "\n",
            "Epoch 125 \n",
            " ---------------------------------------\n",
            "loss: 0.199943 [   64/ 1020]\n",
            "loss: 0.525070 [  384/ 1020]\n",
            "loss: 0.529530 [  704/ 1020]\n",
            "loss: 0.328785 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.7%, Avg loss: 6.792184 \n",
            "\n",
            "Epoch 126 \n",
            " ---------------------------------------\n",
            "loss: 0.388300 [   64/ 1020]\n",
            "loss: 0.613136 [  384/ 1020]\n",
            "loss: 0.732223 [  704/ 1020]\n",
            "loss: 0.459850 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.3%, Avg loss: 6.896752 \n",
            "\n",
            "Epoch 127 \n",
            " ---------------------------------------\n",
            "loss: 0.545858 [   64/ 1020]\n",
            "loss: 0.550089 [  384/ 1020]\n",
            "loss: 0.461692 [  704/ 1020]\n",
            "loss: 0.443775 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.3%, Avg loss: 6.427603 \n",
            "\n",
            "Epoch 128 \n",
            " ---------------------------------------\n",
            "loss: 0.284664 [   64/ 1020]\n",
            "loss: 0.462573 [  384/ 1020]\n",
            "loss: 0.737208 [  704/ 1020]\n",
            "loss: 0.436368 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.2%, Avg loss: 6.205618 \n",
            "\n",
            "Epoch 129 \n",
            " ---------------------------------------\n",
            "loss: 0.329292 [   64/ 1020]\n",
            "loss: 0.447259 [  384/ 1020]\n",
            "loss: 0.495706 [  704/ 1020]\n",
            "loss: 0.430194 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.7%, Avg loss: 6.733414 \n",
            "\n",
            "Epoch 130 \n",
            " ---------------------------------------\n",
            "loss: 0.276152 [   64/ 1020]\n",
            "loss: 0.446985 [  384/ 1020]\n",
            "loss: 0.382274 [  704/ 1020]\n",
            "loss: 0.589373 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.7%, Avg loss: 6.480082 \n",
            "\n",
            "Epoch 131 \n",
            " ---------------------------------------\n",
            "loss: 0.344453 [   64/ 1020]\n",
            "loss: 0.439310 [  384/ 1020]\n",
            "loss: 0.504315 [  704/ 1020]\n",
            "loss: 0.466134 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.1%, Avg loss: 6.512730 \n",
            "\n",
            "Epoch 132 \n",
            " ---------------------------------------\n",
            "loss: 0.468686 [   64/ 1020]\n",
            "loss: 0.463817 [  384/ 1020]\n",
            "loss: 0.378643 [  704/ 1020]\n",
            "loss: 0.625338 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.8%, Avg loss: 6.838483 \n",
            "\n",
            "Epoch 133 \n",
            " ---------------------------------------\n",
            "loss: 0.591938 [   64/ 1020]\n",
            "loss: 0.533900 [  384/ 1020]\n",
            "loss: 0.193451 [  704/ 1020]\n",
            "loss: 0.461918 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.6%, Avg loss: 6.433669 \n",
            "\n",
            "Epoch 134 \n",
            " ---------------------------------------\n",
            "loss: 0.245909 [   64/ 1020]\n",
            "loss: 0.386838 [  384/ 1020]\n",
            "loss: 0.788999 [  704/ 1020]\n",
            "loss: 0.136251 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.3%, Avg loss: 6.325385 \n",
            "\n",
            "Epoch 135 \n",
            " ---------------------------------------\n",
            "loss: 0.543857 [   64/ 1020]\n",
            "loss: 0.329099 [  384/ 1020]\n",
            "loss: 0.466941 [  704/ 1020]\n",
            "loss: 0.917496 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.7%, Avg loss: 6.713074 \n",
            "\n",
            "Epoch 136 \n",
            " ---------------------------------------\n",
            "loss: 0.525813 [   64/ 1020]\n",
            "loss: 0.288403 [  384/ 1020]\n",
            "loss: 0.249316 [  704/ 1020]\n",
            "loss: 0.502690 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.7%, Avg loss: 6.511266 \n",
            "\n",
            "Epoch 137 \n",
            " ---------------------------------------\n",
            "loss: 0.517675 [   64/ 1020]\n",
            "loss: 0.246025 [  384/ 1020]\n",
            "loss: 0.363140 [  704/ 1020]\n",
            "loss: 0.453032 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.0%, Avg loss: 6.613981 \n",
            "\n",
            "Epoch 138 \n",
            " ---------------------------------------\n",
            "loss: 0.453175 [   64/ 1020]\n",
            "loss: 0.371983 [  384/ 1020]\n",
            "loss: 0.210584 [  704/ 1020]\n",
            "loss: 0.710512 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.7%, Avg loss: 6.378400 \n",
            "\n",
            "Epoch 139 \n",
            " ---------------------------------------\n",
            "loss: 0.451579 [   64/ 1020]\n",
            "loss: 0.369839 [  384/ 1020]\n",
            "loss: 0.283402 [  704/ 1020]\n",
            "loss: 0.399503 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.3%, Avg loss: 6.797016 \n",
            "\n",
            "Epoch 140 \n",
            " ---------------------------------------\n",
            "loss: 0.675471 [   64/ 1020]\n",
            "loss: 0.560786 [  384/ 1020]\n",
            "loss: 0.728959 [  704/ 1020]\n",
            "loss: 0.424146 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.1%, Avg loss: 6.690074 \n",
            "\n",
            "Epoch 141 \n",
            " ---------------------------------------\n",
            "loss: 0.812160 [   64/ 1020]\n",
            "loss: 0.670581 [  384/ 1020]\n",
            "loss: 0.367249 [  704/ 1020]\n",
            "loss: 0.673903 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.2%, Avg loss: 6.248829 \n",
            "\n",
            "Epoch 142 \n",
            " ---------------------------------------\n",
            "loss: 0.156711 [   64/ 1020]\n",
            "loss: 0.413425 [  384/ 1020]\n",
            "loss: 0.397436 [  704/ 1020]\n",
            "loss: 0.560675 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.1%, Avg loss: 6.614802 \n",
            "\n",
            "Epoch 143 \n",
            " ---------------------------------------\n",
            "loss: 0.221543 [   64/ 1020]\n",
            "loss: 0.308948 [  384/ 1020]\n",
            "loss: 0.692293 [  704/ 1020]\n",
            "loss: 0.497947 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.3%, Avg loss: 6.911324 \n",
            "\n",
            "Epoch 144 \n",
            " ---------------------------------------\n",
            "loss: 0.364185 [   64/ 1020]\n",
            "loss: 0.581280 [  384/ 1020]\n",
            "loss: 0.268833 [  704/ 1020]\n",
            "loss: 0.283473 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.1%, Avg loss: 7.025858 \n",
            "\n",
            "Epoch 145 \n",
            " ---------------------------------------\n",
            "loss: 0.138360 [   64/ 1020]\n",
            "loss: 0.565433 [  384/ 1020]\n",
            "loss: 0.208518 [  704/ 1020]\n",
            "loss: 0.275164 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.9%, Avg loss: 7.083990 \n",
            "\n",
            "Epoch 146 \n",
            " ---------------------------------------\n",
            "loss: 0.347575 [   64/ 1020]\n",
            "loss: 0.324746 [  384/ 1020]\n",
            "loss: 0.260423 [  704/ 1020]\n",
            "loss: 0.313119 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.9%, Avg loss: 7.065357 \n",
            "\n",
            "Epoch 147 \n",
            " ---------------------------------------\n",
            "loss: 0.511758 [   64/ 1020]\n",
            "loss: 0.346344 [  384/ 1020]\n",
            "loss: 0.373165 [  704/ 1020]\n",
            "loss: 0.406732 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.2%, Avg loss: 6.829322 \n",
            "\n",
            "Epoch 148 \n",
            " ---------------------------------------\n",
            "loss: 0.148341 [   64/ 1020]\n",
            "loss: 0.435816 [  384/ 1020]\n",
            "loss: 0.573953 [  704/ 1020]\n",
            "loss: 0.516344 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.0%, Avg loss: 6.325879 \n",
            "\n",
            "Epoch 149 \n",
            " ---------------------------------------\n",
            "loss: 0.252713 [   64/ 1020]\n",
            "loss: 0.096357 [  384/ 1020]\n",
            "loss: 0.371217 [  704/ 1020]\n",
            "loss: 0.445644 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.3%, Avg loss: 6.649349 \n",
            "\n",
            "Epoch 150 \n",
            " ---------------------------------------\n",
            "loss: 0.366917 [   64/ 1020]\n",
            "loss: 0.276676 [  384/ 1020]\n",
            "loss: 0.311169 [  704/ 1020]\n",
            "loss: 0.420287 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.3%, Avg loss: 6.480528 \n",
            "\n",
            "Epoch 151 \n",
            " ---------------------------------------\n",
            "loss: 0.228261 [   64/ 1020]\n",
            "loss: 0.250155 [  384/ 1020]\n",
            "loss: 0.558053 [  704/ 1020]\n",
            "loss: 0.532805 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.8%, Avg loss: 7.141294 \n",
            "\n",
            "Epoch 152 \n",
            " ---------------------------------------\n",
            "loss: 0.626251 [   64/ 1020]\n",
            "loss: 0.457863 [  384/ 1020]\n",
            "loss: 0.380112 [  704/ 1020]\n",
            "loss: 0.621047 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.2%, Avg loss: 6.850084 \n",
            "\n",
            "Epoch 153 \n",
            " ---------------------------------------\n",
            "loss: 0.273920 [   64/ 1020]\n",
            "loss: 0.243386 [  384/ 1020]\n",
            "loss: 0.265005 [  704/ 1020]\n",
            "loss: 0.516634 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.1%, Avg loss: 6.503292 \n",
            "\n",
            "Epoch 154 \n",
            " ---------------------------------------\n",
            "loss: 0.336559 [   64/ 1020]\n",
            "loss: 0.589495 [  384/ 1020]\n",
            "loss: 0.719223 [  704/ 1020]\n",
            "loss: 0.404596 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.4%, Avg loss: 7.085521 \n",
            "\n",
            "Epoch 155 \n",
            " ---------------------------------------\n",
            "loss: 0.304078 [   64/ 1020]\n",
            "loss: 0.193773 [  384/ 1020]\n",
            "loss: 0.322650 [  704/ 1020]\n",
            "loss: 0.236169 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.7%, Avg loss: 7.029584 \n",
            "\n",
            "Epoch 156 \n",
            " ---------------------------------------\n",
            "loss: 0.506120 [   64/ 1020]\n",
            "loss: 0.238128 [  384/ 1020]\n",
            "loss: 0.385945 [  704/ 1020]\n",
            "loss: 0.221147 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.0%, Avg loss: 6.591920 \n",
            "\n",
            "Epoch 157 \n",
            " ---------------------------------------\n",
            "loss: 0.274695 [   64/ 1020]\n",
            "loss: 0.360183 [  384/ 1020]\n",
            "loss: 0.473095 [  704/ 1020]\n",
            "loss: 0.299108 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.1%, Avg loss: 6.400980 \n",
            "\n",
            "Epoch 158 \n",
            " ---------------------------------------\n",
            "loss: 0.505164 [   64/ 1020]\n",
            "loss: 0.315743 [  384/ 1020]\n",
            "loss: 0.280078 [  704/ 1020]\n",
            "loss: 0.441631 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.8%, Avg loss: 6.211582 \n",
            "\n",
            "Epoch 159 \n",
            " ---------------------------------------\n",
            "loss: 0.324688 [   64/ 1020]\n",
            "loss: 0.330635 [  384/ 1020]\n",
            "loss: 0.371097 [  704/ 1020]\n",
            "loss: 0.226149 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.4%, Avg loss: 6.736120 \n",
            "\n",
            "Epoch 160 \n",
            " ---------------------------------------\n",
            "loss: 0.422941 [   64/ 1020]\n",
            "loss: 0.116630 [  384/ 1020]\n",
            "loss: 0.363274 [  704/ 1020]\n",
            "loss: 0.370003 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.1%, Avg loss: 6.743065 \n",
            "\n",
            "Epoch 161 \n",
            " ---------------------------------------\n",
            "loss: 0.504526 [   64/ 1020]\n",
            "loss: 0.225675 [  384/ 1020]\n",
            "loss: 0.284092 [  704/ 1020]\n",
            "loss: 0.591631 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.9%, Avg loss: 6.832150 \n",
            "\n",
            "Epoch 162 \n",
            " ---------------------------------------\n",
            "loss: 0.419367 [   64/ 1020]\n",
            "loss: 0.516050 [  384/ 1020]\n",
            "loss: 0.440503 [  704/ 1020]\n",
            "loss: 0.334640 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.3%, Avg loss: 6.842247 \n",
            "\n",
            "Epoch 163 \n",
            " ---------------------------------------\n",
            "loss: 0.140554 [   64/ 1020]\n",
            "loss: 0.240766 [  384/ 1020]\n",
            "loss: 0.423414 [  704/ 1020]\n",
            "loss: 0.376641 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.8%, Avg loss: 7.436227 \n",
            "\n",
            "Epoch 164 \n",
            " ---------------------------------------\n",
            "loss: 0.285200 [   64/ 1020]\n",
            "loss: 0.244391 [  384/ 1020]\n",
            "loss: 0.483483 [  704/ 1020]\n",
            "loss: 0.532784 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.8%, Avg loss: 7.161983 \n",
            "\n",
            "Epoch 165 \n",
            " ---------------------------------------\n",
            "loss: 0.355632 [   64/ 1020]\n",
            "loss: 0.211955 [  384/ 1020]\n",
            "loss: 0.407892 [  704/ 1020]\n",
            "loss: 0.683553 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.8%, Avg loss: 6.358959 \n",
            "\n",
            "Epoch 166 \n",
            " ---------------------------------------\n",
            "loss: 0.326643 [   64/ 1020]\n",
            "loss: 0.376385 [  384/ 1020]\n",
            "loss: 0.387740 [  704/ 1020]\n",
            "loss: 0.210983 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.5%, Avg loss: 6.715450 \n",
            "\n",
            "Epoch 167 \n",
            " ---------------------------------------\n",
            "loss: 0.270350 [   64/ 1020]\n",
            "loss: 0.314139 [  384/ 1020]\n",
            "loss: 0.445140 [  704/ 1020]\n",
            "loss: 0.333191 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.8%, Avg loss: 6.854052 \n",
            "\n",
            "Epoch 168 \n",
            " ---------------------------------------\n",
            "loss: 0.203435 [   64/ 1020]\n",
            "loss: 0.218692 [  384/ 1020]\n",
            "loss: 0.113821 [  704/ 1020]\n",
            "loss: 0.430737 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.9%, Avg loss: 7.078262 \n",
            "\n",
            "Epoch 169 \n",
            " ---------------------------------------\n",
            "loss: 0.421679 [   64/ 1020]\n",
            "loss: 0.604663 [  384/ 1020]\n",
            "loss: 0.406874 [  704/ 1020]\n",
            "loss: 0.791951 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.2%, Avg loss: 6.896730 \n",
            "\n",
            "Epoch 170 \n",
            " ---------------------------------------\n",
            "loss: 0.258609 [   64/ 1020]\n",
            "loss: 0.298364 [  384/ 1020]\n",
            "loss: 0.575476 [  704/ 1020]\n",
            "loss: 0.239345 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.6%, Avg loss: 6.808902 \n",
            "\n",
            "Epoch 171 \n",
            " ---------------------------------------\n",
            "loss: 0.310070 [   64/ 1020]\n",
            "loss: 0.190402 [  384/ 1020]\n",
            "loss: 0.149926 [  704/ 1020]\n",
            "loss: 0.358047 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.2%, Avg loss: 6.959994 \n",
            "\n",
            "Epoch 172 \n",
            " ---------------------------------------\n",
            "loss: 0.158364 [   64/ 1020]\n",
            "loss: 0.543169 [  384/ 1020]\n",
            "loss: 0.100473 [  704/ 1020]\n",
            "loss: 0.891216 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.0%, Avg loss: 7.076866 \n",
            "\n",
            "Epoch 173 \n",
            " ---------------------------------------\n",
            "loss: 0.547184 [   64/ 1020]\n",
            "loss: 0.458806 [  384/ 1020]\n",
            "loss: 0.249787 [  704/ 1020]\n",
            "loss: 0.136540 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.7%, Avg loss: 6.901916 \n",
            "\n",
            "Epoch 174 \n",
            " ---------------------------------------\n",
            "loss: 0.229549 [   64/ 1020]\n",
            "loss: 0.546869 [  384/ 1020]\n",
            "loss: 0.338111 [  704/ 1020]\n",
            "loss: 0.375860 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.0%, Avg loss: 6.665645 \n",
            "\n",
            "Epoch 175 \n",
            " ---------------------------------------\n",
            "loss: 0.297814 [   64/ 1020]\n",
            "loss: 0.479617 [  384/ 1020]\n",
            "loss: 0.336021 [  704/ 1020]\n",
            "loss: 0.160507 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.0%, Avg loss: 6.769903 \n",
            "\n",
            "Epoch 176 \n",
            " ---------------------------------------\n",
            "loss: 0.110476 [   64/ 1020]\n",
            "loss: 0.254992 [  384/ 1020]\n",
            "loss: 0.374679 [  704/ 1020]\n",
            "loss: 0.675995 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.6%, Avg loss: 7.203467 \n",
            "\n",
            "Epoch 177 \n",
            " ---------------------------------------\n",
            "loss: 0.305538 [   64/ 1020]\n",
            "loss: 0.307820 [  384/ 1020]\n",
            "loss: 0.280841 [  704/ 1020]\n",
            "loss: 0.180208 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.3%, Avg loss: 6.735014 \n",
            "\n",
            "Epoch 178 \n",
            " ---------------------------------------\n",
            "loss: 0.222107 [   64/ 1020]\n",
            "loss: 0.473770 [  384/ 1020]\n",
            "loss: 0.369643 [  704/ 1020]\n",
            "loss: 0.358344 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.2%, Avg loss: 6.933696 \n",
            "\n",
            "Epoch 179 \n",
            " ---------------------------------------\n",
            "loss: 0.340830 [   64/ 1020]\n",
            "loss: 0.243206 [  384/ 1020]\n",
            "loss: 0.614116 [  704/ 1020]\n",
            "loss: 0.210118 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.2%, Avg loss: 7.151052 \n",
            "\n",
            "Epoch 180 \n",
            " ---------------------------------------\n",
            "loss: 0.178460 [   64/ 1020]\n",
            "loss: 0.105919 [  384/ 1020]\n",
            "loss: 0.547102 [  704/ 1020]\n",
            "loss: 0.375308 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.2%, Avg loss: 7.227824 \n",
            "\n",
            "Epoch 181 \n",
            " ---------------------------------------\n",
            "loss: 0.348632 [   64/ 1020]\n",
            "loss: 0.473405 [  384/ 1020]\n",
            "loss: 0.439791 [  704/ 1020]\n",
            "loss: 0.191439 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.1%, Avg loss: 6.943533 \n",
            "\n",
            "Epoch 182 \n",
            " ---------------------------------------\n",
            "loss: 0.507027 [   64/ 1020]\n",
            "loss: 0.259597 [  384/ 1020]\n",
            "loss: 0.289041 [  704/ 1020]\n",
            "loss: 0.187699 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.3%, Avg loss: 7.058953 \n",
            "\n",
            "Epoch 183 \n",
            " ---------------------------------------\n",
            "loss: 0.199592 [   64/ 1020]\n",
            "loss: 0.157038 [  384/ 1020]\n",
            "loss: 0.553662 [  704/ 1020]\n",
            "loss: 0.536281 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.1%, Avg loss: 6.878950 \n",
            "\n",
            "Epoch 184 \n",
            " ---------------------------------------\n",
            "loss: 0.138095 [   64/ 1020]\n",
            "loss: 0.333880 [  384/ 1020]\n",
            "loss: 0.146498 [  704/ 1020]\n",
            "loss: 0.215401 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.4%, Avg loss: 7.468392 \n",
            "\n",
            "Epoch 185 \n",
            " ---------------------------------------\n",
            "loss: 0.579427 [   64/ 1020]\n",
            "loss: 0.172931 [  384/ 1020]\n",
            "loss: 0.223022 [  704/ 1020]\n",
            "loss: 0.613609 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.1%, Avg loss: 7.473503 \n",
            "\n",
            "Epoch 186 \n",
            " ---------------------------------------\n",
            "loss: 0.302953 [   64/ 1020]\n",
            "loss: 0.368738 [  384/ 1020]\n",
            "loss: 0.260932 [  704/ 1020]\n",
            "loss: 0.320421 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.4%, Avg loss: 6.598309 \n",
            "\n",
            "Epoch 187 \n",
            " ---------------------------------------\n",
            "loss: 0.259258 [   64/ 1020]\n",
            "loss: 0.200152 [  384/ 1020]\n",
            "loss: 0.302659 [  704/ 1020]\n",
            "loss: 0.388822 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.9%, Avg loss: 7.161385 \n",
            "\n",
            "Epoch 188 \n",
            " ---------------------------------------\n",
            "loss: 0.072406 [   64/ 1020]\n",
            "loss: 0.463375 [  384/ 1020]\n",
            "loss: 0.207116 [  704/ 1020]\n",
            "loss: 0.135912 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.4%, Avg loss: 7.019671 \n",
            "\n",
            "Epoch 189 \n",
            " ---------------------------------------\n",
            "loss: 0.276691 [   64/ 1020]\n",
            "loss: 0.362298 [  384/ 1020]\n",
            "loss: 0.104240 [  704/ 1020]\n",
            "loss: 0.287577 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.8%, Avg loss: 6.871052 \n",
            "\n",
            "Epoch 190 \n",
            " ---------------------------------------\n",
            "loss: 0.336922 [   64/ 1020]\n",
            "loss: 0.327811 [  384/ 1020]\n",
            "loss: 0.229978 [  704/ 1020]\n",
            "loss: 0.324577 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.5%, Avg loss: 7.500802 \n",
            "\n",
            "Epoch 191 \n",
            " ---------------------------------------\n",
            "loss: 0.322502 [   64/ 1020]\n",
            "loss: 0.464181 [  384/ 1020]\n",
            "loss: 0.493742 [  704/ 1020]\n",
            "loss: 0.253846 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.6%, Avg loss: 6.982003 \n",
            "\n",
            "Epoch 192 \n",
            " ---------------------------------------\n",
            "loss: 0.289721 [   64/ 1020]\n",
            "loss: 0.257454 [  384/ 1020]\n",
            "loss: 0.085131 [  704/ 1020]\n",
            "loss: 0.227851 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.6%, Avg loss: 7.041894 \n",
            "\n",
            "Epoch 193 \n",
            " ---------------------------------------\n",
            "loss: 0.272480 [   64/ 1020]\n",
            "loss: 0.374529 [  384/ 1020]\n",
            "loss: 0.393380 [  704/ 1020]\n",
            "loss: 0.278636 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.3%, Avg loss: 7.225166 \n",
            "\n",
            "Epoch 194 \n",
            " ---------------------------------------\n",
            "loss: 0.483434 [   64/ 1020]\n",
            "loss: 0.231176 [  384/ 1020]\n",
            "loss: 0.248017 [  704/ 1020]\n",
            "loss: 0.610169 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.0%, Avg loss: 7.706577 \n",
            "\n",
            "Epoch 195 \n",
            " ---------------------------------------\n",
            "loss: 0.333558 [   64/ 1020]\n",
            "loss: 0.105885 [  384/ 1020]\n",
            "loss: 0.250745 [  704/ 1020]\n",
            "loss: 0.319738 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.0%, Avg loss: 7.677371 \n",
            "\n",
            "Epoch 196 \n",
            " ---------------------------------------\n",
            "loss: 0.077254 [   64/ 1020]\n",
            "loss: 0.216341 [  384/ 1020]\n",
            "loss: 0.415806 [  704/ 1020]\n",
            "loss: 0.310096 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.9%, Avg loss: 7.188494 \n",
            "\n",
            "Epoch 197 \n",
            " ---------------------------------------\n",
            "loss: 0.127185 [   64/ 1020]\n",
            "loss: 0.407504 [  384/ 1020]\n",
            "loss: 0.171545 [  704/ 1020]\n",
            "loss: 0.336788 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.7%, Avg loss: 7.680292 \n",
            "\n",
            "Epoch 198 \n",
            " ---------------------------------------\n",
            "loss: 0.156152 [   64/ 1020]\n",
            "loss: 0.342734 [  384/ 1020]\n",
            "loss: 0.307114 [  704/ 1020]\n",
            "loss: 0.384318 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.3%, Avg loss: 7.518392 \n",
            "\n",
            "Epoch 199 \n",
            " ---------------------------------------\n",
            "loss: 0.197210 [   64/ 1020]\n",
            "loss: 0.239552 [  384/ 1020]\n",
            "loss: 0.117262 [  704/ 1020]\n",
            "loss: 0.272314 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.5%, Avg loss: 7.924668 \n",
            "\n",
            "Epoch 200 \n",
            " ---------------------------------------\n",
            "loss: 0.129433 [   64/ 1020]\n",
            "loss: 0.497574 [  384/ 1020]\n",
            "loss: 0.157851 [  704/ 1020]\n",
            "loss: 0.390602 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.8%, Avg loss: 7.021854 \n",
            "\n",
            "Testing -----------------------\n",
            "Test Error: \n",
            " Accuracy: 33.4%, Avg loss: 7.620603 \n",
            "\n",
            "Done!!!!\n"
          ]
        }
      ],
      "source": [
        "epochs = 200\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1} \\n ---------------------------------------\")\n",
        "  training_data = datasets.Flowers102(root=\"dataset\", split=\"train\", transform=train_transform, download=True)\n",
        "  train_dataloader = DataLoader(training_data, batch_size = batch_size, shuffle=True)\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "  test(val_dataloader, model, loss_fn)\n",
        "print(\"Testing -----------------------\")\n",
        "test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!!!!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPLv63xb+XVGRvnO/O2B1bT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}