{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erha500/IMLO-Open-Assessment/blob/main/IMLO_Open_Assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MGJhK0Wy6U2-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as T\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1FLWsWbK-ylG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5215b4a-f825-4e6b-ac99-0f32aa5a65e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\erhan\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#transform function with augmentations to be used on training set\n",
        "train_transform_augment = v2.Compose([\n",
        "    v2.Resize([224,224]),\n",
        "    v2.RandomHorizontalFlip(0.5),\n",
        "    v2.RandomRotation(45),\n",
        "    v2.ToTensor(),\n",
        "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "#transform function without augmentations to be used on validation and test sets\n",
        "test_transform = v2.Compose([\n",
        "  v2.Resize([224,224]),\n",
        "  v2.ToTensor(),\n",
        "  v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWVmTrcs9QGM"
      },
      "source": [
        "Downloading Flowers102 dataset from datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2AG1ERmI9WXU"
      },
      "outputs": [],
      "source": [
        "training_data_augment = datasets.Flowers102(root=\"dataset\", split=\"train\", transform=train_transform_augment, download=True)\n",
        "\n",
        "val_data = datasets.Flowers102(root=\"dataset\", split=\"val\", transform=test_transform, download=True)\n",
        "\n",
        "test_data = datasets.Flowers102(root=\"dataset\", split=\"test\", transform=test_transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EiOOyavq-T-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de17f32-fcb2-4fd2-b6d7-13ebdee137f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 3, 224, 224])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "#Create data loaders\n",
        "train_dataloader = DataLoader(training_data_augment, batch_size = batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "  print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3fL6F9TLEdDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4461880e-8487-4e51-f99b-5dae16ff89c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU()\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): ReLU()\n",
            "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (16): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (18): ReLU()\n",
            "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU()\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Flatten(start_dim=1, end_dim=-1)\n",
            "    (25): Linear(in_features=4608, out_features=1024, bias=True)\n",
            "    (26): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): ReLU()\n",
            "    (28): Dropout(p=0.15, inplace=False)\n",
            "    (29): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (30): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (31): ReLU()\n",
            "    (32): Dropout(p=0.15, inplace=False)\n",
            "    (33): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (34): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (35): ReLU()\n",
            "    (36): Dropout(p=0.15, inplace=False)\n",
            "    (37): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (38): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU()\n",
            "    (40): Dropout(p=0.15, inplace=False)\n",
            "    (41): Linear(in_features=128, out_features=102, bias=True)\n",
            "    (42): BatchNorm1d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (43): ReLU()\n",
            "    (44): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "#Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "      #Convolutional layers\n",
        "      nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      nn.Conv2d(64,64, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      nn.Conv2d(128,128, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(256),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      nn.Conv2d(256,512, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(512),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      #Linear layers\n",
        "      nn.Flatten(),\n",
        "\n",
        "      nn.Linear(512 * 3 * 3, 1024),\n",
        "      nn.BatchNorm1d(1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.15),\n",
        "\n",
        "      nn.Linear(1024, 512),\n",
        "      nn.BatchNorm1d(512),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.15),\n",
        "\n",
        "      nn.Linear(512,256),\n",
        "      nn.BatchNorm1d(256),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.15),\n",
        "\n",
        "      nn.Linear(256,128),\n",
        "      nn.BatchNorm1d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.15),\n",
        "\n",
        "      nn.Linear(128,102),\n",
        "      nn.BatchNorm1d(102),\n",
        "      nn.ReLU(),\n",
        "\n",
        "      nn.LogSoftmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9IvJsfvwE0VG"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.005) #weight decay is L2 regularisation\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=5, factor=0.5) #scheduler to reduce learning rate during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "o4bMoWUAE1kO"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    #Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 5 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "y4Mf49itE3A-"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct) :>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    accuracy = 100 * correct\n",
        "    return accuracy, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Xr7VD7E3E5y1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f30874-30d9-4f07-eb52-48a404472cc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            " ---------------------------------------\n",
            "loss: 4.866370 [   64/ 1020]\n",
            "loss: 4.719733 [  384/ 1020]\n",
            "loss: 4.533412 [  704/ 1020]\n",
            "loss: 4.462550 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 3.8%, Avg loss: 4.526966 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 2 \n",
            " ---------------------------------------\n",
            "loss: 4.545269 [   64/ 1020]\n",
            "loss: 4.291059 [  384/ 1020]\n",
            "loss: 4.427072 [  704/ 1020]\n",
            "loss: 4.425832 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 8.0%, Avg loss: 4.239967 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 3 \n",
            " ---------------------------------------\n",
            "loss: 3.955077 [   64/ 1020]\n",
            "loss: 4.113866 [  384/ 1020]\n",
            "loss: 4.179543 [  704/ 1020]\n",
            "loss: 3.969239 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 11.0%, Avg loss: 4.023171 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 4 \n",
            " ---------------------------------------\n",
            "loss: 3.936655 [   64/ 1020]\n",
            "loss: 3.787292 [  384/ 1020]\n",
            "loss: 3.715247 [  704/ 1020]\n",
            "loss: 3.767992 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 15.7%, Avg loss: 3.820350 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 5 \n",
            " ---------------------------------------\n",
            "loss: 3.598139 [   64/ 1020]\n",
            "loss: 3.692185 [  384/ 1020]\n",
            "loss: 3.689452 [  704/ 1020]\n",
            "loss: 3.450278 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 11.4%, Avg loss: 3.942441 \n",
            "\n",
            "Epoch 6 \n",
            " ---------------------------------------\n",
            "loss: 3.580825 [   64/ 1020]\n",
            "loss: 3.666225 [  384/ 1020]\n",
            "loss: 3.685326 [  704/ 1020]\n",
            "loss: 3.669050 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 18.2%, Avg loss: 3.666122 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 7 \n",
            " ---------------------------------------\n",
            "loss: 3.261278 [   64/ 1020]\n",
            "loss: 3.488325 [  384/ 1020]\n",
            "loss: 3.619515 [  704/ 1020]\n",
            "loss: 3.386561 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 19.1%, Avg loss: 3.652435 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 8 \n",
            " ---------------------------------------\n",
            "loss: 3.207320 [   64/ 1020]\n",
            "loss: 3.072020 [  384/ 1020]\n",
            "loss: 3.583652 [  704/ 1020]\n",
            "loss: 3.371359 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 14.4%, Avg loss: 3.811975 \n",
            "\n",
            "Epoch 9 \n",
            " ---------------------------------------\n",
            "loss: 3.171812 [   64/ 1020]\n",
            "loss: 3.415972 [  384/ 1020]\n",
            "loss: 3.410874 [  704/ 1020]\n",
            "loss: 3.387482 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 14.8%, Avg loss: 3.711543 \n",
            "\n",
            "Epoch 10 \n",
            " ---------------------------------------\n",
            "loss: 2.992387 [   64/ 1020]\n",
            "loss: 2.953587 [  384/ 1020]\n",
            "loss: 3.379197 [  704/ 1020]\n",
            "loss: 3.105154 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 13.4%, Avg loss: 3.953478 \n",
            "\n",
            "Epoch 11 \n",
            " ---------------------------------------\n",
            "loss: 3.052661 [   64/ 1020]\n",
            "loss: 3.201124 [  384/ 1020]\n",
            "loss: 3.235083 [  704/ 1020]\n",
            "loss: 3.028156 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 22.8%, Avg loss: 3.430946 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 12 \n",
            " ---------------------------------------\n",
            "loss: 2.907218 [   64/ 1020]\n",
            "loss: 2.993772 [  384/ 1020]\n",
            "loss: 2.996834 [  704/ 1020]\n",
            "loss: 3.083649 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 20.2%, Avg loss: 3.480283 \n",
            "\n",
            "Epoch 13 \n",
            " ---------------------------------------\n",
            "loss: 2.993709 [   64/ 1020]\n",
            "loss: 2.820190 [  384/ 1020]\n",
            "loss: 2.931804 [  704/ 1020]\n",
            "loss: 2.911902 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 20.2%, Avg loss: 3.448028 \n",
            "\n",
            "Epoch 14 \n",
            " ---------------------------------------\n",
            "loss: 3.046424 [   64/ 1020]\n",
            "loss: 2.720728 [  384/ 1020]\n",
            "loss: 2.585079 [  704/ 1020]\n",
            "loss: 2.936305 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.5%, Avg loss: 3.344096 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 15 \n",
            " ---------------------------------------\n",
            "loss: 2.827809 [   64/ 1020]\n",
            "loss: 3.044084 [  384/ 1020]\n",
            "loss: 2.612556 [  704/ 1020]\n",
            "loss: 2.965468 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 16.9%, Avg loss: 3.668230 \n",
            "\n",
            "Epoch 16 \n",
            " ---------------------------------------\n",
            "loss: 2.631367 [   64/ 1020]\n",
            "loss: 2.849861 [  384/ 1020]\n",
            "loss: 2.906157 [  704/ 1020]\n",
            "loss: 3.078189 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 21.1%, Avg loss: 3.362258 \n",
            "\n",
            "Epoch 17 \n",
            " ---------------------------------------\n",
            "loss: 2.554419 [   64/ 1020]\n",
            "loss: 2.700501 [  384/ 1020]\n",
            "loss: 2.687358 [  704/ 1020]\n",
            "loss: 2.888848 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.4%, Avg loss: 3.328388 \n",
            "\n",
            "Epoch 18 \n",
            " ---------------------------------------\n",
            "loss: 2.696876 [   64/ 1020]\n",
            "loss: 2.733319 [  384/ 1020]\n",
            "loss: 2.825226 [  704/ 1020]\n",
            "loss: 2.860978 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.2%, Avg loss: 3.345331 \n",
            "\n",
            "Epoch 19 \n",
            " ---------------------------------------\n",
            "loss: 2.876712 [   64/ 1020]\n",
            "loss: 2.473705 [  384/ 1020]\n",
            "loss: 2.640788 [  704/ 1020]\n",
            "loss: 2.591506 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.9%, Avg loss: 3.311509 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 20 \n",
            " ---------------------------------------\n",
            "loss: 2.413657 [   64/ 1020]\n",
            "loss: 2.788603 [  384/ 1020]\n",
            "loss: 2.317888 [  704/ 1020]\n",
            "loss: 2.564534 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.4%, Avg loss: 3.076126 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 21 \n",
            " ---------------------------------------\n",
            "loss: 2.317833 [   64/ 1020]\n",
            "loss: 2.613588 [  384/ 1020]\n",
            "loss: 2.698439 [  704/ 1020]\n",
            "loss: 2.493301 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.4%, Avg loss: 3.105850 \n",
            "\n",
            "Epoch 22 \n",
            " ---------------------------------------\n",
            "loss: 2.567316 [   64/ 1020]\n",
            "loss: 2.342560 [  384/ 1020]\n",
            "loss: 2.062376 [  704/ 1020]\n",
            "loss: 2.395135 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.4%, Avg loss: 2.980168 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 23 \n",
            " ---------------------------------------\n",
            "loss: 2.095917 [   64/ 1020]\n",
            "loss: 2.328893 [  384/ 1020]\n",
            "loss: 2.541071 [  704/ 1020]\n",
            "loss: 2.610364 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.4%, Avg loss: 3.238466 \n",
            "\n",
            "Epoch 24 \n",
            " ---------------------------------------\n",
            "loss: 2.198529 [   64/ 1020]\n",
            "loss: 2.438480 [  384/ 1020]\n",
            "loss: 2.437580 [  704/ 1020]\n",
            "loss: 2.571620 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.5%, Avg loss: 3.129993 \n",
            "\n",
            "Epoch 25 \n",
            " ---------------------------------------\n",
            "loss: 2.088798 [   64/ 1020]\n",
            "loss: 2.361711 [  384/ 1020]\n",
            "loss: 2.332818 [  704/ 1020]\n",
            "loss: 2.540881 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.5%, Avg loss: 2.943522 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 26 \n",
            " ---------------------------------------\n",
            "loss: 2.039572 [   64/ 1020]\n",
            "loss: 2.217654 [  384/ 1020]\n",
            "loss: 2.504232 [  704/ 1020]\n",
            "loss: 2.133096 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.5%, Avg loss: 3.073600 \n",
            "\n",
            "Epoch 27 \n",
            " ---------------------------------------\n",
            "loss: 2.222663 [   64/ 1020]\n",
            "loss: 1.903483 [  384/ 1020]\n",
            "loss: 2.344163 [  704/ 1020]\n",
            "loss: 2.296957 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.2%, Avg loss: 2.976583 \n",
            "\n",
            "Epoch 28 \n",
            " ---------------------------------------\n",
            "loss: 1.953288 [   64/ 1020]\n",
            "loss: 2.229627 [  384/ 1020]\n",
            "loss: 2.290021 [  704/ 1020]\n",
            "loss: 2.003435 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.9%, Avg loss: 3.070619 \n",
            "\n",
            "Epoch 29 \n",
            " ---------------------------------------\n",
            "loss: 2.033067 [   64/ 1020]\n",
            "loss: 1.938618 [  384/ 1020]\n",
            "loss: 2.014997 [  704/ 1020]\n",
            "loss: 2.241943 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.2%, Avg loss: 2.945197 \n",
            "\n",
            "Epoch 30 \n",
            " ---------------------------------------\n",
            "loss: 1.756111 [   64/ 1020]\n",
            "loss: 2.228742 [  384/ 1020]\n",
            "loss: 2.017260 [  704/ 1020]\n",
            "loss: 2.518454 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.8%, Avg loss: 3.045141 \n",
            "\n",
            "Epoch 31 \n",
            " ---------------------------------------\n",
            "loss: 1.735307 [   64/ 1020]\n",
            "loss: 1.814350 [  384/ 1020]\n",
            "loss: 2.088485 [  704/ 1020]\n",
            "loss: 2.012482 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.6%, Avg loss: 3.140003 \n",
            "\n",
            "Epoch 32 \n",
            " ---------------------------------------\n",
            "loss: 1.801149 [   64/ 1020]\n",
            "loss: 1.864898 [  384/ 1020]\n",
            "loss: 1.762908 [  704/ 1020]\n",
            "loss: 1.857756 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 40.9%, Avg loss: 2.622724 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 33 \n",
            " ---------------------------------------\n",
            "loss: 1.658151 [   64/ 1020]\n",
            "loss: 1.598894 [  384/ 1020]\n",
            "loss: 1.713233 [  704/ 1020]\n",
            "loss: 1.590743 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 40.8%, Avg loss: 2.649656 \n",
            "\n",
            "Epoch 34 \n",
            " ---------------------------------------\n",
            "loss: 1.523577 [   64/ 1020]\n",
            "loss: 1.757652 [  384/ 1020]\n",
            "loss: 1.644230 [  704/ 1020]\n",
            "loss: 1.723600 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 40.2%, Avg loss: 2.596413 \n",
            "\n",
            "Epoch 35 \n",
            " ---------------------------------------\n",
            "loss: 1.534846 [   64/ 1020]\n",
            "loss: 1.397951 [  384/ 1020]\n",
            "loss: 1.564934 [  704/ 1020]\n",
            "loss: 1.443014 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 42.9%, Avg loss: 2.543241 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 36 \n",
            " ---------------------------------------\n",
            "loss: 1.498436 [   64/ 1020]\n",
            "loss: 1.373916 [  384/ 1020]\n",
            "loss: 1.485981 [  704/ 1020]\n",
            "loss: 1.554388 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.0%, Avg loss: 2.559019 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 37 \n",
            " ---------------------------------------\n",
            "loss: 1.483094 [   64/ 1020]\n",
            "loss: 1.221956 [  384/ 1020]\n",
            "loss: 1.511109 [  704/ 1020]\n",
            "loss: 1.677690 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 41.2%, Avg loss: 2.615476 \n",
            "\n",
            "Epoch 38 \n",
            " ---------------------------------------\n",
            "loss: 1.505660 [   64/ 1020]\n",
            "loss: 1.592071 [  384/ 1020]\n",
            "loss: 1.558493 [  704/ 1020]\n",
            "loss: 1.590348 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 41.1%, Avg loss: 2.605408 \n",
            "\n",
            "Epoch 39 \n",
            " ---------------------------------------\n",
            "loss: 1.356236 [   64/ 1020]\n",
            "loss: 1.417124 [  384/ 1020]\n",
            "loss: 1.425702 [  704/ 1020]\n",
            "loss: 1.464320 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 41.7%, Avg loss: 2.597368 \n",
            "\n",
            "Epoch 40 \n",
            " ---------------------------------------\n",
            "loss: 1.140971 [   64/ 1020]\n",
            "loss: 1.450939 [  384/ 1020]\n",
            "loss: 1.529433 [  704/ 1020]\n",
            "loss: 1.520604 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.8%, Avg loss: 2.474952 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 41 \n",
            " ---------------------------------------\n",
            "loss: 1.291550 [   64/ 1020]\n",
            "loss: 1.296844 [  384/ 1020]\n",
            "loss: 1.407872 [  704/ 1020]\n",
            "loss: 1.469359 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.0%, Avg loss: 2.527946 \n",
            "\n",
            "Epoch 42 \n",
            " ---------------------------------------\n",
            "loss: 1.218107 [   64/ 1020]\n",
            "loss: 1.257758 [  384/ 1020]\n",
            "loss: 1.389885 [  704/ 1020]\n",
            "loss: 1.429116 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 40.5%, Avg loss: 2.642976 \n",
            "\n",
            "Epoch 43 \n",
            " ---------------------------------------\n",
            "loss: 1.185592 [   64/ 1020]\n",
            "loss: 1.363697 [  384/ 1020]\n",
            "loss: 1.508123 [  704/ 1020]\n",
            "loss: 1.342252 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.3%, Avg loss: 2.500278 \n",
            "\n",
            "Epoch 44 \n",
            " ---------------------------------------\n",
            "loss: 1.326674 [   64/ 1020]\n",
            "loss: 1.263773 [  384/ 1020]\n",
            "loss: 1.399451 [  704/ 1020]\n",
            "loss: 1.261795 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.3%, Avg loss: 2.458471 \n",
            "\n",
            "Epoch 45 \n",
            " ---------------------------------------\n",
            "loss: 1.196009 [   64/ 1020]\n",
            "loss: 1.275178 [  384/ 1020]\n",
            "loss: 1.225657 [  704/ 1020]\n",
            "loss: 1.536959 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 43.9%, Avg loss: 2.524078 \n",
            "\n",
            "Epoch 46 \n",
            " ---------------------------------------\n",
            "loss: 1.339587 [   64/ 1020]\n",
            "loss: 1.005165 [  384/ 1020]\n",
            "loss: 1.160470 [  704/ 1020]\n",
            "loss: 1.292341 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 43.0%, Avg loss: 2.523505 \n",
            "\n",
            "Epoch 47 \n",
            " ---------------------------------------\n",
            "loss: 1.134649 [   64/ 1020]\n",
            "loss: 1.017900 [  384/ 1020]\n",
            "loss: 1.130547 [  704/ 1020]\n",
            "loss: 1.131868 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.0%, Avg loss: 2.451660 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 48 \n",
            " ---------------------------------------\n",
            "loss: 1.406857 [   64/ 1020]\n",
            "loss: 1.091352 [  384/ 1020]\n",
            "loss: 1.101377 [  704/ 1020]\n",
            "loss: 1.334546 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 45.0%, Avg loss: 2.492099 \n",
            "\n",
            "Epoch 49 \n",
            " ---------------------------------------\n",
            "loss: 1.126024 [   64/ 1020]\n",
            "loss: 1.132850 [  384/ 1020]\n",
            "loss: 1.190582 [  704/ 1020]\n",
            "loss: 1.283195 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.0%, Avg loss: 2.455243 \n",
            "\n",
            "Epoch 50 \n",
            " ---------------------------------------\n",
            "loss: 1.273936 [   64/ 1020]\n",
            "loss: 1.297264 [  384/ 1020]\n",
            "loss: 1.152607 [  704/ 1020]\n",
            "loss: 1.134238 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.0%, Avg loss: 2.410858 \n",
            "\n",
            "Epoch 51 \n",
            " ---------------------------------------\n",
            "loss: 0.965080 [   64/ 1020]\n",
            "loss: 1.010893 [  384/ 1020]\n",
            "loss: 1.223636 [  704/ 1020]\n",
            "loss: 1.013739 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 46.3%, Avg loss: 2.457594 \n",
            "\n",
            "Epoch 52 \n",
            " ---------------------------------------\n",
            "loss: 1.058303 [   64/ 1020]\n",
            "loss: 1.086571 [  384/ 1020]\n",
            "loss: 1.125229 [  704/ 1020]\n",
            "loss: 1.282320 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.7%, Avg loss: 2.371943 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 53 \n",
            " ---------------------------------------\n",
            "loss: 1.176182 [   64/ 1020]\n",
            "loss: 0.885308 [  384/ 1020]\n",
            "loss: 0.950316 [  704/ 1020]\n",
            "loss: 0.968001 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.6%, Avg loss: 2.408796 \n",
            "\n",
            "Epoch 54 \n",
            " ---------------------------------------\n",
            "loss: 0.973835 [   64/ 1020]\n",
            "loss: 0.875996 [  384/ 1020]\n",
            "loss: 1.119537 [  704/ 1020]\n",
            "loss: 1.251877 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 41.3%, Avg loss: 2.660138 \n",
            "\n",
            "Epoch 55 \n",
            " ---------------------------------------\n",
            "loss: 0.892713 [   64/ 1020]\n",
            "loss: 1.083436 [  384/ 1020]\n",
            "loss: 1.241467 [  704/ 1020]\n",
            "loss: 1.004682 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 48.0%, Avg loss: 2.333679 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 56 \n",
            " ---------------------------------------\n",
            "loss: 1.038957 [   64/ 1020]\n",
            "loss: 1.224319 [  384/ 1020]\n",
            "loss: 0.985847 [  704/ 1020]\n",
            "loss: 0.999642 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.0%, Avg loss: 2.394608 \n",
            "\n",
            "Epoch 57 \n",
            " ---------------------------------------\n",
            "loss: 0.922845 [   64/ 1020]\n",
            "loss: 0.940428 [  384/ 1020]\n",
            "loss: 0.983648 [  704/ 1020]\n",
            "loss: 0.765195 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 46.1%, Avg loss: 2.394594 \n",
            "\n",
            "Epoch 58 \n",
            " ---------------------------------------\n",
            "loss: 0.925955 [   64/ 1020]\n",
            "loss: 1.160412 [  384/ 1020]\n",
            "loss: 0.807420 [  704/ 1020]\n",
            "loss: 1.137678 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.2%, Avg loss: 2.481563 \n",
            "\n",
            "Epoch 59 \n",
            " ---------------------------------------\n",
            "loss: 0.835626 [   64/ 1020]\n",
            "loss: 0.892988 [  384/ 1020]\n",
            "loss: 1.027251 [  704/ 1020]\n",
            "loss: 0.932205 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.5%, Avg loss: 2.361906 \n",
            "\n",
            "Epoch 60 \n",
            " ---------------------------------------\n",
            "loss: 0.779577 [   64/ 1020]\n",
            "loss: 0.933016 [  384/ 1020]\n",
            "loss: 0.875614 [  704/ 1020]\n",
            "loss: 0.770490 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 51.1%, Avg loss: 2.342057 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 61 \n",
            " ---------------------------------------\n",
            "loss: 0.704711 [   64/ 1020]\n",
            "loss: 0.869529 [  384/ 1020]\n",
            "loss: 1.054509 [  704/ 1020]\n",
            "loss: 1.027261 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.8%, Avg loss: 2.470795 \n",
            "\n",
            "Epoch 62 \n",
            " ---------------------------------------\n",
            "loss: 0.878779 [   64/ 1020]\n",
            "loss: 1.087506 [  384/ 1020]\n",
            "loss: 0.826845 [  704/ 1020]\n",
            "loss: 0.923629 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.1%, Avg loss: 2.145352 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 63 \n",
            " ---------------------------------------\n",
            "loss: 0.739114 [   64/ 1020]\n",
            "loss: 0.661324 [  384/ 1020]\n",
            "loss: 0.732990 [  704/ 1020]\n",
            "loss: 0.936569 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.8%, Avg loss: 2.124843 \n",
            "\n",
            "Epoch 64 \n",
            " ---------------------------------------\n",
            "loss: 1.029325 [   64/ 1020]\n",
            "loss: 0.773379 [  384/ 1020]\n",
            "loss: 0.686069 [  704/ 1020]\n",
            "loss: 0.775146 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.1%, Avg loss: 2.129653 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 65 \n",
            " ---------------------------------------\n",
            "loss: 0.680919 [   64/ 1020]\n",
            "loss: 0.560724 [  384/ 1020]\n",
            "loss: 0.603719 [  704/ 1020]\n",
            "loss: 0.626128 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.3%, Avg loss: 2.099569 \n",
            "\n",
            "Epoch 66 \n",
            " ---------------------------------------\n",
            "loss: 0.671883 [   64/ 1020]\n",
            "loss: 0.664840 [  384/ 1020]\n",
            "loss: 0.575678 [  704/ 1020]\n",
            "loss: 0.735088 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.2%, Avg loss: 2.107574 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 67 \n",
            " ---------------------------------------\n",
            "loss: 0.630958 [   64/ 1020]\n",
            "loss: 0.628449 [  384/ 1020]\n",
            "loss: 0.458173 [  704/ 1020]\n",
            "loss: 0.672865 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.5%, Avg loss: 2.080833 \n",
            "\n",
            "Epoch 68 \n",
            " ---------------------------------------\n",
            "loss: 0.619790 [   64/ 1020]\n",
            "loss: 0.555325 [  384/ 1020]\n",
            "loss: 0.647058 [  704/ 1020]\n",
            "loss: 0.555959 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.2%, Avg loss: 2.089802 \n",
            "\n",
            "Epoch 69 \n",
            " ---------------------------------------\n",
            "loss: 0.599962 [   64/ 1020]\n",
            "loss: 0.665937 [  384/ 1020]\n",
            "loss: 0.614824 [  704/ 1020]\n",
            "loss: 0.600468 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 56.3%, Avg loss: 2.078617 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 70 \n",
            " ---------------------------------------\n",
            "loss: 0.623519 [   64/ 1020]\n",
            "loss: 0.550499 [  384/ 1020]\n",
            "loss: 0.772429 [  704/ 1020]\n",
            "loss: 0.675081 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.1%, Avg loss: 2.155474 \n",
            "\n",
            "Epoch 71 \n",
            " ---------------------------------------\n",
            "loss: 0.718376 [   64/ 1020]\n",
            "loss: 0.554516 [  384/ 1020]\n",
            "loss: 0.622467 [  704/ 1020]\n",
            "loss: 0.671239 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.5%, Avg loss: 2.177890 \n",
            "\n",
            "Epoch 72 \n",
            " ---------------------------------------\n",
            "loss: 0.590318 [   64/ 1020]\n",
            "loss: 0.464245 [  384/ 1020]\n",
            "loss: 0.478851 [  704/ 1020]\n",
            "loss: 0.739292 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.3%, Avg loss: 2.118481 \n",
            "\n",
            "Epoch 73 \n",
            " ---------------------------------------\n",
            "loss: 0.711572 [   64/ 1020]\n",
            "loss: 0.518992 [  384/ 1020]\n",
            "loss: 0.622243 [  704/ 1020]\n",
            "loss: 0.628394 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.7%, Avg loss: 2.141929 \n",
            "\n",
            "Epoch 74 \n",
            " ---------------------------------------\n",
            "loss: 0.629201 [   64/ 1020]\n",
            "loss: 0.576280 [  384/ 1020]\n",
            "loss: 0.507993 [  704/ 1020]\n",
            "loss: 0.623221 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.5%, Avg loss: 2.143745 \n",
            "\n",
            "Epoch 75 \n",
            " ---------------------------------------\n",
            "loss: 0.723438 [   64/ 1020]\n",
            "loss: 0.569839 [  384/ 1020]\n",
            "loss: 0.599386 [  704/ 1020]\n",
            "loss: 0.704244 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.3%, Avg loss: 2.145075 \n",
            "\n",
            "Epoch 76 \n",
            " ---------------------------------------\n",
            "loss: 0.445072 [   64/ 1020]\n",
            "loss: 0.453655 [  384/ 1020]\n",
            "loss: 0.634503 [  704/ 1020]\n",
            "loss: 0.569538 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.6%, Avg loss: 2.036797 \n",
            "\n",
            "Epoch 77 \n",
            " ---------------------------------------\n",
            "loss: 0.695422 [   64/ 1020]\n",
            "loss: 0.458414 [  384/ 1020]\n",
            "loss: 0.529207 [  704/ 1020]\n",
            "loss: 0.494463 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 57.0%, Avg loss: 2.015161 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 78 \n",
            " ---------------------------------------\n",
            "loss: 0.675773 [   64/ 1020]\n",
            "loss: 0.522045 [  384/ 1020]\n",
            "loss: 0.464868 [  704/ 1020]\n",
            "loss: 0.482317 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 58.2%, Avg loss: 2.001710 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 79 \n",
            " ---------------------------------------\n",
            "loss: 0.391089 [   64/ 1020]\n",
            "loss: 0.471570 [  384/ 1020]\n",
            "loss: 0.500040 [  704/ 1020]\n",
            "loss: 0.539166 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 57.4%, Avg loss: 2.010571 \n",
            "\n",
            "Epoch 80 \n",
            " ---------------------------------------\n",
            "loss: 0.468077 [   64/ 1020]\n",
            "loss: 0.621760 [  384/ 1020]\n",
            "loss: 0.570649 [  704/ 1020]\n",
            "loss: 0.547282 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 58.3%, Avg loss: 1.999808 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 81 \n",
            " ---------------------------------------\n",
            "loss: 0.354685 [   64/ 1020]\n",
            "loss: 0.406238 [  384/ 1020]\n",
            "loss: 0.468670 [  704/ 1020]\n",
            "loss: 0.438375 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 59.2%, Avg loss: 1.979731 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 82 \n",
            " ---------------------------------------\n",
            "loss: 0.473819 [   64/ 1020]\n",
            "loss: 0.540764 [  384/ 1020]\n",
            "loss: 0.508110 [  704/ 1020]\n",
            "loss: 0.470787 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 2.014471 \n",
            "\n",
            "Epoch 83 \n",
            " ---------------------------------------\n",
            "loss: 0.462747 [   64/ 1020]\n",
            "loss: 0.420338 [  384/ 1020]\n",
            "loss: 0.439177 [  704/ 1020]\n",
            "loss: 0.470936 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 2.046013 \n",
            "\n",
            "Epoch 84 \n",
            " ---------------------------------------\n",
            "loss: 0.554155 [   64/ 1020]\n",
            "loss: 0.506243 [  384/ 1020]\n",
            "loss: 0.420513 [  704/ 1020]\n",
            "loss: 0.551428 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 2.000405 \n",
            "\n",
            "Epoch 85 \n",
            " ---------------------------------------\n",
            "loss: 0.381193 [   64/ 1020]\n",
            "loss: 0.454531 [  384/ 1020]\n",
            "loss: 0.492411 [  704/ 1020]\n",
            "loss: 0.415625 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 58.1%, Avg loss: 1.980320 \n",
            "\n",
            "Epoch 86 \n",
            " ---------------------------------------\n",
            "loss: 0.493652 [   64/ 1020]\n",
            "loss: 0.491274 [  384/ 1020]\n",
            "loss: 0.410419 [  704/ 1020]\n",
            "loss: 0.472743 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 57.9%, Avg loss: 1.990853 \n",
            "\n",
            "Epoch 87 \n",
            " ---------------------------------------\n",
            "loss: 0.413594 [   64/ 1020]\n",
            "loss: 0.480047 [  384/ 1020]\n",
            "loss: 0.419227 [  704/ 1020]\n",
            "loss: 0.519639 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 2.006344 \n",
            "\n",
            "Epoch 88 \n",
            " ---------------------------------------\n",
            "loss: 0.510443 [   64/ 1020]\n",
            "loss: 0.456594 [  384/ 1020]\n",
            "loss: 0.429220 [  704/ 1020]\n",
            "loss: 0.449155 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 59.5%, Avg loss: 1.962893 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 89 \n",
            " ---------------------------------------\n",
            "loss: 0.297156 [   64/ 1020]\n",
            "loss: 0.392512 [  384/ 1020]\n",
            "loss: 0.532288 [  704/ 1020]\n",
            "loss: 0.448614 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 59.1%, Avg loss: 1.961239 \n",
            "\n",
            "Epoch 90 \n",
            " ---------------------------------------\n",
            "loss: 0.330221 [   64/ 1020]\n",
            "loss: 0.366527 [  384/ 1020]\n",
            "loss: 0.353794 [  704/ 1020]\n",
            "loss: 0.444978 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 60.2%, Avg loss: 1.946624 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 91 \n",
            " ---------------------------------------\n",
            "loss: 0.301970 [   64/ 1020]\n",
            "loss: 0.494603 [  384/ 1020]\n",
            "loss: 0.483612 [  704/ 1020]\n",
            "loss: 0.471082 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 60.4%, Avg loss: 1.959062 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 92 \n",
            " ---------------------------------------\n",
            "loss: 0.377004 [   64/ 1020]\n",
            "loss: 0.350853 [  384/ 1020]\n",
            "loss: 0.404010 [  704/ 1020]\n",
            "loss: 0.446935 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 59.9%, Avg loss: 1.954257 \n",
            "\n",
            "Epoch 93 \n",
            " ---------------------------------------\n",
            "loss: 0.409289 [   64/ 1020]\n",
            "loss: 0.565729 [  384/ 1020]\n",
            "loss: 0.383450 [  704/ 1020]\n",
            "loss: 0.419261 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 60.3%, Avg loss: 1.965561 \n",
            "\n",
            "Epoch 94 \n",
            " ---------------------------------------\n",
            "loss: 0.416363 [   64/ 1020]\n",
            "loss: 0.540134 [  384/ 1020]\n",
            "loss: 0.611957 [  704/ 1020]\n",
            "loss: 0.457025 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 58.9%, Avg loss: 1.943363 \n",
            "\n",
            "Epoch 95 \n",
            " ---------------------------------------\n",
            "loss: 0.363795 [   64/ 1020]\n",
            "loss: 0.460376 [  384/ 1020]\n",
            "loss: 0.408954 [  704/ 1020]\n",
            "loss: 0.451828 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 60.5%, Avg loss: 1.945141 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 96 \n",
            " ---------------------------------------\n",
            "loss: 0.339062 [   64/ 1020]\n",
            "loss: 0.449406 [  384/ 1020]\n",
            "loss: 0.567497 [  704/ 1020]\n",
            "loss: 0.391409 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 59.8%, Avg loss: 1.930281 \n",
            "\n",
            "Epoch 97 \n",
            " ---------------------------------------\n",
            "loss: 0.317296 [   64/ 1020]\n",
            "loss: 0.498088 [  384/ 1020]\n",
            "loss: 0.371661 [  704/ 1020]\n",
            "loss: 0.423165 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 60.9%, Avg loss: 1.902896 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 98 \n",
            " ---------------------------------------\n",
            "loss: 0.363147 [   64/ 1020]\n",
            "loss: 0.408422 [  384/ 1020]\n",
            "loss: 0.369739 [  704/ 1020]\n",
            "loss: 0.417412 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.0%, Avg loss: 1.919815 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 99 \n",
            " ---------------------------------------\n",
            "loss: 0.362667 [   64/ 1020]\n",
            "loss: 0.321645 [  384/ 1020]\n",
            "loss: 0.474076 [  704/ 1020]\n",
            "loss: 0.469886 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 60.6%, Avg loss: 1.923008 \n",
            "\n",
            "Epoch 100 \n",
            " ---------------------------------------\n",
            "loss: 0.316903 [   64/ 1020]\n",
            "loss: 0.444109 [  384/ 1020]\n",
            "loss: 0.381424 [  704/ 1020]\n",
            "loss: 0.413979 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 59.7%, Avg loss: 1.932396 \n",
            "\n",
            "Epoch 101 \n",
            " ---------------------------------------\n",
            "loss: 0.373028 [   64/ 1020]\n",
            "loss: 0.423939 [  384/ 1020]\n",
            "loss: 0.351462 [  704/ 1020]\n",
            "loss: 0.345083 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 60.0%, Avg loss: 1.941014 \n",
            "\n",
            "Epoch 102 \n",
            " ---------------------------------------\n",
            "loss: 0.353986 [   64/ 1020]\n",
            "loss: 0.341519 [  384/ 1020]\n",
            "loss: 0.520666 [  704/ 1020]\n",
            "loss: 0.539294 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 59.2%, Avg loss: 1.941658 \n",
            "\n",
            "Epoch 103 \n",
            " ---------------------------------------\n",
            "loss: 0.317563 [   64/ 1020]\n",
            "loss: 0.410743 [  384/ 1020]\n",
            "loss: 0.428858 [  704/ 1020]\n",
            "loss: 0.401286 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 60.7%, Avg loss: 1.921597 \n",
            "\n",
            "Epoch 104 \n",
            " ---------------------------------------\n",
            "loss: 0.512888 [   64/ 1020]\n",
            "loss: 0.447655 [  384/ 1020]\n",
            "loss: 0.559730 [  704/ 1020]\n",
            "loss: 0.403900 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.3%, Avg loss: 1.910836 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 105 \n",
            " ---------------------------------------\n",
            "loss: 0.449530 [   64/ 1020]\n",
            "loss: 0.356252 [  384/ 1020]\n",
            "loss: 0.383266 [  704/ 1020]\n",
            "loss: 0.511745 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 60.5%, Avg loss: 1.912064 \n",
            "\n",
            "Epoch 106 \n",
            " ---------------------------------------\n",
            "loss: 0.413972 [   64/ 1020]\n",
            "loss: 0.504876 [  384/ 1020]\n",
            "loss: 0.504846 [  704/ 1020]\n",
            "loss: 0.405607 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.0%, Avg loss: 1.900599 \n",
            "\n",
            "Epoch 107 \n",
            " ---------------------------------------\n",
            "loss: 0.420423 [   64/ 1020]\n",
            "loss: 0.346152 [  384/ 1020]\n",
            "loss: 0.521558 [  704/ 1020]\n",
            "loss: 0.406127 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.2%, Avg loss: 1.898609 \n",
            "\n",
            "Epoch 108 \n",
            " ---------------------------------------\n",
            "loss: 0.432839 [   64/ 1020]\n",
            "loss: 0.493026 [  384/ 1020]\n",
            "loss: 0.470053 [  704/ 1020]\n",
            "loss: 0.451819 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 60.8%, Avg loss: 1.902912 \n",
            "\n",
            "Epoch 109 \n",
            " ---------------------------------------\n",
            "loss: 0.405319 [   64/ 1020]\n",
            "loss: 0.400648 [  384/ 1020]\n",
            "loss: 0.457973 [  704/ 1020]\n",
            "loss: 0.407920 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.3%, Avg loss: 1.904773 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 110 \n",
            " ---------------------------------------\n",
            "loss: 0.271950 [   64/ 1020]\n",
            "loss: 0.421851 [  384/ 1020]\n",
            "loss: 0.389028 [  704/ 1020]\n",
            "loss: 0.409975 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 60.8%, Avg loss: 1.918758 \n",
            "\n",
            "Epoch 111 \n",
            " ---------------------------------------\n",
            "loss: 0.395796 [   64/ 1020]\n",
            "loss: 0.325485 [  384/ 1020]\n",
            "loss: 0.477781 [  704/ 1020]\n",
            "loss: 0.407887 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 60.9%, Avg loss: 1.899264 \n",
            "\n",
            "Epoch 112 \n",
            " ---------------------------------------\n",
            "loss: 0.284717 [   64/ 1020]\n",
            "loss: 0.414744 [  384/ 1020]\n",
            "loss: 0.258263 [  704/ 1020]\n",
            "loss: 0.476985 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.6%, Avg loss: 1.901293 \n",
            "\n",
            "Epoch 113 \n",
            " ---------------------------------------\n",
            "loss: 0.436099 [   64/ 1020]\n",
            "loss: 0.447652 [  384/ 1020]\n",
            "loss: 0.482924 [  704/ 1020]\n",
            "loss: 0.347292 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.2%, Avg loss: 1.894338 \n",
            "\n",
            "Epoch 114 \n",
            " ---------------------------------------\n",
            "loss: 0.414033 [   64/ 1020]\n",
            "loss: 0.343374 [  384/ 1020]\n",
            "loss: 0.444037 [  704/ 1020]\n",
            "loss: 0.430982 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.1%, Avg loss: 1.890456 \n",
            "\n",
            "Epoch 115 \n",
            " ---------------------------------------\n",
            "loss: 0.363938 [   64/ 1020]\n",
            "loss: 0.406807 [  384/ 1020]\n",
            "loss: 0.469094 [  704/ 1020]\n",
            "loss: 0.431639 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.5%, Avg loss: 1.889074 \n",
            "\n",
            "Epoch 116 \n",
            " ---------------------------------------\n",
            "loss: 0.369961 [   64/ 1020]\n",
            "loss: 0.327817 [  384/ 1020]\n",
            "loss: 0.387462 [  704/ 1020]\n",
            "loss: 0.568835 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.5%, Avg loss: 1.886555 \n",
            "\n",
            "Epoch 117 \n",
            " ---------------------------------------\n",
            "loss: 0.435609 [   64/ 1020]\n",
            "loss: 0.464535 [  384/ 1020]\n",
            "loss: 0.375309 [  704/ 1020]\n",
            "loss: 0.282101 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 60.6%, Avg loss: 1.897901 \n",
            "\n",
            "Epoch 118 \n",
            " ---------------------------------------\n",
            "loss: 0.431423 [   64/ 1020]\n",
            "loss: 0.371846 [  384/ 1020]\n",
            "loss: 0.310467 [  704/ 1020]\n",
            "loss: 0.354398 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.3%, Avg loss: 1.888802 \n",
            "\n",
            "Epoch 119 \n",
            " ---------------------------------------\n",
            "loss: 0.591380 [   64/ 1020]\n",
            "loss: 0.402998 [  384/ 1020]\n",
            "loss: 0.404077 [  704/ 1020]\n",
            "loss: 0.398227 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 60.6%, Avg loss: 1.895032 \n",
            "\n",
            "Epoch 120 \n",
            " ---------------------------------------\n",
            "loss: 0.290440 [   64/ 1020]\n",
            "loss: 0.381147 [  384/ 1020]\n",
            "loss: 0.381421 [  704/ 1020]\n",
            "loss: 0.290385 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 60.8%, Avg loss: 1.903395 \n",
            "\n",
            "Epoch 121 \n",
            " ---------------------------------------\n",
            "loss: 0.312884 [   64/ 1020]\n",
            "loss: 0.513864 [  384/ 1020]\n",
            "loss: 0.489988 [  704/ 1020]\n",
            "loss: 0.567336 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.1%, Avg loss: 1.899455 \n",
            "\n",
            "Epoch 122 \n",
            " ---------------------------------------\n",
            "loss: 0.335787 [   64/ 1020]\n",
            "loss: 0.529763 [  384/ 1020]\n",
            "loss: 0.482801 [  704/ 1020]\n",
            "loss: 0.467217 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.5%, Avg loss: 1.903430 \n",
            "\n",
            "Epoch 123 \n",
            " ---------------------------------------\n",
            "loss: 0.394105 [   64/ 1020]\n",
            "loss: 0.324419 [  384/ 1020]\n",
            "loss: 0.397692 [  704/ 1020]\n",
            "loss: 0.378608 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.3%, Avg loss: 1.908959 \n",
            "\n",
            "Epoch 124 \n",
            " ---------------------------------------\n",
            "loss: 0.382079 [   64/ 1020]\n",
            "loss: 0.478038 [  384/ 1020]\n",
            "loss: 0.424965 [  704/ 1020]\n",
            "loss: 0.453681 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.3%, Avg loss: 1.903686 \n",
            "\n",
            "Epoch 125 \n",
            " ---------------------------------------\n",
            "loss: 0.411355 [   64/ 1020]\n",
            "loss: 0.315482 [  384/ 1020]\n",
            "loss: 0.442966 [  704/ 1020]\n",
            "loss: 0.465071 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 60.2%, Avg loss: 1.902868 \n",
            "\n",
            "Epoch 126 \n",
            " ---------------------------------------\n",
            "loss: 0.307470 [   64/ 1020]\n",
            "loss: 0.323401 [  384/ 1020]\n",
            "loss: 0.341241 [  704/ 1020]\n",
            "loss: 0.457035 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.2%, Avg loss: 1.906713 \n",
            "\n",
            "Epoch 127 \n",
            " ---------------------------------------\n",
            "loss: 0.372290 [   64/ 1020]\n",
            "loss: 0.369660 [  384/ 1020]\n",
            "loss: 0.387351 [  704/ 1020]\n",
            "loss: 0.433596 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.7%, Avg loss: 1.896663 \n",
            "\n",
            "Epoch 128 \n",
            " ---------------------------------------\n",
            "loss: 0.350713 [   64/ 1020]\n",
            "loss: 0.312163 [  384/ 1020]\n",
            "loss: 0.345939 [  704/ 1020]\n",
            "loss: 0.464142 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.6%, Avg loss: 1.890352 \n",
            "\n",
            "Epoch 129 \n",
            " ---------------------------------------\n",
            "loss: 0.293931 [   64/ 1020]\n",
            "loss: 0.294146 [  384/ 1020]\n",
            "loss: 0.402159 [  704/ 1020]\n",
            "loss: 0.407715 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.4%, Avg loss: 1.887567 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 130 \n",
            " ---------------------------------------\n",
            "loss: 0.452901 [   64/ 1020]\n",
            "loss: 0.407544 [  384/ 1020]\n",
            "loss: 0.473445 [  704/ 1020]\n",
            "loss: 0.420215 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.2%, Avg loss: 1.902492 \n",
            "\n",
            "Epoch 131 \n",
            " ---------------------------------------\n",
            "loss: 0.415824 [   64/ 1020]\n",
            "loss: 0.294915 [  384/ 1020]\n",
            "loss: 0.427180 [  704/ 1020]\n",
            "loss: 0.404280 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.2%, Avg loss: 1.887411 \n",
            "\n",
            "Epoch 132 \n",
            " ---------------------------------------\n",
            "loss: 0.340674 [   64/ 1020]\n",
            "loss: 0.392403 [  384/ 1020]\n",
            "loss: 0.342720 [  704/ 1020]\n",
            "loss: 0.443698 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.7%, Avg loss: 1.898571 \n",
            "\n",
            "Epoch 133 \n",
            " ---------------------------------------\n",
            "loss: 0.417314 [   64/ 1020]\n",
            "loss: 0.295542 [  384/ 1020]\n",
            "loss: 0.427596 [  704/ 1020]\n",
            "loss: 0.533910 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.4%, Avg loss: 1.897082 \n",
            "\n",
            "Epoch 134 \n",
            " ---------------------------------------\n",
            "loss: 0.423468 [   64/ 1020]\n",
            "loss: 0.463905 [  384/ 1020]\n",
            "loss: 0.384522 [  704/ 1020]\n",
            "loss: 0.414990 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.7%, Avg loss: 1.889091 \n",
            "\n",
            "Epoch 135 \n",
            " ---------------------------------------\n",
            "loss: 0.327076 [   64/ 1020]\n",
            "loss: 0.409695 [  384/ 1020]\n",
            "loss: 0.421852 [  704/ 1020]\n",
            "loss: 0.393318 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.8%, Avg loss: 1.893691 \n",
            "\n",
            "Epoch 136 \n",
            " ---------------------------------------\n",
            "loss: 0.485236 [   64/ 1020]\n",
            "loss: 0.297756 [  384/ 1020]\n",
            "loss: 0.359706 [  704/ 1020]\n",
            "loss: 0.511014 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.5%, Avg loss: 1.887359 \n",
            "\n",
            "Epoch 137 \n",
            " ---------------------------------------\n",
            "loss: 0.349443 [   64/ 1020]\n",
            "loss: 0.368121 [  384/ 1020]\n",
            "loss: 0.402819 [  704/ 1020]\n",
            "loss: 0.373459 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.0%, Avg loss: 1.887622 \n",
            "\n",
            "Epoch 138 \n",
            " ---------------------------------------\n",
            "loss: 0.473400 [   64/ 1020]\n",
            "loss: 0.405128 [  384/ 1020]\n",
            "loss: 0.313110 [  704/ 1020]\n",
            "loss: 0.525612 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.8%, Avg loss: 1.885956 \n",
            "\n",
            "Epoch 139 \n",
            " ---------------------------------------\n",
            "loss: 0.450348 [   64/ 1020]\n",
            "loss: 0.356698 [  384/ 1020]\n",
            "loss: 0.324179 [  704/ 1020]\n",
            "loss: 0.530942 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.6%, Avg loss: 1.887148 \n",
            "\n",
            "Epoch 140 \n",
            " ---------------------------------------\n",
            "loss: 0.394086 [   64/ 1020]\n",
            "loss: 0.377239 [  384/ 1020]\n",
            "loss: 0.352459 [  704/ 1020]\n",
            "loss: 0.456909 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.0%, Avg loss: 1.878265 \n",
            "\n",
            "Epoch 141 \n",
            " ---------------------------------------\n",
            "loss: 0.361793 [   64/ 1020]\n",
            "loss: 0.442789 [  384/ 1020]\n",
            "loss: 0.311705 [  704/ 1020]\n",
            "loss: 0.318464 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.5%, Avg loss: 1.883536 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 142 \n",
            " ---------------------------------------\n",
            "loss: 0.309574 [   64/ 1020]\n",
            "loss: 0.424211 [  384/ 1020]\n",
            "loss: 0.403530 [  704/ 1020]\n",
            "loss: 0.514202 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.9%, Avg loss: 1.884813 \n",
            "\n",
            "Epoch 143 \n",
            " ---------------------------------------\n",
            "loss: 0.412382 [   64/ 1020]\n",
            "loss: 0.415430 [  384/ 1020]\n",
            "loss: 0.411943 [  704/ 1020]\n",
            "loss: 0.471231 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.9%, Avg loss: 1.885428 \n",
            "\n",
            "Epoch 144 \n",
            " ---------------------------------------\n",
            "loss: 0.362017 [   64/ 1020]\n",
            "loss: 0.369757 [  384/ 1020]\n",
            "loss: 0.398698 [  704/ 1020]\n",
            "loss: 0.468015 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.5%, Avg loss: 1.878874 \n",
            "\n",
            "Epoch 145 \n",
            " ---------------------------------------\n",
            "loss: 0.521590 [   64/ 1020]\n",
            "loss: 0.371407 [  384/ 1020]\n",
            "loss: 0.488407 [  704/ 1020]\n",
            "loss: 0.438696 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.2%, Avg loss: 1.876982 \n",
            "\n",
            "Epoch 146 \n",
            " ---------------------------------------\n",
            "loss: 0.428618 [   64/ 1020]\n",
            "loss: 0.352940 [  384/ 1020]\n",
            "loss: 0.353117 [  704/ 1020]\n",
            "loss: 0.482677 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.2%, Avg loss: 1.883516 \n",
            "\n",
            "Epoch 147 \n",
            " ---------------------------------------\n",
            "loss: 0.408864 [   64/ 1020]\n",
            "loss: 0.463695 [  384/ 1020]\n",
            "loss: 0.426933 [  704/ 1020]\n",
            "loss: 0.396336 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.2%, Avg loss: 1.887201 \n",
            "\n",
            "Epoch 148 \n",
            " ---------------------------------------\n",
            "loss: 0.359668 [   64/ 1020]\n",
            "loss: 0.354926 [  384/ 1020]\n",
            "loss: 0.458008 [  704/ 1020]\n",
            "loss: 0.412071 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.8%, Avg loss: 1.880955 \n",
            "\n",
            "Epoch 149 \n",
            " ---------------------------------------\n",
            "loss: 0.399116 [   64/ 1020]\n",
            "loss: 0.430434 [  384/ 1020]\n",
            "loss: 0.425650 [  704/ 1020]\n",
            "loss: 0.364299 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.3%, Avg loss: 1.879458 \n",
            "\n",
            "Epoch 150 \n",
            " ---------------------------------------\n",
            "loss: 0.349952 [   64/ 1020]\n",
            "loss: 0.387278 [  384/ 1020]\n",
            "loss: 0.350334 [  704/ 1020]\n",
            "loss: 0.371907 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.5%, Avg loss: 1.881930 \n",
            "\n",
            "Epoch 151 \n",
            " ---------------------------------------\n",
            "loss: 0.337416 [   64/ 1020]\n",
            "loss: 0.361215 [  384/ 1020]\n",
            "loss: 0.376588 [  704/ 1020]\n",
            "loss: 0.354332 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.2%, Avg loss: 1.878404 \n",
            "\n",
            "Epoch 152 \n",
            " ---------------------------------------\n",
            "loss: 0.399991 [   64/ 1020]\n",
            "loss: 0.323172 [  384/ 1020]\n",
            "loss: 0.363191 [  704/ 1020]\n",
            "loss: 0.390081 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.6%, Avg loss: 1.882088 \n",
            "\n",
            "Epoch 153 \n",
            " ---------------------------------------\n",
            "loss: 0.419384 [   64/ 1020]\n",
            "loss: 0.322591 [  384/ 1020]\n",
            "loss: 0.350477 [  704/ 1020]\n",
            "loss: 0.325342 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.2%, Avg loss: 1.887550 \n",
            "\n",
            "Epoch 154 \n",
            " ---------------------------------------\n",
            "loss: 0.290694 [   64/ 1020]\n",
            "loss: 0.323393 [  384/ 1020]\n",
            "loss: 0.412393 [  704/ 1020]\n",
            "loss: 0.244003 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.4%, Avg loss: 1.879591 \n",
            "\n",
            "Epoch 155 \n",
            " ---------------------------------------\n",
            "loss: 0.503559 [   64/ 1020]\n",
            "loss: 0.472675 [  384/ 1020]\n",
            "loss: 0.413479 [  704/ 1020]\n",
            "loss: 0.435869 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.6%, Avg loss: 1.881110 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 156 \n",
            " ---------------------------------------\n",
            "loss: 0.340383 [   64/ 1020]\n",
            "loss: 0.402291 [  384/ 1020]\n",
            "loss: 0.327886 [  704/ 1020]\n",
            "loss: 0.379213 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.9%, Avg loss: 1.875575 \n",
            "\n",
            "Epoch 157 \n",
            " ---------------------------------------\n",
            "loss: 0.468308 [   64/ 1020]\n",
            "loss: 0.453442 [  384/ 1020]\n",
            "loss: 0.336184 [  704/ 1020]\n",
            "loss: 0.401755 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.0%, Avg loss: 1.876284 \n",
            "\n",
            "Epoch 158 \n",
            " ---------------------------------------\n",
            "loss: 0.314047 [   64/ 1020]\n",
            "loss: 0.328281 [  384/ 1020]\n",
            "loss: 0.374463 [  704/ 1020]\n",
            "loss: 0.359652 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.5%, Avg loss: 1.881407 \n",
            "\n",
            "Epoch 159 \n",
            " ---------------------------------------\n",
            "loss: 0.353479 [   64/ 1020]\n",
            "loss: 0.335233 [  384/ 1020]\n",
            "loss: 0.403572 [  704/ 1020]\n",
            "loss: 0.399220 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.6%, Avg loss: 1.874263 \n",
            "\n",
            "Epoch 160 \n",
            " ---------------------------------------\n",
            "loss: 0.353954 [   64/ 1020]\n",
            "loss: 0.435419 [  384/ 1020]\n",
            "loss: 0.436404 [  704/ 1020]\n",
            "loss: 0.402657 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.1%, Avg loss: 1.882127 \n",
            "\n",
            "Epoch 161 \n",
            " ---------------------------------------\n",
            "loss: 0.338066 [   64/ 1020]\n",
            "loss: 0.360054 [  384/ 1020]\n",
            "loss: 0.358147 [  704/ 1020]\n",
            "loss: 0.361513 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.0%, Avg loss: 1.881541 \n",
            "\n",
            "Epoch 162 \n",
            " ---------------------------------------\n",
            "loss: 0.409361 [   64/ 1020]\n",
            "loss: 0.456610 [  384/ 1020]\n",
            "loss: 0.273583 [  704/ 1020]\n",
            "loss: 0.370401 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.1%, Avg loss: 1.882475 \n",
            "\n",
            "Epoch 163 \n",
            " ---------------------------------------\n",
            "loss: 0.322538 [   64/ 1020]\n",
            "loss: 0.487325 [  384/ 1020]\n",
            "loss: 0.391231 [  704/ 1020]\n",
            "loss: 0.480224 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.5%, Avg loss: 1.875480 \n",
            "\n",
            "Epoch 164 \n",
            " ---------------------------------------\n",
            "loss: 0.341277 [   64/ 1020]\n",
            "loss: 0.496490 [  384/ 1020]\n",
            "loss: 0.334132 [  704/ 1020]\n",
            "loss: 0.483424 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.0%, Avg loss: 1.884855 \n",
            "\n",
            "Epoch 165 \n",
            " ---------------------------------------\n",
            "loss: 0.434845 [   64/ 1020]\n",
            "loss: 0.343365 [  384/ 1020]\n",
            "loss: 0.387877 [  704/ 1020]\n",
            "loss: 0.436187 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.3%, Avg loss: 1.883301 \n",
            "\n",
            "Epoch 166 \n",
            " ---------------------------------------\n",
            "loss: 0.327879 [   64/ 1020]\n",
            "loss: 0.317736 [  384/ 1020]\n",
            "loss: 0.429482 [  704/ 1020]\n",
            "loss: 0.492702 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.6%, Avg loss: 1.885166 \n",
            "\n",
            "Epoch 167 \n",
            " ---------------------------------------\n",
            "loss: 0.430878 [   64/ 1020]\n",
            "loss: 0.365890 [  384/ 1020]\n",
            "loss: 0.370531 [  704/ 1020]\n",
            "loss: 0.539316 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.2%, Avg loss: 1.869476 \n",
            "\n",
            "Epoch 168 \n",
            " ---------------------------------------\n",
            "loss: 0.416898 [   64/ 1020]\n",
            "loss: 0.319171 [  384/ 1020]\n",
            "loss: 0.347806 [  704/ 1020]\n",
            "loss: 0.428778 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.3%, Avg loss: 1.877357 \n",
            "\n",
            "Epoch 169 \n",
            " ---------------------------------------\n",
            "loss: 0.373626 [   64/ 1020]\n",
            "loss: 0.348242 [  384/ 1020]\n",
            "loss: 0.308035 [  704/ 1020]\n",
            "loss: 0.404277 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.6%, Avg loss: 1.887444 \n",
            "\n",
            "Epoch 170 \n",
            " ---------------------------------------\n",
            "loss: 0.515964 [   64/ 1020]\n",
            "loss: 0.359465 [  384/ 1020]\n",
            "loss: 0.335485 [  704/ 1020]\n",
            "loss: 0.429686 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.5%, Avg loss: 1.874394 \n",
            "\n",
            "Epoch 171 \n",
            " ---------------------------------------\n",
            "loss: 0.375697 [   64/ 1020]\n",
            "loss: 0.248961 [  384/ 1020]\n",
            "loss: 0.407162 [  704/ 1020]\n",
            "loss: 0.370574 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.6%, Avg loss: 1.876034 \n",
            "\n",
            "Epoch 172 \n",
            " ---------------------------------------\n",
            "loss: 0.378898 [   64/ 1020]\n",
            "loss: 0.294787 [  384/ 1020]\n",
            "loss: 0.366781 [  704/ 1020]\n",
            "loss: 0.380077 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.1%, Avg loss: 1.882265 \n",
            "\n",
            "Epoch 173 \n",
            " ---------------------------------------\n",
            "loss: 0.295226 [   64/ 1020]\n",
            "loss: 0.358228 [  384/ 1020]\n",
            "loss: 0.281139 [  704/ 1020]\n",
            "loss: 0.483344 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.5%, Avg loss: 1.881256 \n",
            "\n",
            "Epoch 174 \n",
            " ---------------------------------------\n",
            "loss: 0.385238 [   64/ 1020]\n",
            "loss: 0.277398 [  384/ 1020]\n",
            "loss: 0.428726 [  704/ 1020]\n",
            "loss: 0.432102 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.6%, Avg loss: 1.877510 \n",
            "\n",
            "Epoch 175 \n",
            " ---------------------------------------\n",
            "loss: 0.373268 [   64/ 1020]\n",
            "loss: 0.370671 [  384/ 1020]\n",
            "loss: 0.290554 [  704/ 1020]\n",
            "loss: 0.370271 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 62.1%, Avg loss: 1.878315 \n",
            "\n",
            "Epoch 176 \n",
            " ---------------------------------------\n",
            "loss: 0.359603 [   64/ 1020]\n",
            "loss: 0.393046 [  384/ 1020]\n",
            "loss: 0.323013 [  704/ 1020]\n",
            "loss: 0.366828 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 61.9%, Avg loss: 1.885388 \n",
            "\n",
            "Stopping early\n"
          ]
        }
      ],
      "source": [
        "epochs = 250\n",
        "\n",
        "best_accuracy = 0\n",
        "patience = 20\n",
        "triggers = 0\n",
        "\n",
        "#training loop\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1} \\n ---------------------------------------\")\n",
        "\n",
        "  #train on augmented data\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "\n",
        "  #testing on evaluation data\n",
        "  accuracy, test_loss = test(val_dataloader, model, loss_fn)\n",
        "\n",
        "  scheduler.step(test_loss)\n",
        "\n",
        "  #save the network state at the highest accuracy\n",
        "  if accuracy > best_accuracy:\n",
        "    best_accuracy = accuracy\n",
        "    triggers = 0\n",
        "    torch.save(model.state_dict(), \"model.pb\")\n",
        "    print(\"Saved model at current state\")\n",
        "  else:\n",
        "    triggers += 1\n",
        "\n",
        "  #stop early if the accuracy doesn't improve to prevent overfitting\n",
        "  if triggers > patience:\n",
        "    print(\"Stopping early\")\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing -----------------------\")\n",
        "print(\"Loading state of neural network at highest accuracy...\")\n",
        "model.load_state_dict(torch.load(\"model.pb\"))\n",
        "model.eval()\n",
        "test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m7z80P5yfjJ",
        "outputId": "83873aa9-f653-457e-8acc-789261582f8e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing -----------------------\n",
            "Loading state of neural network at highest accuracy...\n",
            "Test Error: \n",
            " Accuracy: 55.7%, Avg loss: 2.090641 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyO/Qv1I7lw+UkHLyDQgCmTT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}