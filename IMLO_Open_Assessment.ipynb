{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erha500/IMLO-Open-Assessment/blob/main/IMLO_Open_Assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MGJhK0Wy6U2-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as T\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1FLWsWbK-ylG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8791ff45-beb8-4ff8-ee8f-4ab56e28166f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\erhan\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_transform_augment = v2.Compose([\n",
        "    v2.Resize([224,224]),\n",
        "    #v2.RandomPerspective(),\n",
        "    v2.RandomHorizontalFlip(0.5),\n",
        "    v2.RandomRotation(45),\n",
        "    #v2.RandomVerticalFlip(0.5)\n",
        "    #v2.RandomAutocontrast(),\n",
        "    #v2.GaussianBlur(kernel_size=3),\n",
        "    v2.ToTensor(),\n",
        "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_transform = v2.Compose([\n",
        "  v2.Resize([224,224]),\n",
        "  v2.ToTensor(),\n",
        "  v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "test_transform = v2.Compose([\n",
        "  v2.Resize([224,224]),\n",
        "  v2.ToTensor(),\n",
        "  v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWVmTrcs9QGM"
      },
      "source": [
        "Downloading Flowers102 dataset from datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2AG1ERmI9WXU"
      },
      "outputs": [],
      "source": [
        "training_data_augment = datasets.Flowers102(root=\"dataset\", split=\"train\", transform=train_transform_augment, download=True)\n",
        "\n",
        "training_data = datasets.Flowers102(root=\"dataset\", split=\"train\", transform=train_transform, download=True)\n",
        "\n",
        "val_data = datasets.Flowers102(root=\"dataset\", split=\"val\", transform=test_transform, download=True)\n",
        "\n",
        "test_data = datasets.Flowers102(root=\"dataset\", split=\"test\", transform=test_transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EiOOyavq-T-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f939bf4f-b607-4d18-ace1-e93691b14139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 3, 224, 224])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "#Create data loaders\n",
        "train_dataloader = DataLoader(training_data_augment, batch_size = batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "  print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3fL6F9TLEdDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a0c3622-45db-4077-ccf3-8915deff8a81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU()\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): ReLU()\n",
            "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (16): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (18): ReLU()\n",
            "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU()\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Flatten(start_dim=1, end_dim=-1)\n",
            "    (25): Linear(in_features=4608, out_features=1024, bias=True)\n",
            "    (26): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): ReLU()\n",
            "    (28): Dropout(p=0.15, inplace=False)\n",
            "    (29): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (30): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (31): ReLU()\n",
            "    (32): Dropout(p=0.15, inplace=False)\n",
            "    (33): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (34): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (35): ReLU()\n",
            "    (36): Dropout(p=0.15, inplace=False)\n",
            "    (37): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (38): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU()\n",
            "    (40): Dropout(p=0.15, inplace=False)\n",
            "    (41): Linear(in_features=128, out_features=102, bias=True)\n",
            "    (42): BatchNorm1d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (43): ReLU()\n",
            "    (44): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "#Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "      #Convolutional layers\n",
        "      nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      nn.Conv2d(64,64, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      nn.Conv2d(128,128, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(256),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      nn.Conv2d(256,512, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(512),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      #Linear layers\n",
        "      nn.Flatten(),\n",
        "\n",
        "      nn.Linear(512 * 3 * 3, 1024),\n",
        "      nn.BatchNorm1d(1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.15),\n",
        "\n",
        "      nn.Linear(1024, 512),\n",
        "      nn.BatchNorm1d(512),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.15),\n",
        "\n",
        "      nn.Linear(512,256),\n",
        "      nn.BatchNorm1d(256),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.15),\n",
        "\n",
        "      nn.Linear(256,128),\n",
        "      nn.BatchNorm1d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.15),\n",
        "\n",
        "      nn.Linear(128,102),\n",
        "      nn.BatchNorm1d(102),\n",
        "      nn.ReLU(),\n",
        "\n",
        "      nn.LogSoftmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9IvJsfvwE0VG"
      },
      "outputs": [],
      "source": [
        "#loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn = nn.NLLLoss()\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.005) #weight decay is L2 regularisation\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=5, factor=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "o4bMoWUAE1kO"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    #Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 5 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "y4Mf49itE3A-"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct) :>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    accuracy = 100 * correct\n",
        "    return accuracy, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Xr7VD7E3E5y1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1cdd3aa-95db-427f-8eb8-d609a5031ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            " ---------------------------------------\n",
            "loss: 4.883137 [   64/ 1020]\n",
            "loss: 4.743159 [  384/ 1020]\n",
            "loss: 4.671972 [  704/ 1020]\n",
            "loss: 4.664656 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 2.1%, Avg loss: 4.565525 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 2 \n",
            " ---------------------------------------\n",
            "loss: 4.620378 [   64/ 1020]\n",
            "loss: 4.293226 [  384/ 1020]\n",
            "loss: 4.496023 [  704/ 1020]\n",
            "loss: 4.379253 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 6.5%, Avg loss: 4.385546 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 3 \n",
            " ---------------------------------------\n",
            "loss: 4.121545 [   64/ 1020]\n",
            "loss: 4.256337 [  384/ 1020]\n",
            "loss: 4.189755 [  704/ 1020]\n",
            "loss: 4.064929 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 10.4%, Avg loss: 4.076002 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 4 \n",
            " ---------------------------------------\n",
            "loss: 3.809357 [   64/ 1020]\n",
            "loss: 4.102147 [  384/ 1020]\n",
            "loss: 3.825341 [  704/ 1020]\n",
            "loss: 3.877821 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 13.0%, Avg loss: 3.969913 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 5 \n",
            " ---------------------------------------\n",
            "loss: 3.858229 [   64/ 1020]\n",
            "loss: 3.884274 [  384/ 1020]\n",
            "loss: 3.762606 [  704/ 1020]\n",
            "loss: 3.626945 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 12.4%, Avg loss: 3.906115 \n",
            "\n",
            "Epoch 6 \n",
            " ---------------------------------------\n",
            "loss: 3.516148 [   64/ 1020]\n",
            "loss: 3.584176 [  384/ 1020]\n",
            "loss: 3.649332 [  704/ 1020]\n",
            "loss: 3.601135 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 10.9%, Avg loss: 4.012557 \n",
            "\n",
            "Epoch 7 \n",
            " ---------------------------------------\n",
            "loss: 3.607831 [   64/ 1020]\n",
            "loss: 3.501029 [  384/ 1020]\n",
            "loss: 3.521148 [  704/ 1020]\n",
            "loss: 3.321438 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 15.9%, Avg loss: 3.682713 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 8 \n",
            " ---------------------------------------\n",
            "loss: 3.339883 [   64/ 1020]\n",
            "loss: 3.421539 [  384/ 1020]\n",
            "loss: 3.469481 [  704/ 1020]\n",
            "loss: 3.258578 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 3.961166 \n",
            "\n",
            "Epoch 9 \n",
            " ---------------------------------------\n",
            "loss: 3.201960 [   64/ 1020]\n",
            "loss: 3.276497 [  384/ 1020]\n",
            "loss: 3.152868 [  704/ 1020]\n",
            "loss: 3.407949 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 16.8%, Avg loss: 3.722023 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 10 \n",
            " ---------------------------------------\n",
            "loss: 3.079020 [   64/ 1020]\n",
            "loss: 2.894609 [  384/ 1020]\n",
            "loss: 3.064302 [  704/ 1020]\n",
            "loss: 3.274413 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 20.4%, Avg loss: 3.518223 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 11 \n",
            " ---------------------------------------\n",
            "loss: 3.024805 [   64/ 1020]\n",
            "loss: 2.958816 [  384/ 1020]\n",
            "loss: 3.148049 [  704/ 1020]\n",
            "loss: 2.939044 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 22.0%, Avg loss: 3.422424 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 12 \n",
            " ---------------------------------------\n",
            "loss: 3.062896 [   64/ 1020]\n",
            "loss: 2.977826 [  384/ 1020]\n",
            "loss: 3.013213 [  704/ 1020]\n",
            "loss: 2.949102 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.7%, Avg loss: 3.357644 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 13 \n",
            " ---------------------------------------\n",
            "loss: 2.862461 [   64/ 1020]\n",
            "loss: 3.082589 [  384/ 1020]\n",
            "loss: 2.832733 [  704/ 1020]\n",
            "loss: 2.772624 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 22.3%, Avg loss: 3.384194 \n",
            "\n",
            "Epoch 14 \n",
            " ---------------------------------------\n",
            "loss: 2.915241 [   64/ 1020]\n",
            "loss: 2.946164 [  384/ 1020]\n",
            "loss: 2.818806 [  704/ 1020]\n",
            "loss: 2.854964 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 19.4%, Avg loss: 3.497819 \n",
            "\n",
            "Epoch 15 \n",
            " ---------------------------------------\n",
            "loss: 2.942173 [   64/ 1020]\n",
            "loss: 2.494693 [  384/ 1020]\n",
            "loss: 3.181206 [  704/ 1020]\n",
            "loss: 2.675865 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.7%, Avg loss: 3.181469 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 16 \n",
            " ---------------------------------------\n",
            "loss: 2.839827 [   64/ 1020]\n",
            "loss: 2.629098 [  384/ 1020]\n",
            "loss: 2.686750 [  704/ 1020]\n",
            "loss: 3.060913 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.5%, Avg loss: 3.228135 \n",
            "\n",
            "Epoch 17 \n",
            " ---------------------------------------\n",
            "loss: 2.598410 [   64/ 1020]\n",
            "loss: 2.511428 [  384/ 1020]\n",
            "loss: 2.510763 [  704/ 1020]\n",
            "loss: 2.594437 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.4%, Avg loss: 3.213992 \n",
            "\n",
            "Epoch 18 \n",
            " ---------------------------------------\n",
            "loss: 2.669878 [   64/ 1020]\n",
            "loss: 2.350136 [  384/ 1020]\n",
            "loss: 2.711989 [  704/ 1020]\n",
            "loss: 2.529825 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.9%, Avg loss: 3.098806 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 19 \n",
            " ---------------------------------------\n",
            "loss: 2.573129 [   64/ 1020]\n",
            "loss: 2.437088 [  384/ 1020]\n",
            "loss: 2.664029 [  704/ 1020]\n",
            "loss: 2.447390 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.9%, Avg loss: 3.196973 \n",
            "\n",
            "Epoch 20 \n",
            " ---------------------------------------\n",
            "loss: 2.306419 [   64/ 1020]\n",
            "loss: 2.516849 [  384/ 1020]\n",
            "loss: 2.598912 [  704/ 1020]\n",
            "loss: 2.515969 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.5%, Avg loss: 3.128930 \n",
            "\n",
            "Epoch 21 \n",
            " ---------------------------------------\n",
            "loss: 2.593046 [   64/ 1020]\n",
            "loss: 2.307810 [  384/ 1020]\n",
            "loss: 2.123717 [  704/ 1020]\n",
            "loss: 2.381965 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.4%, Avg loss: 3.038287 \n",
            "\n",
            "Epoch 22 \n",
            " ---------------------------------------\n",
            "loss: 2.323952 [   64/ 1020]\n",
            "loss: 2.199755 [  384/ 1020]\n",
            "loss: 2.389429 [  704/ 1020]\n",
            "loss: 2.204187 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.9%, Avg loss: 3.071754 \n",
            "\n",
            "Epoch 23 \n",
            " ---------------------------------------\n",
            "loss: 2.145780 [   64/ 1020]\n",
            "loss: 2.119286 [  384/ 1020]\n",
            "loss: 2.402663 [  704/ 1020]\n",
            "loss: 2.240342 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 33.8%, Avg loss: 2.921157 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 24 \n",
            " ---------------------------------------\n",
            "loss: 2.314674 [   64/ 1020]\n",
            "loss: 2.149854 [  384/ 1020]\n",
            "loss: 2.134835 [  704/ 1020]\n",
            "loss: 2.550573 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.4%, Avg loss: 3.130225 \n",
            "\n",
            "Epoch 25 \n",
            " ---------------------------------------\n",
            "loss: 2.241082 [   64/ 1020]\n",
            "loss: 2.023260 [  384/ 1020]\n",
            "loss: 2.182944 [  704/ 1020]\n",
            "loss: 2.455173 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.3%, Avg loss: 3.234146 \n",
            "\n",
            "Epoch 26 \n",
            " ---------------------------------------\n",
            "loss: 2.210201 [   64/ 1020]\n",
            "loss: 2.054351 [  384/ 1020]\n",
            "loss: 2.021504 [  704/ 1020]\n",
            "loss: 2.113263 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.2%, Avg loss: 3.090207 \n",
            "\n",
            "Epoch 27 \n",
            " ---------------------------------------\n",
            "loss: 2.118487 [   64/ 1020]\n",
            "loss: 2.329412 [  384/ 1020]\n",
            "loss: 2.006966 [  704/ 1020]\n",
            "loss: 2.376109 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.9%, Avg loss: 3.178339 \n",
            "\n",
            "Epoch 28 \n",
            " ---------------------------------------\n",
            "loss: 2.028568 [   64/ 1020]\n",
            "loss: 2.038819 [  384/ 1020]\n",
            "loss: 2.082893 [  704/ 1020]\n",
            "loss: 2.110008 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.1%, Avg loss: 2.892264 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 29 \n",
            " ---------------------------------------\n",
            "loss: 1.771443 [   64/ 1020]\n",
            "loss: 1.744894 [  384/ 1020]\n",
            "loss: 2.169911 [  704/ 1020]\n",
            "loss: 2.112541 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.8%, Avg loss: 3.018742 \n",
            "\n",
            "Epoch 30 \n",
            " ---------------------------------------\n",
            "loss: 1.844856 [   64/ 1020]\n",
            "loss: 2.050598 [  384/ 1020]\n",
            "loss: 1.742854 [  704/ 1020]\n",
            "loss: 2.061683 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.0%, Avg loss: 2.888883 \n",
            "\n",
            "Epoch 31 \n",
            " ---------------------------------------\n",
            "loss: 1.740885 [   64/ 1020]\n",
            "loss: 1.956789 [  384/ 1020]\n",
            "loss: 2.085739 [  704/ 1020]\n",
            "loss: 1.980889 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.2%, Avg loss: 2.850672 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 32 \n",
            " ---------------------------------------\n",
            "loss: 1.775819 [   64/ 1020]\n",
            "loss: 1.812860 [  384/ 1020]\n",
            "loss: 1.967454 [  704/ 1020]\n",
            "loss: 1.798741 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.4%, Avg loss: 2.853006 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 33 \n",
            " ---------------------------------------\n",
            "loss: 1.715169 [   64/ 1020]\n",
            "loss: 1.857769 [  384/ 1020]\n",
            "loss: 1.787541 [  704/ 1020]\n",
            "loss: 1.616624 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.4%, Avg loss: 2.748200 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 34 \n",
            " ---------------------------------------\n",
            "loss: 1.703300 [   64/ 1020]\n",
            "loss: 1.719374 [  384/ 1020]\n",
            "loss: 1.559625 [  704/ 1020]\n",
            "loss: 1.899989 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.6%, Avg loss: 3.049410 \n",
            "\n",
            "Epoch 35 \n",
            " ---------------------------------------\n",
            "loss: 1.748838 [   64/ 1020]\n",
            "loss: 1.593455 [  384/ 1020]\n",
            "loss: 1.745069 [  704/ 1020]\n",
            "loss: 2.159081 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.4%, Avg loss: 2.780136 \n",
            "\n",
            "Epoch 36 \n",
            " ---------------------------------------\n",
            "loss: 1.692338 [   64/ 1020]\n",
            "loss: 1.878624 [  384/ 1020]\n",
            "loss: 1.882397 [  704/ 1020]\n",
            "loss: 1.789539 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.9%, Avg loss: 2.849922 \n",
            "\n",
            "Epoch 37 \n",
            " ---------------------------------------\n",
            "loss: 1.587956 [   64/ 1020]\n",
            "loss: 1.509071 [  384/ 1020]\n",
            "loss: 1.735813 [  704/ 1020]\n",
            "loss: 2.045138 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.9%, Avg loss: 3.012743 \n",
            "\n",
            "Epoch 38 \n",
            " ---------------------------------------\n",
            "loss: 1.760298 [   64/ 1020]\n",
            "loss: 1.576941 [  384/ 1020]\n",
            "loss: 1.796351 [  704/ 1020]\n",
            "loss: 1.616977 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.6%, Avg loss: 2.890847 \n",
            "\n",
            "Epoch 39 \n",
            " ---------------------------------------\n",
            "loss: 1.642296 [   64/ 1020]\n",
            "loss: 1.606577 [  384/ 1020]\n",
            "loss: 1.645159 [  704/ 1020]\n",
            "loss: 1.640647 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 41.9%, Avg loss: 2.610749 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 40 \n",
            " ---------------------------------------\n",
            "loss: 1.437756 [   64/ 1020]\n",
            "loss: 1.258294 [  384/ 1020]\n",
            "loss: 1.681260 [  704/ 1020]\n",
            "loss: 2.007409 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.0%, Avg loss: 2.762547 \n",
            "\n",
            "Epoch 41 \n",
            " ---------------------------------------\n",
            "loss: 1.536196 [   64/ 1020]\n",
            "loss: 1.646241 [  384/ 1020]\n",
            "loss: 1.449214 [  704/ 1020]\n",
            "loss: 1.641568 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.8%, Avg loss: 2.747392 \n",
            "\n",
            "Epoch 42 \n",
            " ---------------------------------------\n",
            "loss: 1.460115 [   64/ 1020]\n",
            "loss: 1.785974 [  384/ 1020]\n",
            "loss: 1.442559 [  704/ 1020]\n",
            "loss: 1.394448 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.1%, Avg loss: 2.801990 \n",
            "\n",
            "Epoch 43 \n",
            " ---------------------------------------\n",
            "loss: 1.692511 [   64/ 1020]\n",
            "loss: 1.811226 [  384/ 1020]\n",
            "loss: 1.784473 [  704/ 1020]\n",
            "loss: 1.406452 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.4%, Avg loss: 2.796358 \n",
            "\n",
            "Epoch 44 \n",
            " ---------------------------------------\n",
            "loss: 1.568660 [   64/ 1020]\n",
            "loss: 1.667869 [  384/ 1020]\n",
            "loss: 1.499735 [  704/ 1020]\n",
            "loss: 1.507205 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 41.0%, Avg loss: 2.655158 \n",
            "\n",
            "Epoch 45 \n",
            " ---------------------------------------\n",
            "loss: 1.336517 [   64/ 1020]\n",
            "loss: 1.453163 [  384/ 1020]\n",
            "loss: 1.462146 [  704/ 1020]\n",
            "loss: 1.474209 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.6%, Avg loss: 2.700762 \n",
            "\n",
            "Epoch 46 \n",
            " ---------------------------------------\n",
            "loss: 1.634283 [   64/ 1020]\n",
            "loss: 1.570687 [  384/ 1020]\n",
            "loss: 1.388123 [  704/ 1020]\n",
            "loss: 1.190748 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 45.7%, Avg loss: 2.398487 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 47 \n",
            " ---------------------------------------\n",
            "loss: 1.265174 [   64/ 1020]\n",
            "loss: 1.079697 [  384/ 1020]\n",
            "loss: 1.024597 [  704/ 1020]\n",
            "loss: 1.054782 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 46.5%, Avg loss: 2.359132 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 48 \n",
            " ---------------------------------------\n",
            "loss: 1.158897 [   64/ 1020]\n",
            "loss: 1.219191 [  384/ 1020]\n",
            "loss: 1.114102 [  704/ 1020]\n",
            "loss: 1.039839 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 50.8%, Avg loss: 2.262121 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 49 \n",
            " ---------------------------------------\n",
            "loss: 1.014546 [   64/ 1020]\n",
            "loss: 0.956761 [  384/ 1020]\n",
            "loss: 0.850859 [  704/ 1020]\n",
            "loss: 0.952540 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.7%, Avg loss: 2.470340 \n",
            "\n",
            "Epoch 50 \n",
            " ---------------------------------------\n",
            "loss: 1.059052 [   64/ 1020]\n",
            "loss: 0.915171 [  384/ 1020]\n",
            "loss: 1.154190 [  704/ 1020]\n",
            "loss: 0.971216 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 46.3%, Avg loss: 2.407842 \n",
            "\n",
            "Epoch 51 \n",
            " ---------------------------------------\n",
            "loss: 1.039743 [   64/ 1020]\n",
            "loss: 0.842977 [  384/ 1020]\n",
            "loss: 0.771269 [  704/ 1020]\n",
            "loss: 0.945438 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 48.0%, Avg loss: 2.340399 \n",
            "\n",
            "Epoch 52 \n",
            " ---------------------------------------\n",
            "loss: 0.884596 [   64/ 1020]\n",
            "loss: 0.962468 [  384/ 1020]\n",
            "loss: 0.892030 [  704/ 1020]\n",
            "loss: 1.021735 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 50.9%, Avg loss: 2.232401 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 53 \n",
            " ---------------------------------------\n",
            "loss: 0.904195 [   64/ 1020]\n",
            "loss: 0.827002 [  384/ 1020]\n",
            "loss: 1.023958 [  704/ 1020]\n",
            "loss: 0.982355 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 48.3%, Avg loss: 2.378356 \n",
            "\n",
            "Epoch 54 \n",
            " ---------------------------------------\n",
            "loss: 0.884353 [   64/ 1020]\n",
            "loss: 0.849796 [  384/ 1020]\n",
            "loss: 1.006900 [  704/ 1020]\n",
            "loss: 1.036215 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 48.0%, Avg loss: 2.346048 \n",
            "\n",
            "Epoch 55 \n",
            " ---------------------------------------\n",
            "loss: 0.886736 [   64/ 1020]\n",
            "loss: 0.884832 [  384/ 1020]\n",
            "loss: 0.931427 [  704/ 1020]\n",
            "loss: 0.856730 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.5%, Avg loss: 2.330972 \n",
            "\n",
            "Epoch 56 \n",
            " ---------------------------------------\n",
            "loss: 0.854320 [   64/ 1020]\n",
            "loss: 0.970239 [  384/ 1020]\n",
            "loss: 1.156015 [  704/ 1020]\n",
            "loss: 1.024658 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.9%, Avg loss: 2.422714 \n",
            "\n",
            "Epoch 57 \n",
            " ---------------------------------------\n",
            "loss: 0.912490 [   64/ 1020]\n",
            "loss: 1.000507 [  384/ 1020]\n",
            "loss: 0.952780 [  704/ 1020]\n",
            "loss: 1.173262 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 45.7%, Avg loss: 2.452227 \n",
            "\n",
            "Epoch 58 \n",
            " ---------------------------------------\n",
            "loss: 0.865671 [   64/ 1020]\n",
            "loss: 0.898398 [  384/ 1020]\n",
            "loss: 0.856901 [  704/ 1020]\n",
            "loss: 0.687959 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.4%, Avg loss: 2.328322 \n",
            "\n",
            "Epoch 59 \n",
            " ---------------------------------------\n",
            "loss: 0.868821 [   64/ 1020]\n",
            "loss: 0.780602 [  384/ 1020]\n",
            "loss: 0.888273 [  704/ 1020]\n",
            "loss: 0.883793 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.0%, Avg loss: 2.172077 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 60 \n",
            " ---------------------------------------\n",
            "loss: 0.834823 [   64/ 1020]\n",
            "loss: 0.795977 [  384/ 1020]\n",
            "loss: 0.648745 [  704/ 1020]\n",
            "loss: 0.830513 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.7%, Avg loss: 2.093318 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 61 \n",
            " ---------------------------------------\n",
            "loss: 0.617327 [   64/ 1020]\n",
            "loss: 0.616558 [  384/ 1020]\n",
            "loss: 0.655980 [  704/ 1020]\n",
            "loss: 0.719876 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.8%, Avg loss: 2.171970 \n",
            "\n",
            "Epoch 62 \n",
            " ---------------------------------------\n",
            "loss: 0.708266 [   64/ 1020]\n",
            "loss: 0.613361 [  384/ 1020]\n",
            "loss: 0.639241 [  704/ 1020]\n",
            "loss: 0.616625 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.5%, Avg loss: 2.106856 \n",
            "\n",
            "Epoch 63 \n",
            " ---------------------------------------\n",
            "loss: 0.580453 [   64/ 1020]\n",
            "loss: 0.554891 [  384/ 1020]\n",
            "loss: 0.633633 [  704/ 1020]\n",
            "loss: 0.660395 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.7%, Avg loss: 2.110605 \n",
            "\n",
            "Epoch 64 \n",
            " ---------------------------------------\n",
            "loss: 0.752112 [   64/ 1020]\n",
            "loss: 0.582254 [  384/ 1020]\n",
            "loss: 0.723683 [  704/ 1020]\n",
            "loss: 0.739452 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.9%, Avg loss: 2.076629 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 65 \n",
            " ---------------------------------------\n",
            "loss: 0.520981 [   64/ 1020]\n",
            "loss: 0.624964 [  384/ 1020]\n",
            "loss: 0.551760 [  704/ 1020]\n",
            "loss: 0.646680 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.7%, Avg loss: 2.178921 \n",
            "\n",
            "Epoch 66 \n",
            " ---------------------------------------\n",
            "loss: 0.530119 [   64/ 1020]\n",
            "loss: 0.676027 [  384/ 1020]\n",
            "loss: 0.517956 [  704/ 1020]\n",
            "loss: 0.692584 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.4%, Avg loss: 2.107805 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 67 \n",
            " ---------------------------------------\n",
            "loss: 0.687780 [   64/ 1020]\n",
            "loss: 0.563777 [  384/ 1020]\n",
            "loss: 0.552061 [  704/ 1020]\n",
            "loss: 0.732446 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.6%, Avg loss: 2.053316 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 68 \n",
            " ---------------------------------------\n",
            "loss: 0.592105 [   64/ 1020]\n",
            "loss: 0.644603 [  384/ 1020]\n",
            "loss: 0.682478 [  704/ 1020]\n",
            "loss: 0.630224 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.7%, Avg loss: 2.114190 \n",
            "\n",
            "Epoch 69 \n",
            " ---------------------------------------\n",
            "loss: 0.498914 [   64/ 1020]\n",
            "loss: 0.502792 [  384/ 1020]\n",
            "loss: 0.604607 [  704/ 1020]\n",
            "loss: 0.630304 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.8%, Avg loss: 2.135929 \n",
            "\n",
            "Epoch 70 \n",
            " ---------------------------------------\n",
            "loss: 0.583503 [   64/ 1020]\n",
            "loss: 0.546930 [  384/ 1020]\n",
            "loss: 0.635613 [  704/ 1020]\n",
            "loss: 0.603952 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.2%, Avg loss: 2.102574 \n",
            "\n",
            "Epoch 71 \n",
            " ---------------------------------------\n",
            "loss: 0.587227 [   64/ 1020]\n",
            "loss: 0.505835 [  384/ 1020]\n",
            "loss: 0.480600 [  704/ 1020]\n",
            "loss: 0.568906 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.1%, Avg loss: 2.147164 \n",
            "\n",
            "Epoch 72 \n",
            " ---------------------------------------\n",
            "loss: 0.684906 [   64/ 1020]\n",
            "loss: 0.533931 [  384/ 1020]\n",
            "loss: 0.567351 [  704/ 1020]\n",
            "loss: 0.688039 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.1%, Avg loss: 2.129698 \n",
            "\n",
            "Epoch 73 \n",
            " ---------------------------------------\n",
            "loss: 0.404103 [   64/ 1020]\n",
            "loss: 0.444968 [  384/ 1020]\n",
            "loss: 0.573744 [  704/ 1020]\n",
            "loss: 0.558591 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.1%, Avg loss: 2.110432 \n",
            "\n",
            "Epoch 74 \n",
            " ---------------------------------------\n",
            "loss: 0.659442 [   64/ 1020]\n",
            "loss: 0.544358 [  384/ 1020]\n",
            "loss: 0.594439 [  704/ 1020]\n",
            "loss: 0.520502 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 56.8%, Avg loss: 2.043097 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 75 \n",
            " ---------------------------------------\n",
            "loss: 0.488334 [   64/ 1020]\n",
            "loss: 0.536445 [  384/ 1020]\n",
            "loss: 0.473089 [  704/ 1020]\n",
            "loss: 0.541858 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 57.5%, Avg loss: 2.004325 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 76 \n",
            " ---------------------------------------\n",
            "loss: 0.385894 [   64/ 1020]\n",
            "loss: 0.575990 [  384/ 1020]\n",
            "loss: 0.409579 [  704/ 1020]\n",
            "loss: 0.475023 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 56.8%, Avg loss: 2.029989 \n",
            "\n",
            "Epoch 77 \n",
            " ---------------------------------------\n",
            "loss: 0.545611 [   64/ 1020]\n",
            "loss: 0.401456 [  384/ 1020]\n",
            "loss: 0.369570 [  704/ 1020]\n",
            "loss: 0.480052 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 1.968442 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 78 \n",
            " ---------------------------------------\n",
            "loss: 0.391774 [   64/ 1020]\n",
            "loss: 0.598547 [  384/ 1020]\n",
            "loss: 0.456598 [  704/ 1020]\n",
            "loss: 0.424254 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 1.958772 \n",
            "\n",
            "Epoch 79 \n",
            " ---------------------------------------\n",
            "loss: 0.387036 [   64/ 1020]\n",
            "loss: 0.510399 [  384/ 1020]\n",
            "loss: 0.433844 [  704/ 1020]\n",
            "loss: 0.493066 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 58.4%, Avg loss: 1.986190 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 80 \n",
            " ---------------------------------------\n",
            "loss: 0.573478 [   64/ 1020]\n",
            "loss: 0.473350 [  384/ 1020]\n",
            "loss: 0.523736 [  704/ 1020]\n",
            "loss: 0.491489 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 57.9%, Avg loss: 1.988857 \n",
            "\n",
            "Epoch 81 \n",
            " ---------------------------------------\n",
            "loss: 0.466624 [   64/ 1020]\n",
            "loss: 0.463595 [  384/ 1020]\n",
            "loss: 0.520122 [  704/ 1020]\n",
            "loss: 0.587584 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 57.2%, Avg loss: 2.005717 \n",
            "\n",
            "Epoch 82 \n",
            " ---------------------------------------\n",
            "loss: 0.467864 [   64/ 1020]\n",
            "loss: 0.414124 [  384/ 1020]\n",
            "loss: 0.459605 [  704/ 1020]\n",
            "loss: 0.478552 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 56.9%, Avg loss: 2.005110 \n",
            "\n",
            "Epoch 83 \n",
            " ---------------------------------------\n",
            "loss: 0.444846 [   64/ 1020]\n",
            "loss: 0.457852 [  384/ 1020]\n",
            "loss: 0.481861 [  704/ 1020]\n",
            "loss: 0.533804 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 55.8%, Avg loss: 2.044738 \n",
            "\n",
            "Epoch 84 \n",
            " ---------------------------------------\n",
            "loss: 0.668485 [   64/ 1020]\n",
            "loss: 0.438579 [  384/ 1020]\n",
            "loss: 0.426435 [  704/ 1020]\n",
            "loss: 0.515392 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 58.1%, Avg loss: 2.037310 \n",
            "\n",
            "Epoch 85 \n",
            " ---------------------------------------\n",
            "loss: 0.366659 [   64/ 1020]\n",
            "loss: 0.435045 [  384/ 1020]\n",
            "loss: 0.426072 [  704/ 1020]\n",
            "loss: 0.537346 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 59.6%, Avg loss: 1.977476 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 86 \n",
            " ---------------------------------------\n",
            "loss: 0.457122 [   64/ 1020]\n",
            "loss: 0.398339 [  384/ 1020]\n",
            "loss: 0.524130 [  704/ 1020]\n",
            "loss: 0.546735 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 59.0%, Avg loss: 1.942968 \n",
            "\n",
            "Epoch 87 \n",
            " ---------------------------------------\n",
            "loss: 0.468984 [   64/ 1020]\n",
            "loss: 0.317628 [  384/ 1020]\n",
            "loss: 0.433341 [  704/ 1020]\n",
            "loss: 0.471126 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 58.9%, Avg loss: 1.959459 \n",
            "\n",
            "Epoch 88 \n",
            " ---------------------------------------\n",
            "loss: 0.439765 [   64/ 1020]\n",
            "loss: 0.516056 [  384/ 1020]\n",
            "loss: 0.438023 [  704/ 1020]\n",
            "loss: 0.502715 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 58.6%, Avg loss: 1.973875 \n",
            "\n",
            "Epoch 89 \n",
            " ---------------------------------------\n",
            "loss: 0.409844 [   64/ 1020]\n",
            "loss: 0.393302 [  384/ 1020]\n",
            "loss: 0.547503 [  704/ 1020]\n",
            "loss: 0.389586 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 58.9%, Avg loss: 1.961370 \n",
            "\n",
            "Epoch 90 \n",
            " ---------------------------------------\n",
            "loss: 0.470493 [   64/ 1020]\n",
            "loss: 0.485438 [  384/ 1020]\n",
            "loss: 0.581410 [  704/ 1020]\n",
            "loss: 0.440913 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 59.3%, Avg loss: 1.971718 \n",
            "\n",
            "Epoch 91 \n",
            " ---------------------------------------\n",
            "loss: 0.506535 [   64/ 1020]\n",
            "loss: 0.433379 [  384/ 1020]\n",
            "loss: 0.418147 [  704/ 1020]\n",
            "loss: 0.422095 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 59.4%, Avg loss: 1.967785 \n",
            "\n",
            "Epoch 92 \n",
            " ---------------------------------------\n",
            "loss: 0.430208 [   64/ 1020]\n",
            "loss: 0.438723 [  384/ 1020]\n",
            "loss: 0.458092 [  704/ 1020]\n",
            "loss: 0.443671 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 57.9%, Avg loss: 1.971902 \n",
            "\n",
            "Epoch 93 \n",
            " ---------------------------------------\n",
            "loss: 0.534309 [   64/ 1020]\n",
            "loss: 0.451801 [  384/ 1020]\n",
            "loss: 0.563050 [  704/ 1020]\n",
            "loss: 0.452824 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 58.5%, Avg loss: 1.945067 \n",
            "\n",
            "Epoch 94 \n",
            " ---------------------------------------\n",
            "loss: 0.392896 [   64/ 1020]\n",
            "loss: 0.458785 [  384/ 1020]\n",
            "loss: 0.332040 [  704/ 1020]\n",
            "loss: 0.460362 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 59.3%, Avg loss: 1.939341 \n",
            "\n",
            "Epoch 95 \n",
            " ---------------------------------------\n",
            "loss: 0.322687 [   64/ 1020]\n",
            "loss: 0.349889 [  384/ 1020]\n",
            "loss: 0.476331 [  704/ 1020]\n",
            "loss: 0.321347 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 58.3%, Avg loss: 1.944239 \n",
            "\n",
            "Epoch 96 \n",
            " ---------------------------------------\n",
            "loss: 0.514809 [   64/ 1020]\n",
            "loss: 0.568915 [  384/ 1020]\n",
            "loss: 0.424810 [  704/ 1020]\n",
            "loss: 0.525850 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 59.3%, Avg loss: 1.948511 \n",
            "\n",
            "Stopping early\n",
            "Testing -----------------------\n",
            "Loading state of neural network at highest accuracy...\n",
            "Test Error: \n",
            " Accuracy: 52.6%, Avg loss: 2.191807 \n",
            "\n",
            "Done!!!!\n"
          ]
        }
      ],
      "source": [
        "epochs = 250\n",
        "\n",
        "best_accuracy = 0\n",
        "patience = 10\n",
        "triggers = 0\n",
        "\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1} \\n ---------------------------------------\")\n",
        "\n",
        "  \"\"\"#train on original data\n",
        "  train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\"\"\"\n",
        "\n",
        "  #train on augmented data\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "\n",
        "  #testing on evaluation data\n",
        "  accuracy, test_loss = test(val_dataloader, model, loss_fn)\n",
        "\n",
        "  scheduler.step(test_loss)\n",
        "\n",
        "  if accuracy > best_accuracy:\n",
        "    best_accuracy = accuracy\n",
        "    triggers = 0\n",
        "    torch.save(model.state_dict(), \"model.pt\")\n",
        "    print(\"Saved model at current state\")\n",
        "  else:\n",
        "    triggers += 1\n",
        "\n",
        "  if triggers > patience:\n",
        "    print(\"Stopping early\")\n",
        "    break\n",
        "\n",
        "print(\"Testing -----------------------\")\n",
        "print(\"Loading state of neural network at highest accuracy...\")\n",
        "model.load_state_dict(torch.load(\"model.pt\"))\n",
        "model.eval()\n",
        "test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!!!!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOHyC6kKxXVd0Ku231or7i7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}