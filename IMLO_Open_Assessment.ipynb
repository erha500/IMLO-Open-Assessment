{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erha500/IMLO-Open-Assessment/blob/main/IMLO_Open_Assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MGJhK0Wy6U2-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as T\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1FLWsWbK-ylG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e509121-792e-4391-cfe4-60117cdfd1b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\erhan\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_transform = v2.Compose([\n",
        "    v2.RandomResizedCrop([320,320], scale=[0.25,1.0], ratio=[1.0,1.0]),\n",
        "    #v2.RandomPerspective(),\n",
        "    v2.RandomHorizontalFlip(0.5),\n",
        "    #v2.RandomRotation(180),\n",
        "    #v2.RandomVerticalFlip(0.5)\n",
        "    v2.ToTensor(),\n",
        "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = v2.Compose([\n",
        "  v2.Resize([320,320]),\n",
        "  v2.ToTensor(),\n",
        "  v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWVmTrcs9QGM"
      },
      "source": [
        "Downloading Flowers102 dataset from datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2AG1ERmI9WXU"
      },
      "outputs": [],
      "source": [
        "training_data = datasets.Flowers102(root=\"dataset\", split=\"train\", transform=train_transform, download=True)\n",
        "\n",
        "test_data = datasets.Flowers102(root=\"dataset\", split=\"val\", transform=test_transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EiOOyavq-T-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33285e5c-4cda-49f5-ae2d-777cf0120294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 3, 320, 320])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "#Create data loaders\n",
        "train_dataloader = DataLoader(training_data, batch_size = batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "  print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3fL6F9TLEdDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fda2eb2-938d-4f32-9bb5-1e1c7f84c742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU()\n",
            "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU()\n",
            "    (11): Flatten(start_dim=1, end_dim=-1)\n",
            "    (12): Linear(in_features=204800, out_features=1024, bias=True)\n",
            "    (13): ReLU()\n",
            "    (14): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (15): ReLU()\n",
            "    (16): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (17): ReLU()\n",
            "    (18): Linear(in_features=256, out_features=102, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "#Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "      nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2),\n",
        "      nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(128 * 40 * 40, 1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(1024, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512,256),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(256,102)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9IvJsfvwE0VG"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "o4bMoWUAE1kO"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    #Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 5 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "y4Mf49itE3A-"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct) :>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Xr7VD7E3E5y1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ace2e0-78c7-476d-aeca-3cfd367b8a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            " ---------------------------------------\n",
            "loss: 4.626515 [   64/ 1020]\n",
            "loss: 4.627560 [  384/ 1020]\n",
            "loss: 4.622780 [  704/ 1020]\n",
            "loss: 4.627001 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 1.0%, Avg loss: 4.624411 \n",
            "\n",
            "Epoch 2 \n",
            " ---------------------------------------\n",
            "loss: 4.626202 [   64/ 1020]\n",
            "loss: 4.613575 [  384/ 1020]\n",
            "loss: 4.604685 [  704/ 1020]\n",
            "loss: 4.595652 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 1.9%, Avg loss: 4.584902 \n",
            "\n",
            "Epoch 3 \n",
            " ---------------------------------------\n",
            "loss: 4.562348 [   64/ 1020]\n",
            "loss: 4.446759 [  384/ 1020]\n",
            "loss: 4.575757 [  704/ 1020]\n",
            "loss: 4.474576 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 2.0%, Avg loss: 4.411970 \n",
            "\n",
            "Epoch 4 \n",
            " ---------------------------------------\n",
            "loss: 4.391622 [   64/ 1020]\n",
            "loss: 4.245652 [  384/ 1020]\n",
            "loss: 4.344252 [  704/ 1020]\n",
            "loss: 4.282022 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 2.1%, Avg loss: 4.252119 \n",
            "\n",
            "Epoch 5 \n",
            " ---------------------------------------\n",
            "loss: 4.194000 [   64/ 1020]\n",
            "loss: 4.177701 [  384/ 1020]\n",
            "loss: 4.182245 [  704/ 1020]\n",
            "loss: 4.195471 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 1.8%, Avg loss: 4.172035 \n",
            "\n",
            "Epoch 6 \n",
            " ---------------------------------------\n",
            "loss: 4.145385 [   64/ 1020]\n",
            "loss: 4.186697 [  384/ 1020]\n",
            "loss: 4.161092 [  704/ 1020]\n",
            "loss: 4.098592 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 2.5%, Avg loss: 4.144817 \n",
            "\n",
            "Epoch 7 \n",
            " ---------------------------------------\n",
            "loss: 4.054239 [   64/ 1020]\n",
            "loss: 4.146026 [  384/ 1020]\n",
            "loss: 4.193449 [  704/ 1020]\n",
            "loss: 3.890838 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 2.1%, Avg loss: 4.120809 \n",
            "\n",
            "Epoch 8 \n",
            " ---------------------------------------\n",
            "loss: 4.033777 [   64/ 1020]\n",
            "loss: 4.049754 [  384/ 1020]\n",
            "loss: 4.158240 [  704/ 1020]\n",
            "loss: 4.103347 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 2.5%, Avg loss: 4.080360 \n",
            "\n",
            "Epoch 9 \n",
            " ---------------------------------------\n",
            "loss: 3.992144 [   64/ 1020]\n",
            "loss: 4.083755 [  384/ 1020]\n",
            "loss: 4.079575 [  704/ 1020]\n",
            "loss: 4.115826 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 2.9%, Avg loss: 4.061803 \n",
            "\n",
            "Epoch 10 \n",
            " ---------------------------------------\n",
            "loss: 3.944586 [   64/ 1020]\n",
            "loss: 4.040643 [  384/ 1020]\n",
            "loss: 3.932492 [  704/ 1020]\n",
            "loss: 4.026806 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 3.7%, Avg loss: 3.982308 \n",
            "\n",
            "Epoch 11 \n",
            " ---------------------------------------\n",
            "loss: 3.867921 [   64/ 1020]\n",
            "loss: 3.875014 [  384/ 1020]\n",
            "loss: 3.985120 [  704/ 1020]\n",
            "loss: 4.022353 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 4.0%, Avg loss: 3.964436 \n",
            "\n",
            "Epoch 12 \n",
            " ---------------------------------------\n",
            "loss: 3.942757 [   64/ 1020]\n",
            "loss: 3.865003 [  384/ 1020]\n",
            "loss: 3.889542 [  704/ 1020]\n",
            "loss: 4.085460 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 4.2%, Avg loss: 3.972199 \n",
            "\n",
            "Epoch 13 \n",
            " ---------------------------------------\n",
            "loss: 3.742230 [   64/ 1020]\n",
            "loss: 3.959052 [  384/ 1020]\n",
            "loss: 3.899922 [  704/ 1020]\n",
            "loss: 3.689259 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 4.6%, Avg loss: 3.947523 \n",
            "\n",
            "Epoch 14 \n",
            " ---------------------------------------\n",
            "loss: 3.804587 [   64/ 1020]\n",
            "loss: 3.704195 [  384/ 1020]\n",
            "loss: 3.948485 [  704/ 1020]\n",
            "loss: 3.718374 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 4.9%, Avg loss: 3.979168 \n",
            "\n",
            "Epoch 15 \n",
            " ---------------------------------------\n",
            "loss: 3.737212 [   64/ 1020]\n",
            "loss: 3.969579 [  384/ 1020]\n",
            "loss: 3.588661 [  704/ 1020]\n",
            "loss: 3.735142 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 5.5%, Avg loss: 3.850998 \n",
            "\n",
            "Epoch 16 \n",
            " ---------------------------------------\n",
            "loss: 3.530193 [   64/ 1020]\n",
            "loss: 3.878328 [  384/ 1020]\n",
            "loss: 3.683361 [  704/ 1020]\n",
            "loss: 3.882400 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 5.2%, Avg loss: 3.991701 \n",
            "\n",
            "Epoch 17 \n",
            " ---------------------------------------\n",
            "loss: 3.862954 [   64/ 1020]\n",
            "loss: 3.727497 [  384/ 1020]\n",
            "loss: 3.613382 [  704/ 1020]\n",
            "loss: 3.790038 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 7.4%, Avg loss: 3.824760 \n",
            "\n",
            "Epoch 18 \n",
            " ---------------------------------------\n",
            "loss: 3.515965 [   64/ 1020]\n",
            "loss: 3.607901 [  384/ 1020]\n",
            "loss: 3.536966 [  704/ 1020]\n",
            "loss: 3.609444 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 7.6%, Avg loss: 3.758649 \n",
            "\n",
            "Epoch 19 \n",
            " ---------------------------------------\n",
            "loss: 3.799798 [   64/ 1020]\n",
            "loss: 3.716627 [  384/ 1020]\n",
            "loss: 3.703596 [  704/ 1020]\n",
            "loss: 3.696467 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 6.6%, Avg loss: 3.835411 \n",
            "\n",
            "Epoch 20 \n",
            " ---------------------------------------\n",
            "loss: 3.671644 [   64/ 1020]\n",
            "loss: 3.278558 [  384/ 1020]\n",
            "loss: 3.764154 [  704/ 1020]\n",
            "loss: 3.568280 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 10.2%, Avg loss: 3.673706 \n",
            "\n",
            "Epoch 21 \n",
            " ---------------------------------------\n",
            "loss: 3.365823 [   64/ 1020]\n",
            "loss: 3.617708 [  384/ 1020]\n",
            "loss: 3.361614 [  704/ 1020]\n",
            "loss: 3.421618 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 9.7%, Avg loss: 3.670541 \n",
            "\n",
            "Epoch 22 \n",
            " ---------------------------------------\n",
            "loss: 3.289397 [   64/ 1020]\n",
            "loss: 3.007747 [  384/ 1020]\n",
            "loss: 3.622492 [  704/ 1020]\n",
            "loss: 3.381881 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 9.7%, Avg loss: 3.651914 \n",
            "\n",
            "Epoch 23 \n",
            " ---------------------------------------\n",
            "loss: 3.369553 [   64/ 1020]\n",
            "loss: 3.318921 [  384/ 1020]\n",
            "loss: 3.288023 [  704/ 1020]\n",
            "loss: 3.372620 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 10.4%, Avg loss: 3.726545 \n",
            "\n",
            "Epoch 24 \n",
            " ---------------------------------------\n",
            "loss: 3.370881 [   64/ 1020]\n",
            "loss: 3.070134 [  384/ 1020]\n",
            "loss: 3.680897 [  704/ 1020]\n",
            "loss: 3.141287 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 12.1%, Avg loss: 3.612695 \n",
            "\n",
            "Epoch 25 \n",
            " ---------------------------------------\n",
            "loss: 3.023042 [   64/ 1020]\n",
            "loss: 3.504702 [  384/ 1020]\n",
            "loss: 3.246538 [  704/ 1020]\n",
            "loss: 3.310361 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 12.0%, Avg loss: 3.545536 \n",
            "\n",
            "Epoch 26 \n",
            " ---------------------------------------\n",
            "loss: 3.382839 [   64/ 1020]\n",
            "loss: 3.207056 [  384/ 1020]\n",
            "loss: 3.095803 [  704/ 1020]\n",
            "loss: 3.179137 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 13.7%, Avg loss: 3.576949 \n",
            "\n",
            "Epoch 27 \n",
            " ---------------------------------------\n",
            "loss: 3.012533 [   64/ 1020]\n",
            "loss: 2.983572 [  384/ 1020]\n",
            "loss: 3.360365 [  704/ 1020]\n",
            "loss: 2.911336 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 13.4%, Avg loss: 3.492795 \n",
            "\n",
            "Epoch 28 \n",
            " ---------------------------------------\n",
            "loss: 2.810901 [   64/ 1020]\n",
            "loss: 2.987435 [  384/ 1020]\n",
            "loss: 3.020133 [  704/ 1020]\n",
            "loss: 3.044740 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 14.1%, Avg loss: 3.407613 \n",
            "\n",
            "Epoch 29 \n",
            " ---------------------------------------\n",
            "loss: 2.795069 [   64/ 1020]\n",
            "loss: 3.060891 [  384/ 1020]\n",
            "loss: 3.346983 [  704/ 1020]\n",
            "loss: 3.272415 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 16.4%, Avg loss: 3.465235 \n",
            "\n",
            "Epoch 30 \n",
            " ---------------------------------------\n",
            "loss: 2.944020 [   64/ 1020]\n",
            "loss: 2.817120 [  384/ 1020]\n",
            "loss: 3.052133 [  704/ 1020]\n",
            "loss: 3.161430 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 13.8%, Avg loss: 3.434064 \n",
            "\n",
            "Epoch 31 \n",
            " ---------------------------------------\n",
            "loss: 2.853220 [   64/ 1020]\n",
            "loss: 2.814374 [  384/ 1020]\n",
            "loss: 2.944298 [  704/ 1020]\n",
            "loss: 2.894785 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 16.9%, Avg loss: 3.538620 \n",
            "\n",
            "Epoch 32 \n",
            " ---------------------------------------\n",
            "loss: 2.920875 [   64/ 1020]\n",
            "loss: 2.892166 [  384/ 1020]\n",
            "loss: 2.697176 [  704/ 1020]\n",
            "loss: 2.966599 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 15.8%, Avg loss: 3.511474 \n",
            "\n",
            "Epoch 33 \n",
            " ---------------------------------------\n",
            "loss: 2.596663 [   64/ 1020]\n",
            "loss: 2.773604 [  384/ 1020]\n",
            "loss: 2.897969 [  704/ 1020]\n",
            "loss: 2.638721 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 16.7%, Avg loss: 3.327660 \n",
            "\n",
            "Epoch 34 \n",
            " ---------------------------------------\n",
            "loss: 2.581837 [   64/ 1020]\n",
            "loss: 2.963441 [  384/ 1020]\n",
            "loss: 2.725116 [  704/ 1020]\n",
            "loss: 2.863162 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 18.1%, Avg loss: 3.222051 \n",
            "\n",
            "Epoch 35 \n",
            " ---------------------------------------\n",
            "loss: 2.497689 [   64/ 1020]\n",
            "loss: 2.420293 [  384/ 1020]\n",
            "loss: 2.467683 [  704/ 1020]\n",
            "loss: 2.861703 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 18.3%, Avg loss: 3.371031 \n",
            "\n",
            "Epoch 36 \n",
            " ---------------------------------------\n",
            "loss: 2.491037 [   64/ 1020]\n",
            "loss: 2.404142 [  384/ 1020]\n",
            "loss: 2.681906 [  704/ 1020]\n",
            "loss: 2.611575 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 18.2%, Avg loss: 3.509241 \n",
            "\n",
            "Epoch 37 \n",
            " ---------------------------------------\n",
            "loss: 2.281980 [   64/ 1020]\n",
            "loss: 2.516988 [  384/ 1020]\n",
            "loss: 2.471386 [  704/ 1020]\n",
            "loss: 2.868890 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 17.7%, Avg loss: 3.495852 \n",
            "\n",
            "Epoch 38 \n",
            " ---------------------------------------\n",
            "loss: 2.530719 [   64/ 1020]\n",
            "loss: 2.292823 [  384/ 1020]\n",
            "loss: 2.582410 [  704/ 1020]\n",
            "loss: 2.643983 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 19.5%, Avg loss: 3.382265 \n",
            "\n",
            "Epoch 39 \n",
            " ---------------------------------------\n",
            "loss: 2.403618 [   64/ 1020]\n",
            "loss: 2.711539 [  384/ 1020]\n",
            "loss: 2.592435 [  704/ 1020]\n",
            "loss: 2.474963 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 20.4%, Avg loss: 3.318016 \n",
            "\n",
            "Epoch 40 \n",
            " ---------------------------------------\n",
            "loss: 2.315663 [   64/ 1020]\n",
            "loss: 2.664603 [  384/ 1020]\n",
            "loss: 2.128178 [  704/ 1020]\n",
            "loss: 2.268469 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 19.1%, Avg loss: 3.283057 \n",
            "\n",
            "Epoch 41 \n",
            " ---------------------------------------\n",
            "loss: 1.958960 [   64/ 1020]\n",
            "loss: 1.916594 [  384/ 1020]\n",
            "loss: 2.474897 [  704/ 1020]\n",
            "loss: 2.318098 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 20.9%, Avg loss: 3.435629 \n",
            "\n",
            "Epoch 42 \n",
            " ---------------------------------------\n",
            "loss: 2.188684 [   64/ 1020]\n",
            "loss: 2.040446 [  384/ 1020]\n",
            "loss: 2.321276 [  704/ 1020]\n",
            "loss: 2.600152 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 18.8%, Avg loss: 3.667415 \n",
            "\n",
            "Epoch 43 \n",
            " ---------------------------------------\n",
            "loss: 2.187758 [   64/ 1020]\n",
            "loss: 2.079429 [  384/ 1020]\n",
            "loss: 2.285949 [  704/ 1020]\n",
            "loss: 2.546745 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 21.7%, Avg loss: 3.377242 \n",
            "\n",
            "Epoch 44 \n",
            " ---------------------------------------\n",
            "loss: 2.100570 [   64/ 1020]\n",
            "loss: 1.855105 [  384/ 1020]\n",
            "loss: 2.475386 [  704/ 1020]\n",
            "loss: 2.105099 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 16.9%, Avg loss: 3.742301 \n",
            "\n",
            "Epoch 45 \n",
            " ---------------------------------------\n",
            "loss: 2.099312 [   64/ 1020]\n",
            "loss: 1.969770 [  384/ 1020]\n",
            "loss: 2.450941 [  704/ 1020]\n",
            "loss: 2.318081 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 21.3%, Avg loss: 3.338480 \n",
            "\n",
            "Epoch 46 \n",
            " ---------------------------------------\n",
            "loss: 1.957989 [   64/ 1020]\n",
            "loss: 1.802242 [  384/ 1020]\n",
            "loss: 2.051825 [  704/ 1020]\n",
            "loss: 2.164806 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 21.4%, Avg loss: 3.341133 \n",
            "\n",
            "Epoch 47 \n",
            " ---------------------------------------\n",
            "loss: 1.810624 [   64/ 1020]\n",
            "loss: 1.982124 [  384/ 1020]\n",
            "loss: 2.195234 [  704/ 1020]\n",
            "loss: 2.385966 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 22.3%, Avg loss: 3.469237 \n",
            "\n",
            "Epoch 48 \n",
            " ---------------------------------------\n",
            "loss: 1.708881 [   64/ 1020]\n",
            "loss: 1.942135 [  384/ 1020]\n",
            "loss: 1.932192 [  704/ 1020]\n",
            "loss: 1.964427 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 22.3%, Avg loss: 3.613366 \n",
            "\n",
            "Epoch 49 \n",
            " ---------------------------------------\n",
            "loss: 1.918933 [   64/ 1020]\n",
            "loss: 1.867616 [  384/ 1020]\n",
            "loss: 2.064387 [  704/ 1020]\n",
            "loss: 1.997857 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 22.8%, Avg loss: 3.575753 \n",
            "\n",
            "Epoch 50 \n",
            " ---------------------------------------\n",
            "loss: 1.838649 [   64/ 1020]\n",
            "loss: 1.892203 [  384/ 1020]\n",
            "loss: 1.654160 [  704/ 1020]\n",
            "loss: 1.773381 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 21.1%, Avg loss: 3.925453 \n",
            "\n",
            "Epoch 51 \n",
            " ---------------------------------------\n",
            "loss: 1.847396 [   64/ 1020]\n",
            "loss: 1.694685 [  384/ 1020]\n",
            "loss: 1.724242 [  704/ 1020]\n",
            "loss: 1.852412 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.7%, Avg loss: 3.614126 \n",
            "\n",
            "Epoch 52 \n",
            " ---------------------------------------\n",
            "loss: 1.587852 [   64/ 1020]\n",
            "loss: 1.701634 [  384/ 1020]\n",
            "loss: 1.872250 [  704/ 1020]\n",
            "loss: 1.853791 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 24.1%, Avg loss: 3.518099 \n",
            "\n",
            "Epoch 53 \n",
            " ---------------------------------------\n",
            "loss: 1.653629 [   64/ 1020]\n",
            "loss: 1.668990 [  384/ 1020]\n",
            "loss: 1.783565 [  704/ 1020]\n",
            "loss: 2.161161 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.2%, Avg loss: 3.693038 \n",
            "\n",
            "Epoch 54 \n",
            " ---------------------------------------\n",
            "loss: 1.661210 [   64/ 1020]\n",
            "loss: 1.819775 [  384/ 1020]\n",
            "loss: 1.913998 [  704/ 1020]\n",
            "loss: 1.536030 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 22.8%, Avg loss: 3.870505 \n",
            "\n",
            "Epoch 55 \n",
            " ---------------------------------------\n",
            "loss: 1.445038 [   64/ 1020]\n",
            "loss: 1.823274 [  384/ 1020]\n",
            "loss: 2.010961 [  704/ 1020]\n",
            "loss: 1.613415 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.4%, Avg loss: 3.643089 \n",
            "\n",
            "Epoch 56 \n",
            " ---------------------------------------\n",
            "loss: 1.599540 [   64/ 1020]\n",
            "loss: 1.746632 [  384/ 1020]\n",
            "loss: 1.806489 [  704/ 1020]\n",
            "loss: 1.634228 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.7%, Avg loss: 4.097260 \n",
            "\n",
            "Epoch 57 \n",
            " ---------------------------------------\n",
            "loss: 1.398529 [   64/ 1020]\n",
            "loss: 1.657783 [  384/ 1020]\n",
            "loss: 1.598389 [  704/ 1020]\n",
            "loss: 1.625720 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.2%, Avg loss: 3.928439 \n",
            "\n",
            "Epoch 58 \n",
            " ---------------------------------------\n",
            "loss: 1.432985 [   64/ 1020]\n",
            "loss: 1.156352 [  384/ 1020]\n",
            "loss: 1.795058 [  704/ 1020]\n",
            "loss: 1.917080 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 24.3%, Avg loss: 3.677982 \n",
            "\n",
            "Epoch 59 \n",
            " ---------------------------------------\n",
            "loss: 1.757359 [   64/ 1020]\n",
            "loss: 1.482322 [  384/ 1020]\n",
            "loss: 1.543992 [  704/ 1020]\n",
            "loss: 1.663227 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.3%, Avg loss: 3.906506 \n",
            "\n",
            "Epoch 60 \n",
            " ---------------------------------------\n",
            "loss: 1.739418 [   64/ 1020]\n",
            "loss: 1.408179 [  384/ 1020]\n",
            "loss: 1.431543 [  704/ 1020]\n",
            "loss: 1.922464 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.5%, Avg loss: 3.999942 \n",
            "\n",
            "Epoch 61 \n",
            " ---------------------------------------\n",
            "loss: 1.693264 [   64/ 1020]\n",
            "loss: 1.690029 [  384/ 1020]\n",
            "loss: 1.497708 [  704/ 1020]\n",
            "loss: 1.553314 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.3%, Avg loss: 3.766040 \n",
            "\n",
            "Epoch 62 \n",
            " ---------------------------------------\n",
            "loss: 1.344749 [   64/ 1020]\n",
            "loss: 1.216983 [  384/ 1020]\n",
            "loss: 1.163203 [  704/ 1020]\n",
            "loss: 1.581972 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.9%, Avg loss: 4.193071 \n",
            "\n",
            "Epoch 63 \n",
            " ---------------------------------------\n",
            "loss: 1.375941 [   64/ 1020]\n",
            "loss: 1.380499 [  384/ 1020]\n",
            "loss: 1.417005 [  704/ 1020]\n",
            "loss: 1.263756 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 23.2%, Avg loss: 4.255478 \n",
            "\n",
            "Epoch 64 \n",
            " ---------------------------------------\n",
            "loss: 1.447399 [   64/ 1020]\n",
            "loss: 1.586814 [  384/ 1020]\n",
            "loss: 1.122774 [  704/ 1020]\n",
            "loss: 1.382870 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.3%, Avg loss: 3.823114 \n",
            "\n",
            "Epoch 65 \n",
            " ---------------------------------------\n",
            "loss: 1.018277 [   64/ 1020]\n",
            "loss: 1.153635 [  384/ 1020]\n",
            "loss: 0.972816 [  704/ 1020]\n",
            "loss: 1.711532 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.4%, Avg loss: 3.925459 \n",
            "\n",
            "Epoch 66 \n",
            " ---------------------------------------\n",
            "loss: 1.027807 [   64/ 1020]\n",
            "loss: 1.566878 [  384/ 1020]\n",
            "loss: 1.153192 [  704/ 1020]\n",
            "loss: 1.297203 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.8%, Avg loss: 3.997285 \n",
            "\n",
            "Epoch 67 \n",
            " ---------------------------------------\n",
            "loss: 1.431720 [   64/ 1020]\n",
            "loss: 1.049356 [  384/ 1020]\n",
            "loss: 1.037414 [  704/ 1020]\n",
            "loss: 1.048348 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.9%, Avg loss: 4.136208 \n",
            "\n",
            "Epoch 68 \n",
            " ---------------------------------------\n",
            "loss: 1.032627 [   64/ 1020]\n",
            "loss: 1.085369 [  384/ 1020]\n",
            "loss: 0.993522 [  704/ 1020]\n",
            "loss: 1.224875 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.9%, Avg loss: 4.224208 \n",
            "\n",
            "Epoch 69 \n",
            " ---------------------------------------\n",
            "loss: 1.015333 [   64/ 1020]\n",
            "loss: 1.270283 [  384/ 1020]\n",
            "loss: 1.339860 [  704/ 1020]\n",
            "loss: 0.969047 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 26.5%, Avg loss: 4.072765 \n",
            "\n",
            "Epoch 70 \n",
            " ---------------------------------------\n",
            "loss: 1.219143 [   64/ 1020]\n",
            "loss: 0.977746 [  384/ 1020]\n",
            "loss: 1.071037 [  704/ 1020]\n",
            "loss: 1.180902 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.5%, Avg loss: 3.964038 \n",
            "\n",
            "Epoch 71 \n",
            " ---------------------------------------\n",
            "loss: 1.016589 [   64/ 1020]\n",
            "loss: 0.768800 [  384/ 1020]\n",
            "loss: 1.227611 [  704/ 1020]\n",
            "loss: 1.539700 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.3%, Avg loss: 4.441370 \n",
            "\n",
            "Epoch 72 \n",
            " ---------------------------------------\n",
            "loss: 1.084048 [   64/ 1020]\n",
            "loss: 1.115980 [  384/ 1020]\n",
            "loss: 1.074375 [  704/ 1020]\n",
            "loss: 1.332067 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.6%, Avg loss: 3.941447 \n",
            "\n",
            "Epoch 73 \n",
            " ---------------------------------------\n",
            "loss: 1.311893 [   64/ 1020]\n",
            "loss: 1.062937 [  384/ 1020]\n",
            "loss: 1.031594 [  704/ 1020]\n",
            "loss: 1.258188 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.3%, Avg loss: 4.150167 \n",
            "\n",
            "Epoch 74 \n",
            " ---------------------------------------\n",
            "loss: 1.051255 [   64/ 1020]\n",
            "loss: 1.235608 [  384/ 1020]\n",
            "loss: 0.817875 [  704/ 1020]\n",
            "loss: 1.356398 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.6%, Avg loss: 4.184143 \n",
            "\n",
            "Epoch 75 \n",
            " ---------------------------------------\n",
            "loss: 0.962899 [   64/ 1020]\n",
            "loss: 1.147244 [  384/ 1020]\n",
            "loss: 0.853668 [  704/ 1020]\n",
            "loss: 0.842969 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.7%, Avg loss: 4.090876 \n",
            "\n",
            "Epoch 76 \n",
            " ---------------------------------------\n",
            "loss: 0.750911 [   64/ 1020]\n",
            "loss: 1.168461 [  384/ 1020]\n",
            "loss: 1.172341 [  704/ 1020]\n",
            "loss: 1.239195 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.1%, Avg loss: 4.396062 \n",
            "\n",
            "Epoch 77 \n",
            " ---------------------------------------\n",
            "loss: 1.005031 [   64/ 1020]\n",
            "loss: 0.844018 [  384/ 1020]\n",
            "loss: 0.845779 [  704/ 1020]\n",
            "loss: 0.998536 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.6%, Avg loss: 4.238561 \n",
            "\n",
            "Epoch 78 \n",
            " ---------------------------------------\n",
            "loss: 0.987378 [   64/ 1020]\n",
            "loss: 0.984583 [  384/ 1020]\n",
            "loss: 0.826079 [  704/ 1020]\n",
            "loss: 0.957620 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.3%, Avg loss: 4.485907 \n",
            "\n",
            "Epoch 79 \n",
            " ---------------------------------------\n",
            "loss: 0.701985 [   64/ 1020]\n",
            "loss: 0.778598 [  384/ 1020]\n",
            "loss: 0.905542 [  704/ 1020]\n",
            "loss: 1.066152 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.1%, Avg loss: 4.523106 \n",
            "\n",
            "Epoch 80 \n",
            " ---------------------------------------\n",
            "loss: 0.884342 [   64/ 1020]\n",
            "loss: 0.875661 [  384/ 1020]\n",
            "loss: 0.800580 [  704/ 1020]\n",
            "loss: 0.838809 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.8%, Avg loss: 4.414516 \n",
            "\n",
            "Epoch 81 \n",
            " ---------------------------------------\n",
            "loss: 1.037574 [   64/ 1020]\n",
            "loss: 1.094095 [  384/ 1020]\n",
            "loss: 0.842966 [  704/ 1020]\n",
            "loss: 0.851443 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.8%, Avg loss: 4.466341 \n",
            "\n",
            "Epoch 82 \n",
            " ---------------------------------------\n",
            "loss: 0.803778 [   64/ 1020]\n",
            "loss: 0.525880 [  384/ 1020]\n",
            "loss: 0.907932 [  704/ 1020]\n",
            "loss: 0.837212 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.6%, Avg loss: 4.545331 \n",
            "\n",
            "Epoch 83 \n",
            " ---------------------------------------\n",
            "loss: 0.611986 [   64/ 1020]\n",
            "loss: 0.826455 [  384/ 1020]\n",
            "loss: 0.900529 [  704/ 1020]\n",
            "loss: 0.701133 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.2%, Avg loss: 4.570758 \n",
            "\n",
            "Epoch 84 \n",
            " ---------------------------------------\n",
            "loss: 0.826651 [   64/ 1020]\n",
            "loss: 0.729777 [  384/ 1020]\n",
            "loss: 0.765201 [  704/ 1020]\n",
            "loss: 1.094360 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.2%, Avg loss: 4.794586 \n",
            "\n",
            "Epoch 85 \n",
            " ---------------------------------------\n",
            "loss: 0.571556 [   64/ 1020]\n",
            "loss: 1.415215 [  384/ 1020]\n",
            "loss: 0.924875 [  704/ 1020]\n",
            "loss: 0.907411 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 25.5%, Avg loss: 4.599672 \n",
            "\n",
            "Epoch 86 \n",
            " ---------------------------------------\n",
            "loss: 0.892597 [   64/ 1020]\n",
            "loss: 0.751980 [  384/ 1020]\n",
            "loss: 0.778199 [  704/ 1020]\n",
            "loss: 1.007920 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.6%, Avg loss: 4.441385 \n",
            "\n",
            "Epoch 87 \n",
            " ---------------------------------------\n",
            "loss: 0.737911 [   64/ 1020]\n",
            "loss: 0.529607 [  384/ 1020]\n",
            "loss: 0.697475 [  704/ 1020]\n",
            "loss: 0.942653 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.9%, Avg loss: 4.788011 \n",
            "\n",
            "Epoch 88 \n",
            " ---------------------------------------\n",
            "loss: 0.643719 [   64/ 1020]\n",
            "loss: 0.843247 [  384/ 1020]\n",
            "loss: 0.786215 [  704/ 1020]\n",
            "loss: 0.608341 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.0%, Avg loss: 4.887167 \n",
            "\n",
            "Epoch 89 \n",
            " ---------------------------------------\n",
            "loss: 0.846299 [   64/ 1020]\n",
            "loss: 0.600664 [  384/ 1020]\n",
            "loss: 0.449322 [  704/ 1020]\n",
            "loss: 0.959315 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.1%, Avg loss: 4.833691 \n",
            "\n",
            "Epoch 90 \n",
            " ---------------------------------------\n",
            "loss: 0.627127 [   64/ 1020]\n",
            "loss: 0.618051 [  384/ 1020]\n",
            "loss: 0.693369 [  704/ 1020]\n",
            "loss: 0.525157 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.6%, Avg loss: 4.854430 \n",
            "\n",
            "Epoch 91 \n",
            " ---------------------------------------\n",
            "loss: 0.755629 [   64/ 1020]\n",
            "loss: 0.730941 [  384/ 1020]\n",
            "loss: 0.823762 [  704/ 1020]\n",
            "loss: 0.729170 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.3%, Avg loss: 5.007356 \n",
            "\n",
            "Epoch 92 \n",
            " ---------------------------------------\n",
            "loss: 0.724814 [   64/ 1020]\n",
            "loss: 0.579471 [  384/ 1020]\n",
            "loss: 0.693702 [  704/ 1020]\n",
            "loss: 0.538146 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.0%, Avg loss: 4.960369 \n",
            "\n",
            "Epoch 93 \n",
            " ---------------------------------------\n",
            "loss: 0.619125 [   64/ 1020]\n",
            "loss: 0.854185 [  384/ 1020]\n",
            "loss: 1.042904 [  704/ 1020]\n",
            "loss: 0.838571 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.2%, Avg loss: 4.673148 \n",
            "\n",
            "Epoch 94 \n",
            " ---------------------------------------\n",
            "loss: 0.576388 [   64/ 1020]\n",
            "loss: 0.638995 [  384/ 1020]\n",
            "loss: 0.996010 [  704/ 1020]\n",
            "loss: 0.918991 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.8%, Avg loss: 4.525766 \n",
            "\n",
            "Epoch 95 \n",
            " ---------------------------------------\n",
            "loss: 0.677658 [   64/ 1020]\n",
            "loss: 1.042985 [  384/ 1020]\n",
            "loss: 0.795390 [  704/ 1020]\n",
            "loss: 0.875326 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.7%, Avg loss: 4.511065 \n",
            "\n",
            "Epoch 96 \n",
            " ---------------------------------------\n",
            "loss: 0.510193 [   64/ 1020]\n",
            "loss: 0.780556 [  384/ 1020]\n",
            "loss: 0.664263 [  704/ 1020]\n",
            "loss: 0.921212 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.2%, Avg loss: 4.912836 \n",
            "\n",
            "Epoch 97 \n",
            " ---------------------------------------\n",
            "loss: 0.722364 [   64/ 1020]\n",
            "loss: 0.621007 [  384/ 1020]\n",
            "loss: 0.588362 [  704/ 1020]\n",
            "loss: 0.606378 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.6%, Avg loss: 5.299521 \n",
            "\n",
            "Epoch 98 \n",
            " ---------------------------------------\n",
            "loss: 0.561304 [   64/ 1020]\n",
            "loss: 0.448758 [  384/ 1020]\n",
            "loss: 0.878066 [  704/ 1020]\n",
            "loss: 0.965888 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.5%, Avg loss: 5.474419 \n",
            "\n",
            "Epoch 99 \n",
            " ---------------------------------------\n",
            "loss: 0.593128 [   64/ 1020]\n",
            "loss: 0.564819 [  384/ 1020]\n",
            "loss: 0.783352 [  704/ 1020]\n",
            "loss: 0.828730 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.4%, Avg loss: 5.008920 \n",
            "\n",
            "Epoch 100 \n",
            " ---------------------------------------\n",
            "loss: 0.651339 [   64/ 1020]\n",
            "loss: 0.704597 [  384/ 1020]\n",
            "loss: 0.799872 [  704/ 1020]\n",
            "loss: 0.553187 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.1%, Avg loss: 5.030531 \n",
            "\n",
            "Done!!!!\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1} \\n ---------------------------------------\")\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "  test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!!!!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPFxWY48YRwCIYpoJLBvvAi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}