{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erha500/IMLO-Open-Assessment/blob/main/IMLO_Open_Assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MGJhK0Wy6U2-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as T\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1FLWsWbK-ylG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81aac10-cdcf-489e-9796-c00902d3bc69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\erhan\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_transform_augment = v2.Compose([\n",
        "    v2.Resize([224,224]),\n",
        "    #v2.RandomPerspective(),\n",
        "    v2.RandomHorizontalFlip(0.5),\n",
        "    v2.RandomRotation(45),\n",
        "    #v2.RandomVerticalFlip(0.5)\n",
        "    #v2.RandomAutocontrast(),\n",
        "    #v2.GaussianBlur(kernel_size=3),\n",
        "    v2.ToTensor(),\n",
        "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_transform = v2.Compose([\n",
        "  v2.Resize([224,224]),\n",
        "  v2.ToTensor(),\n",
        "  v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "test_transform = v2.Compose([\n",
        "  v2.Resize([224,224]),\n",
        "  v2.ToTensor(),\n",
        "  v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWVmTrcs9QGM"
      },
      "source": [
        "Downloading Flowers102 dataset from datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2AG1ERmI9WXU"
      },
      "outputs": [],
      "source": [
        "training_data_augment = datasets.Flowers102(root=\"dataset\", split=\"train\", transform=train_transform_augment, download=True)\n",
        "\n",
        "training_data = datasets.Flowers102(root=\"dataset\", split=\"train\", transform=train_transform, download=True)\n",
        "\n",
        "val_data = datasets.Flowers102(root=\"dataset\", split=\"val\", transform=test_transform, download=True)\n",
        "\n",
        "test_data = datasets.Flowers102(root=\"dataset\", split=\"test\", transform=test_transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EiOOyavq-T-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0284848d-bb4b-415f-b723-c223060b8045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 3, 224, 224])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "#Create data loaders\n",
        "train_dataloader = DataLoader(training_data_augment, batch_size = batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "  print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3fL6F9TLEdDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ccce928-72a8-4f60-b26f-996ca1e82ad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): ReLU()\n",
            "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU()\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): ReLU()\n",
            "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (16): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (18): ReLU()\n",
            "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU()\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Flatten(start_dim=1, end_dim=-1)\n",
            "    (25): Linear(in_features=2304, out_features=1024, bias=True)\n",
            "    (26): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): ReLU()\n",
            "    (28): Dropout(p=0.2, inplace=False)\n",
            "    (29): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (30): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (31): ReLU()\n",
            "    (32): Dropout(p=0.2, inplace=False)\n",
            "    (33): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (34): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (35): ReLU()\n",
            "    (36): Dropout(p=0.2, inplace=False)\n",
            "    (37): Linear(in_features=256, out_features=102, bias=True)\n",
            "    (38): BatchNorm1d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU()\n",
            "    (40): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "#Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "      #Convolutional layers\n",
        "      nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "      nn.Conv2d(64,64, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "      nn.Conv2d(128,128, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(256),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "      nn.Conv2d(256,256, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(256),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      #Linear layers\n",
        "      nn.Flatten(),\n",
        "\n",
        "      nn.Linear(256 * 3 * 3, 1024),\n",
        "      nn.BatchNorm1d(1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.2),\n",
        "\n",
        "      nn.Linear(1024, 512),\n",
        "      nn.BatchNorm1d(512),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.2),\n",
        "\n",
        "      nn.Linear(512,256),\n",
        "      nn.BatchNorm1d(256),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.2),\n",
        "\n",
        "      nn.Linear(256,102),\n",
        "      nn.BatchNorm1d(102),\n",
        "      nn.ReLU(),\n",
        "\n",
        "      nn.LogSoftmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9IvJsfvwE0VG"
      },
      "outputs": [],
      "source": [
        "#loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn = nn.NLLLoss()\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.005) #weight decay is L2 regularisation\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=5, factor=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "o4bMoWUAE1kO"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    #Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 5 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "y4Mf49itE3A-"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct) :>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    accuracy = 100 * correct\n",
        "    return accuracy, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Xr7VD7E3E5y1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca8764e1-f2c1-4ac9-c7d2-8a1f9e057ba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            " ---------------------------------------\n",
            "loss: 4.861032 [   64/ 1020]\n",
            "loss: 4.880560 [  384/ 1020]\n",
            "loss: 4.775269 [  704/ 1020]\n",
            "loss: 4.742188 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 1.1%, Avg loss: 4.630225 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 2 \n",
            " ---------------------------------------\n",
            "loss: 4.402045 [   64/ 1020]\n",
            "loss: 4.416265 [  384/ 1020]\n",
            "loss: 4.607880 [  704/ 1020]\n",
            "loss: 4.547318 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 5.1%, Avg loss: 4.479878 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 3 \n",
            " ---------------------------------------\n",
            "loss: 4.252069 [   64/ 1020]\n",
            "loss: 4.246429 [  384/ 1020]\n",
            "loss: 4.221443 [  704/ 1020]\n",
            "loss: 4.128718 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 13.5%, Avg loss: 4.137357 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 4 \n",
            " ---------------------------------------\n",
            "loss: 4.108691 [   64/ 1020]\n",
            "loss: 3.949729 [  384/ 1020]\n",
            "loss: 4.023866 [  704/ 1020]\n",
            "loss: 3.835631 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 16.3%, Avg loss: 3.974142 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 5 \n",
            " ---------------------------------------\n",
            "loss: 3.864544 [   64/ 1020]\n",
            "loss: 3.811500 [  384/ 1020]\n",
            "loss: 3.762614 [  704/ 1020]\n",
            "loss: 3.856857 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 18.6%, Avg loss: 3.814471 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 6 \n",
            " ---------------------------------------\n",
            "loss: 3.675716 [   64/ 1020]\n",
            "loss: 3.637097 [  384/ 1020]\n",
            "loss: 3.586799 [  704/ 1020]\n",
            "loss: 3.604867 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 21.6%, Avg loss: 3.731834 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 7 \n",
            " ---------------------------------------\n",
            "loss: 3.593051 [   64/ 1020]\n",
            "loss: 3.369143 [  384/ 1020]\n",
            "loss: 3.572776 [  704/ 1020]\n",
            "loss: 3.823921 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 22.3%, Avg loss: 3.652362 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 8 \n",
            " ---------------------------------------\n",
            "loss: 3.235264 [   64/ 1020]\n",
            "loss: 3.309270 [  384/ 1020]\n",
            "loss: 3.439929 [  704/ 1020]\n",
            "loss: 3.568911 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.0%, Avg loss: 3.525090 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 9 \n",
            " ---------------------------------------\n",
            "loss: 3.589358 [   64/ 1020]\n",
            "loss: 3.285751 [  384/ 1020]\n",
            "loss: 3.416803 [  704/ 1020]\n",
            "loss: 3.370682 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 27.2%, Avg loss: 3.486829 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 10 \n",
            " ---------------------------------------\n",
            "loss: 3.378600 [   64/ 1020]\n",
            "loss: 3.139425 [  384/ 1020]\n",
            "loss: 3.253881 [  704/ 1020]\n",
            "loss: 3.074002 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 29.6%, Avg loss: 3.411248 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 11 \n",
            " ---------------------------------------\n",
            "loss: 3.101991 [   64/ 1020]\n",
            "loss: 3.168171 [  384/ 1020]\n",
            "loss: 2.989272 [  704/ 1020]\n",
            "loss: 3.101980 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 30.3%, Avg loss: 3.366913 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 12 \n",
            " ---------------------------------------\n",
            "loss: 2.889223 [   64/ 1020]\n",
            "loss: 2.810533 [  384/ 1020]\n",
            "loss: 2.856138 [  704/ 1020]\n",
            "loss: 3.193141 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.4%, Avg loss: 3.319215 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 13 \n",
            " ---------------------------------------\n",
            "loss: 2.961153 [   64/ 1020]\n",
            "loss: 2.991462 [  384/ 1020]\n",
            "loss: 3.143442 [  704/ 1020]\n",
            "loss: 2.966626 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.5%, Avg loss: 3.248671 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 14 \n",
            " ---------------------------------------\n",
            "loss: 2.627430 [   64/ 1020]\n",
            "loss: 2.868256 [  384/ 1020]\n",
            "loss: 2.613973 [  704/ 1020]\n",
            "loss: 2.731969 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.7%, Avg loss: 3.226421 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 15 \n",
            " ---------------------------------------\n",
            "loss: 3.007468 [   64/ 1020]\n",
            "loss: 2.904823 [  384/ 1020]\n",
            "loss: 2.785487 [  704/ 1020]\n",
            "loss: 2.998325 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 35.3%, Avg loss: 3.186880 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 16 \n",
            " ---------------------------------------\n",
            "loss: 2.740575 [   64/ 1020]\n",
            "loss: 2.640576 [  384/ 1020]\n",
            "loss: 2.968008 [  704/ 1020]\n",
            "loss: 2.797640 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.0%, Avg loss: 3.119800 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 17 \n",
            " ---------------------------------------\n",
            "loss: 2.802844 [   64/ 1020]\n",
            "loss: 2.462413 [  384/ 1020]\n",
            "loss: 2.703204 [  704/ 1020]\n",
            "loss: 2.711182 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.7%, Avg loss: 3.110552 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 18 \n",
            " ---------------------------------------\n",
            "loss: 2.527138 [   64/ 1020]\n",
            "loss: 2.625044 [  384/ 1020]\n",
            "loss: 2.665587 [  704/ 1020]\n",
            "loss: 2.608546 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.1%, Avg loss: 3.074835 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 19 \n",
            " ---------------------------------------\n",
            "loss: 2.543864 [   64/ 1020]\n",
            "loss: 2.614759 [  384/ 1020]\n",
            "loss: 2.469976 [  704/ 1020]\n",
            "loss: 2.746033 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.5%, Avg loss: 3.008068 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 20 \n",
            " ---------------------------------------\n",
            "loss: 2.619766 [   64/ 1020]\n",
            "loss: 2.548251 [  384/ 1020]\n",
            "loss: 2.524727 [  704/ 1020]\n",
            "loss: 2.398134 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 39.3%, Avg loss: 2.989866 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 21 \n",
            " ---------------------------------------\n",
            "loss: 2.379024 [   64/ 1020]\n",
            "loss: 2.439496 [  384/ 1020]\n",
            "loss: 2.279126 [  704/ 1020]\n",
            "loss: 2.588718 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 38.7%, Avg loss: 2.962374 \n",
            "\n",
            "Epoch 22 \n",
            " ---------------------------------------\n",
            "loss: 2.345693 [   64/ 1020]\n",
            "loss: 2.179622 [  384/ 1020]\n",
            "loss: 2.217146 [  704/ 1020]\n",
            "loss: 2.635426 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 39.9%, Avg loss: 2.929596 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 23 \n",
            " ---------------------------------------\n",
            "loss: 2.201217 [   64/ 1020]\n",
            "loss: 2.254805 [  384/ 1020]\n",
            "loss: 2.235905 [  704/ 1020]\n",
            "loss: 2.485818 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 41.1%, Avg loss: 2.907408 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 24 \n",
            " ---------------------------------------\n",
            "loss: 2.185638 [   64/ 1020]\n",
            "loss: 2.418058 [  384/ 1020]\n",
            "loss: 2.052856 [  704/ 1020]\n",
            "loss: 2.457407 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 41.0%, Avg loss: 2.875616 \n",
            "\n",
            "Epoch 25 \n",
            " ---------------------------------------\n",
            "loss: 2.172547 [   64/ 1020]\n",
            "loss: 2.245521 [  384/ 1020]\n",
            "loss: 2.329170 [  704/ 1020]\n",
            "loss: 2.403855 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 43.1%, Avg loss: 2.836961 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 26 \n",
            " ---------------------------------------\n",
            "loss: 2.116032 [   64/ 1020]\n",
            "loss: 2.094571 [  384/ 1020]\n",
            "loss: 2.206456 [  704/ 1020]\n",
            "loss: 2.304062 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 42.9%, Avg loss: 2.818134 \n",
            "\n",
            "Epoch 27 \n",
            " ---------------------------------------\n",
            "loss: 1.987957 [   64/ 1020]\n",
            "loss: 2.048222 [  384/ 1020]\n",
            "loss: 2.250913 [  704/ 1020]\n",
            "loss: 2.173871 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 43.9%, Avg loss: 2.794941 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 28 \n",
            " ---------------------------------------\n",
            "loss: 2.196395 [   64/ 1020]\n",
            "loss: 2.105959 [  384/ 1020]\n",
            "loss: 2.241457 [  704/ 1020]\n",
            "loss: 2.229642 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 43.0%, Avg loss: 2.759854 \n",
            "\n",
            "Epoch 29 \n",
            " ---------------------------------------\n",
            "loss: 2.086814 [   64/ 1020]\n",
            "loss: 1.932307 [  384/ 1020]\n",
            "loss: 2.145154 [  704/ 1020]\n",
            "loss: 2.098034 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 43.5%, Avg loss: 2.759581 \n",
            "\n",
            "Epoch 30 \n",
            " ---------------------------------------\n",
            "loss: 1.962533 [   64/ 1020]\n",
            "loss: 2.088389 [  384/ 1020]\n",
            "loss: 1.749432 [  704/ 1020]\n",
            "loss: 1.968342 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 43.4%, Avg loss: 2.728311 \n",
            "\n",
            "Epoch 31 \n",
            " ---------------------------------------\n",
            "loss: 2.002033 [   64/ 1020]\n",
            "loss: 1.875396 [  384/ 1020]\n",
            "loss: 2.055235 [  704/ 1020]\n",
            "loss: 2.062527 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 45.2%, Avg loss: 2.724360 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 32 \n",
            " ---------------------------------------\n",
            "loss: 2.032210 [   64/ 1020]\n",
            "loss: 1.892988 [  384/ 1020]\n",
            "loss: 2.143466 [  704/ 1020]\n",
            "loss: 1.999696 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 43.6%, Avg loss: 2.731313 \n",
            "\n",
            "Epoch 33 \n",
            " ---------------------------------------\n",
            "loss: 1.750990 [   64/ 1020]\n",
            "loss: 2.026342 [  384/ 1020]\n",
            "loss: 1.926049 [  704/ 1020]\n",
            "loss: 2.040156 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 43.7%, Avg loss: 2.689294 \n",
            "\n",
            "Epoch 34 \n",
            " ---------------------------------------\n",
            "loss: 1.879849 [   64/ 1020]\n",
            "loss: 1.798676 [  384/ 1020]\n",
            "loss: 1.930333 [  704/ 1020]\n",
            "loss: 1.775983 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.6%, Avg loss: 2.681079 \n",
            "\n",
            "Epoch 35 \n",
            " ---------------------------------------\n",
            "loss: 1.896000 [   64/ 1020]\n",
            "loss: 1.878854 [  384/ 1020]\n",
            "loss: 1.651026 [  704/ 1020]\n",
            "loss: 1.857212 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 45.0%, Avg loss: 2.665406 \n",
            "\n",
            "Epoch 36 \n",
            " ---------------------------------------\n",
            "loss: 1.745171 [   64/ 1020]\n",
            "loss: 1.789255 [  384/ 1020]\n",
            "loss: 1.707654 [  704/ 1020]\n",
            "loss: 1.609280 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.9%, Avg loss: 2.663798 \n",
            "\n",
            "Epoch 37 \n",
            " ---------------------------------------\n",
            "loss: 1.760702 [   64/ 1020]\n",
            "loss: 1.757249 [  384/ 1020]\n",
            "loss: 1.911999 [  704/ 1020]\n",
            "loss: 1.761891 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 46.9%, Avg loss: 2.629552 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 38 \n",
            " ---------------------------------------\n",
            "loss: 1.653450 [   64/ 1020]\n",
            "loss: 1.763351 [  384/ 1020]\n",
            "loss: 1.607045 [  704/ 1020]\n",
            "loss: 1.830194 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 45.2%, Avg loss: 2.632450 \n",
            "\n",
            "Epoch 39 \n",
            " ---------------------------------------\n",
            "loss: 1.731512 [   64/ 1020]\n",
            "loss: 1.992289 [  384/ 1020]\n",
            "loss: 1.740722 [  704/ 1020]\n",
            "loss: 1.768225 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 46.5%, Avg loss: 2.631900 \n",
            "\n",
            "Epoch 40 \n",
            " ---------------------------------------\n",
            "loss: 1.560059 [   64/ 1020]\n",
            "loss: 1.632187 [  384/ 1020]\n",
            "loss: 1.654389 [  704/ 1020]\n",
            "loss: 1.700356 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.6%, Avg loss: 2.585876 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 41 \n",
            " ---------------------------------------\n",
            "loss: 1.510484 [   64/ 1020]\n",
            "loss: 1.675908 [  384/ 1020]\n",
            "loss: 1.565134 [  704/ 1020]\n",
            "loss: 1.639512 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 48.0%, Avg loss: 2.605071 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 42 \n",
            " ---------------------------------------\n",
            "loss: 1.588579 [   64/ 1020]\n",
            "loss: 1.662798 [  384/ 1020]\n",
            "loss: 1.646844 [  704/ 1020]\n",
            "loss: 1.672797 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 48.4%, Avg loss: 2.572127 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 43 \n",
            " ---------------------------------------\n",
            "loss: 1.576653 [   64/ 1020]\n",
            "loss: 1.599136 [  384/ 1020]\n",
            "loss: 1.642360 [  704/ 1020]\n",
            "loss: 1.564500 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 49.1%, Avg loss: 2.536391 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 44 \n",
            " ---------------------------------------\n",
            "loss: 1.500352 [   64/ 1020]\n",
            "loss: 1.356930 [  384/ 1020]\n",
            "loss: 1.455487 [  704/ 1020]\n",
            "loss: 1.504925 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.7%, Avg loss: 2.542981 \n",
            "\n",
            "Epoch 45 \n",
            " ---------------------------------------\n",
            "loss: 1.443493 [   64/ 1020]\n",
            "loss: 1.577359 [  384/ 1020]\n",
            "loss: 1.368222 [  704/ 1020]\n",
            "loss: 1.624805 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 49.4%, Avg loss: 2.546214 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 46 \n",
            " ---------------------------------------\n",
            "loss: 1.547010 [   64/ 1020]\n",
            "loss: 1.636170 [  384/ 1020]\n",
            "loss: 1.400860 [  704/ 1020]\n",
            "loss: 1.631278 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 49.5%, Avg loss: 2.508307 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 47 \n",
            " ---------------------------------------\n",
            "loss: 1.537235 [   64/ 1020]\n",
            "loss: 1.412385 [  384/ 1020]\n",
            "loss: 1.382235 [  704/ 1020]\n",
            "loss: 1.437185 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 50.4%, Avg loss: 2.529662 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 48 \n",
            " ---------------------------------------\n",
            "loss: 1.447886 [   64/ 1020]\n",
            "loss: 1.451585 [  384/ 1020]\n",
            "loss: 1.402960 [  704/ 1020]\n",
            "loss: 1.599024 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 50.3%, Avg loss: 2.512614 \n",
            "\n",
            "Epoch 49 \n",
            " ---------------------------------------\n",
            "loss: 1.524758 [   64/ 1020]\n",
            "loss: 1.470172 [  384/ 1020]\n",
            "loss: 1.487159 [  704/ 1020]\n",
            "loss: 1.239900 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 49.6%, Avg loss: 2.497127 \n",
            "\n",
            "Epoch 50 \n",
            " ---------------------------------------\n",
            "loss: 1.322380 [   64/ 1020]\n",
            "loss: 1.450483 [  384/ 1020]\n",
            "loss: 1.448580 [  704/ 1020]\n",
            "loss: 1.337834 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 49.0%, Avg loss: 2.516091 \n",
            "\n",
            "Epoch 51 \n",
            " ---------------------------------------\n",
            "loss: 1.355193 [   64/ 1020]\n",
            "loss: 1.343478 [  384/ 1020]\n",
            "loss: 1.372675 [  704/ 1020]\n",
            "loss: 1.552958 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 49.4%, Avg loss: 2.476174 \n",
            "\n",
            "Epoch 52 \n",
            " ---------------------------------------\n",
            "loss: 1.260006 [   64/ 1020]\n",
            "loss: 1.357987 [  384/ 1020]\n",
            "loss: 1.367131 [  704/ 1020]\n",
            "loss: 1.527293 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 48.2%, Avg loss: 2.506651 \n",
            "\n",
            "Epoch 53 \n",
            " ---------------------------------------\n",
            "loss: 1.366906 [   64/ 1020]\n",
            "loss: 1.417001 [  384/ 1020]\n",
            "loss: 1.315773 [  704/ 1020]\n",
            "loss: 1.308485 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 50.4%, Avg loss: 2.452733 \n",
            "\n",
            "Epoch 54 \n",
            " ---------------------------------------\n",
            "loss: 1.304791 [   64/ 1020]\n",
            "loss: 1.263943 [  384/ 1020]\n",
            "loss: 1.282981 [  704/ 1020]\n",
            "loss: 1.600228 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 51.5%, Avg loss: 2.420720 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 55 \n",
            " ---------------------------------------\n",
            "loss: 1.344074 [   64/ 1020]\n",
            "loss: 1.213328 [  384/ 1020]\n",
            "loss: 1.033480 [  704/ 1020]\n",
            "loss: 1.290425 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 51.6%, Avg loss: 2.452752 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 56 \n",
            " ---------------------------------------\n",
            "loss: 1.274744 [   64/ 1020]\n",
            "loss: 1.109882 [  384/ 1020]\n",
            "loss: 1.259769 [  704/ 1020]\n",
            "loss: 1.321934 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 51.2%, Avg loss: 2.443741 \n",
            "\n",
            "Epoch 57 \n",
            " ---------------------------------------\n",
            "loss: 1.178221 [   64/ 1020]\n",
            "loss: 1.298703 [  384/ 1020]\n",
            "loss: 1.184137 [  704/ 1020]\n",
            "loss: 1.233422 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 50.3%, Avg loss: 2.426435 \n",
            "\n",
            "Epoch 58 \n",
            " ---------------------------------------\n",
            "loss: 1.163949 [   64/ 1020]\n",
            "loss: 1.091006 [  384/ 1020]\n",
            "loss: 1.282261 [  704/ 1020]\n",
            "loss: 1.413524 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 50.8%, Avg loss: 2.414971 \n",
            "\n",
            "Epoch 59 \n",
            " ---------------------------------------\n",
            "loss: 1.279489 [   64/ 1020]\n",
            "loss: 1.185411 [  384/ 1020]\n",
            "loss: 1.161074 [  704/ 1020]\n",
            "loss: 1.350820 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 51.2%, Avg loss: 2.388198 \n",
            "\n",
            "Epoch 60 \n",
            " ---------------------------------------\n",
            "loss: 1.261742 [   64/ 1020]\n",
            "loss: 1.293536 [  384/ 1020]\n",
            "loss: 1.000858 [  704/ 1020]\n",
            "loss: 1.352773 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 51.5%, Avg loss: 2.393900 \n",
            "\n",
            "Epoch 61 \n",
            " ---------------------------------------\n",
            "loss: 1.090166 [   64/ 1020]\n",
            "loss: 1.054578 [  384/ 1020]\n",
            "loss: 1.283667 [  704/ 1020]\n",
            "loss: 1.137459 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 51.3%, Avg loss: 2.395347 \n",
            "\n",
            "Epoch 62 \n",
            " ---------------------------------------\n",
            "loss: 1.036320 [   64/ 1020]\n",
            "loss: 1.145813 [  384/ 1020]\n",
            "loss: 1.099856 [  704/ 1020]\n",
            "loss: 1.243799 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 49.8%, Avg loss: 2.368855 \n",
            "\n",
            "Epoch 63 \n",
            " ---------------------------------------\n",
            "loss: 1.025053 [   64/ 1020]\n",
            "loss: 1.068423 [  384/ 1020]\n",
            "loss: 1.119781 [  704/ 1020]\n",
            "loss: 1.201552 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 50.6%, Avg loss: 2.382489 \n",
            "\n",
            "Epoch 64 \n",
            " ---------------------------------------\n",
            "loss: 1.171193 [   64/ 1020]\n",
            "loss: 1.103979 [  384/ 1020]\n",
            "loss: 1.184092 [  704/ 1020]\n",
            "loss: 1.109271 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 51.6%, Avg loss: 2.387599 \n",
            "\n",
            "Epoch 65 \n",
            " ---------------------------------------\n",
            "loss: 1.253392 [   64/ 1020]\n",
            "loss: 1.036347 [  384/ 1020]\n",
            "loss: 1.015071 [  704/ 1020]\n",
            "loss: 1.302853 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.5%, Avg loss: 2.368609 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 66 \n",
            " ---------------------------------------\n",
            "loss: 1.013998 [   64/ 1020]\n",
            "loss: 1.011605 [  384/ 1020]\n",
            "loss: 0.981092 [  704/ 1020]\n",
            "loss: 1.135238 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.8%, Avg loss: 2.351796 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 67 \n",
            " ---------------------------------------\n",
            "loss: 0.906856 [   64/ 1020]\n",
            "loss: 1.011135 [  384/ 1020]\n",
            "loss: 1.035300 [  704/ 1020]\n",
            "loss: 1.149687 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.9%, Avg loss: 2.366999 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 68 \n",
            " ---------------------------------------\n",
            "loss: 0.945803 [   64/ 1020]\n",
            "loss: 1.062977 [  384/ 1020]\n",
            "loss: 1.007237 [  704/ 1020]\n",
            "loss: 1.105144 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.1%, Avg loss: 2.335917 \n",
            "\n",
            "Epoch 69 \n",
            " ---------------------------------------\n",
            "loss: 1.065016 [   64/ 1020]\n",
            "loss: 0.989564 [  384/ 1020]\n",
            "loss: 0.863494 [  704/ 1020]\n",
            "loss: 1.237030 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.1%, Avg loss: 2.363678 \n",
            "\n",
            "Epoch 70 \n",
            " ---------------------------------------\n",
            "loss: 1.062992 [   64/ 1020]\n",
            "loss: 0.904131 [  384/ 1020]\n",
            "loss: 0.952493 [  704/ 1020]\n",
            "loss: 1.149444 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.0%, Avg loss: 2.330483 \n",
            "\n",
            "Epoch 71 \n",
            " ---------------------------------------\n",
            "loss: 0.984449 [   64/ 1020]\n",
            "loss: 1.047868 [  384/ 1020]\n",
            "loss: 1.097297 [  704/ 1020]\n",
            "loss: 1.070803 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.4%, Avg loss: 2.303235 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 72 \n",
            " ---------------------------------------\n",
            "loss: 1.008552 [   64/ 1020]\n",
            "loss: 1.030622 [  384/ 1020]\n",
            "loss: 0.872740 [  704/ 1020]\n",
            "loss: 1.020945 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 51.5%, Avg loss: 2.340349 \n",
            "\n",
            "Epoch 73 \n",
            " ---------------------------------------\n",
            "loss: 1.060707 [   64/ 1020]\n",
            "loss: 0.935748 [  384/ 1020]\n",
            "loss: 0.943654 [  704/ 1020]\n",
            "loss: 0.940322 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.0%, Avg loss: 2.338842 \n",
            "\n",
            "Epoch 74 \n",
            " ---------------------------------------\n",
            "loss: 0.922942 [   64/ 1020]\n",
            "loss: 0.902518 [  384/ 1020]\n",
            "loss: 0.926232 [  704/ 1020]\n",
            "loss: 0.986079 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 51.7%, Avg loss: 2.339054 \n",
            "\n",
            "Epoch 75 \n",
            " ---------------------------------------\n",
            "loss: 0.900909 [   64/ 1020]\n",
            "loss: 0.961419 [  384/ 1020]\n",
            "loss: 0.895130 [  704/ 1020]\n",
            "loss: 1.081038 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.3%, Avg loss: 2.328854 \n",
            "\n",
            "Epoch 76 \n",
            " ---------------------------------------\n",
            "loss: 0.820355 [   64/ 1020]\n",
            "loss: 0.843867 [  384/ 1020]\n",
            "loss: 0.936882 [  704/ 1020]\n",
            "loss: 0.987203 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.3%, Avg loss: 2.305144 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 77 \n",
            " ---------------------------------------\n",
            "loss: 0.790893 [   64/ 1020]\n",
            "loss: 0.910907 [  384/ 1020]\n",
            "loss: 0.921195 [  704/ 1020]\n",
            "loss: 0.856440 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.5%, Avg loss: 2.285396 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 78 \n",
            " ---------------------------------------\n",
            "loss: 0.900252 [   64/ 1020]\n",
            "loss: 0.802985 [  384/ 1020]\n",
            "loss: 0.831428 [  704/ 1020]\n",
            "loss: 0.998099 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.5%, Avg loss: 2.299323 \n",
            "\n",
            "Epoch 79 \n",
            " ---------------------------------------\n",
            "loss: 0.881240 [   64/ 1020]\n",
            "loss: 0.800379 [  384/ 1020]\n",
            "loss: 0.817220 [  704/ 1020]\n",
            "loss: 1.030694 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.6%, Avg loss: 2.272965 \n",
            "\n",
            "Epoch 80 \n",
            " ---------------------------------------\n",
            "loss: 0.847752 [   64/ 1020]\n",
            "loss: 0.822901 [  384/ 1020]\n",
            "loss: 0.912260 [  704/ 1020]\n",
            "loss: 0.802647 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 52.6%, Avg loss: 2.287323 \n",
            "\n",
            "Epoch 81 \n",
            " ---------------------------------------\n",
            "loss: 0.774506 [   64/ 1020]\n",
            "loss: 0.904785 [  384/ 1020]\n",
            "loss: 0.904832 [  704/ 1020]\n",
            "loss: 0.748397 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.4%, Avg loss: 2.278916 \n",
            "\n",
            "Epoch 82 \n",
            " ---------------------------------------\n",
            "loss: 0.883880 [   64/ 1020]\n",
            "loss: 0.889813 [  384/ 1020]\n",
            "loss: 0.943393 [  704/ 1020]\n",
            "loss: 0.847034 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.8%, Avg loss: 2.270355 \n",
            "\n",
            "Epoch 83 \n",
            " ---------------------------------------\n",
            "loss: 0.858350 [   64/ 1020]\n",
            "loss: 0.966311 [  384/ 1020]\n",
            "loss: 0.870038 [  704/ 1020]\n",
            "loss: 0.866406 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.6%, Avg loss: 2.271196 \n",
            "\n",
            "Epoch 84 \n",
            " ---------------------------------------\n",
            "loss: 0.733221 [   64/ 1020]\n",
            "loss: 0.876358 [  384/ 1020]\n",
            "loss: 0.659760 [  704/ 1020]\n",
            "loss: 0.891183 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.1%, Avg loss: 2.236669 \n",
            "\n",
            "Epoch 85 \n",
            " ---------------------------------------\n",
            "loss: 0.834023 [   64/ 1020]\n",
            "loss: 0.878475 [  384/ 1020]\n",
            "loss: 0.767867 [  704/ 1020]\n",
            "loss: 0.757124 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 54.5%, Avg loss: 2.267555 \n",
            "\n",
            "Epoch 86 \n",
            " ---------------------------------------\n",
            "loss: 0.820989 [   64/ 1020]\n",
            "loss: 0.741358 [  384/ 1020]\n",
            "loss: 0.874899 [  704/ 1020]\n",
            "loss: 0.832957 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.4%, Avg loss: 2.259278 \n",
            "\n",
            "Epoch 87 \n",
            " ---------------------------------------\n",
            "loss: 0.795174 [   64/ 1020]\n",
            "loss: 0.736765 [  384/ 1020]\n",
            "loss: 0.821412 [  704/ 1020]\n",
            "loss: 0.787395 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.0%, Avg loss: 2.265197 \n",
            "\n",
            "Epoch 88 \n",
            " ---------------------------------------\n",
            "loss: 0.806331 [   64/ 1020]\n",
            "loss: 0.787808 [  384/ 1020]\n",
            "loss: 0.804372 [  704/ 1020]\n",
            "loss: 0.891289 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 53.1%, Avg loss: 2.278399 \n",
            "\n",
            "Stopping early\n",
            "Testing -----------------------\n",
            "Test Error: \n",
            " Accuracy: 50.3%, Avg loss: 2.452589 \n",
            "\n",
            "Done!!!!\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "\n",
        "best_accuracy = 0\n",
        "patience = 10\n",
        "triggers = 0\n",
        "\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1} \\n ---------------------------------------\")\n",
        "\n",
        "  \"\"\"#train on original data\n",
        "  train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\"\"\"\n",
        "\n",
        "  #train on augmented data\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "\n",
        "  #testing on evaluation data\n",
        "  accuracy, test_loss = test(val_dataloader, model, loss_fn)\n",
        "\n",
        "  scheduler.step(test_loss)\n",
        "\n",
        "  if accuracy > best_accuracy:\n",
        "    best_accuracy = accuracy\n",
        "    triggers = 0\n",
        "    torch.save(model.state_dict(), \"model.pt\")\n",
        "    print(\"Saved model at current state\")\n",
        "  else:\n",
        "    triggers += 1\n",
        "\n",
        "  if triggers > patience:\n",
        "    print(\"Stopping early\")\n",
        "    break\n",
        "\n",
        "print(\"Testing -----------------------\")\n",
        "model.load_state_dict(torch.load(\"model.pt\"))\n",
        "model.eval()\n",
        "test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!!!!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPYDTMCPCxVFeQpE0LQKXk1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}