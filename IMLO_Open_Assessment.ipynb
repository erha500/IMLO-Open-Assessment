{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erha500/IMLO-Open-Assessment/blob/main/IMLO_Open_Assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MGJhK0Wy6U2-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as T\n",
        "from torchvision.transforms import v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1FLWsWbK-ylG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4247f87-5971-4e43-bf32-4438e8c4f17f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\erhan\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_transform_augment = v2.Compose([\n",
        "    v2.Resize([224,224]),\n",
        "    #v2.RandomPerspective(),\n",
        "    v2.RandomHorizontalFlip(0.5),\n",
        "    v2.RandomRotation(20),\n",
        "    #v2.RandomVerticalFlip(0.5)\n",
        "    #v2.RandomAutocontrast(),\n",
        "    #v2.GaussianBlur(kernel_size=3),\n",
        "    v2.ToTensor(),\n",
        "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_transform = v2.Compose([\n",
        "  v2.Resize([224,224]),\n",
        "  v2.ToTensor(),\n",
        "  v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "test_transform = v2.Compose([\n",
        "  v2.Resize([224,224]),\n",
        "  v2.ToTensor(),\n",
        "  v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWVmTrcs9QGM"
      },
      "source": [
        "Downloading Flowers102 dataset from datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2AG1ERmI9WXU"
      },
      "outputs": [],
      "source": [
        "training_data_augment = datasets.Flowers102(root=\"dataset\", split=\"train\", transform=train_transform_augment, download=True)\n",
        "\n",
        "training_data = datasets.Flowers102(root=\"dataset\", split=\"train\", transform=train_transform, download=True)\n",
        "\n",
        "val_data = datasets.Flowers102(root=\"dataset\", split=\"val\", transform=test_transform, download=True)\n",
        "\n",
        "test_data = datasets.Flowers102(root=\"dataset\", split=\"test\", transform=test_transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EiOOyavq-T-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "872905de-7d03-4167-b460-c0ced6a70e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 3, 224, 224])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "#Create data loaders\n",
        "train_dataloader = DataLoader(training_data_augment, batch_size = batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "  print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3fL6F9TLEdDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49188c70-bb9d-4a5f-db36-8a6814cc5d6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): ReLU()\n",
            "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU()\n",
            "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU()\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU()\n",
            "    (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (18): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (20): ReLU()\n",
            "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (22): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (23): Flatten(start_dim=1, end_dim=-1)\n",
            "    (24): Linear(in_features=6272, out_features=1024, bias=True)\n",
            "    (25): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU()\n",
            "    (27): Dropout(p=0.2, inplace=False)\n",
            "    (28): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (29): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (30): ReLU()\n",
            "    (31): Dropout(p=0.2, inplace=False)\n",
            "    (32): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (33): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (34): ReLU()\n",
            "    (35): Dropout(p=0.2, inplace=False)\n",
            "    (36): Linear(in_features=256, out_features=102, bias=True)\n",
            "    (37): BatchNorm1d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (38): ReLU()\n",
            "    (39): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "#Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.model = nn.Sequential(\n",
        "      #Convolutional layers\n",
        "      nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(32),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(32,32, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(32),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(64,64, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "      nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "      nn.Conv2d(128,128, kernel_size=3, padding=1),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, stride=2),\n",
        "      nn.AvgPool2d(2, stride=2),\n",
        "\n",
        "      #Linear layers\n",
        "      nn.Flatten(),\n",
        "\n",
        "      nn.Linear(128 * 7 * 7, 1024),\n",
        "      nn.BatchNorm1d(1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.2),\n",
        "\n",
        "      nn.Linear(1024, 512),\n",
        "      nn.BatchNorm1d(512),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.2),\n",
        "\n",
        "      nn.Linear(512,256),\n",
        "      nn.BatchNorm1d(256),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.2),\n",
        "\n",
        "      nn.Linear(256,102),\n",
        "      nn.BatchNorm1d(102),\n",
        "      nn.ReLU(),\n",
        "\n",
        "      nn.LogSoftmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9IvJsfvwE0VG"
      },
      "outputs": [],
      "source": [
        "#loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn = nn.NLLLoss()\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.005) #weight decay is L2 regularisation\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=5, factor=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "o4bMoWUAE1kO"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    #Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 5 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "y4Mf49itE3A-"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct) :>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    accuracy = 100 * correct\n",
        "    return accuracy, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Xr7VD7E3E5y1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c312a8da-6e18-4264-8b3d-4ba158672888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            " ---------------------------------------\n",
            "loss: 4.891087 [   64/ 1020]\n",
            "loss: 4.749405 [  384/ 1020]\n",
            "loss: 4.654094 [  704/ 1020]\n",
            "loss: 4.552983 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 1.0%, Avg loss: 4.637045 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 2 \n",
            " ---------------------------------------\n",
            "loss: 4.345731 [   64/ 1020]\n",
            "loss: 4.289770 [  384/ 1020]\n",
            "loss: 4.285378 [  704/ 1020]\n",
            "loss: 4.294042 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 2.8%, Avg loss: 4.551537 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 3 \n",
            " ---------------------------------------\n",
            "loss: 3.954724 [   64/ 1020]\n",
            "loss: 4.062054 [  384/ 1020]\n",
            "loss: 4.094104 [  704/ 1020]\n",
            "loss: 3.712765 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 14.3%, Avg loss: 4.075199 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 4 \n",
            " ---------------------------------------\n",
            "loss: 3.639166 [   64/ 1020]\n",
            "loss: 3.707895 [  384/ 1020]\n",
            "loss: 3.719373 [  704/ 1020]\n",
            "loss: 3.768642 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 21.2%, Avg loss: 3.831308 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 5 \n",
            " ---------------------------------------\n",
            "loss: 3.471431 [   64/ 1020]\n",
            "loss: 3.396264 [  384/ 1020]\n",
            "loss: 3.441177 [  704/ 1020]\n",
            "loss: 3.361188 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 24.2%, Avg loss: 3.684479 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 6 \n",
            " ---------------------------------------\n",
            "loss: 3.310799 [   64/ 1020]\n",
            "loss: 3.432244 [  384/ 1020]\n",
            "loss: 3.260590 [  704/ 1020]\n",
            "loss: 3.360198 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 28.5%, Avg loss: 3.569966 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 7 \n",
            " ---------------------------------------\n",
            "loss: 3.167834 [   64/ 1020]\n",
            "loss: 3.162289 [  384/ 1020]\n",
            "loss: 3.014990 [  704/ 1020]\n",
            "loss: 3.013248 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.5%, Avg loss: 3.452301 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 8 \n",
            " ---------------------------------------\n",
            "loss: 3.031888 [   64/ 1020]\n",
            "loss: 3.012973 [  384/ 1020]\n",
            "loss: 3.127848 [  704/ 1020]\n",
            "loss: 2.913795 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 31.7%, Avg loss: 3.372714 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 9 \n",
            " ---------------------------------------\n",
            "loss: 2.867140 [   64/ 1020]\n",
            "loss: 2.972804 [  384/ 1020]\n",
            "loss: 2.717116 [  704/ 1020]\n",
            "loss: 2.790005 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 32.9%, Avg loss: 3.328242 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 10 \n",
            " ---------------------------------------\n",
            "loss: 2.907522 [   64/ 1020]\n",
            "loss: 2.644774 [  384/ 1020]\n",
            "loss: 2.783497 [  704/ 1020]\n",
            "loss: 2.619582 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 34.2%, Avg loss: 3.274737 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 11 \n",
            " ---------------------------------------\n",
            "loss: 2.590609 [   64/ 1020]\n",
            "loss: 2.648932 [  384/ 1020]\n",
            "loss: 2.562197 [  704/ 1020]\n",
            "loss: 2.736228 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.0%, Avg loss: 3.229584 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 12 \n",
            " ---------------------------------------\n",
            "loss: 2.557042 [   64/ 1020]\n",
            "loss: 2.597831 [  384/ 1020]\n",
            "loss: 2.534130 [  704/ 1020]\n",
            "loss: 2.584846 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 36.9%, Avg loss: 3.187591 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 13 \n",
            " ---------------------------------------\n",
            "loss: 2.485846 [   64/ 1020]\n",
            "loss: 2.446386 [  384/ 1020]\n",
            "loss: 2.397636 [  704/ 1020]\n",
            "loss: 2.395001 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 37.1%, Avg loss: 3.156312 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 14 \n",
            " ---------------------------------------\n",
            "loss: 2.263503 [   64/ 1020]\n",
            "loss: 2.241831 [  384/ 1020]\n",
            "loss: 2.294139 [  704/ 1020]\n",
            "loss: 2.181752 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 40.3%, Avg loss: 3.133107 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 15 \n",
            " ---------------------------------------\n",
            "loss: 2.424496 [   64/ 1020]\n",
            "loss: 2.202260 [  384/ 1020]\n",
            "loss: 2.431330 [  704/ 1020]\n",
            "loss: 2.235364 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 39.7%, Avg loss: 3.107533 \n",
            "\n",
            "Epoch 16 \n",
            " ---------------------------------------\n",
            "loss: 2.205039 [   64/ 1020]\n",
            "loss: 2.208184 [  384/ 1020]\n",
            "loss: 1.992140 [  704/ 1020]\n",
            "loss: 2.157379 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 39.7%, Avg loss: 3.070754 \n",
            "\n",
            "Epoch 17 \n",
            " ---------------------------------------\n",
            "loss: 2.167411 [   64/ 1020]\n",
            "loss: 2.121500 [  384/ 1020]\n",
            "loss: 2.055272 [  704/ 1020]\n",
            "loss: 2.438159 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 40.3%, Avg loss: 3.053287 \n",
            "\n",
            "Epoch 18 \n",
            " ---------------------------------------\n",
            "loss: 2.064687 [   64/ 1020]\n",
            "loss: 2.177758 [  384/ 1020]\n",
            "loss: 1.925676 [  704/ 1020]\n",
            "loss: 2.032259 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 39.2%, Avg loss: 3.045599 \n",
            "\n",
            "Epoch 19 \n",
            " ---------------------------------------\n",
            "loss: 1.911827 [   64/ 1020]\n",
            "loss: 1.974620 [  384/ 1020]\n",
            "loss: 2.117472 [  704/ 1020]\n",
            "loss: 2.052789 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 40.9%, Avg loss: 3.004561 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 20 \n",
            " ---------------------------------------\n",
            "loss: 1.871990 [   64/ 1020]\n",
            "loss: 1.922039 [  384/ 1020]\n",
            "loss: 1.999745 [  704/ 1020]\n",
            "loss: 1.857301 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 2.994217 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 21 \n",
            " ---------------------------------------\n",
            "loss: 1.773723 [   64/ 1020]\n",
            "loss: 1.924423 [  384/ 1020]\n",
            "loss: 1.937346 [  704/ 1020]\n",
            "loss: 1.855804 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 2.950917 \n",
            "\n",
            "Epoch 22 \n",
            " ---------------------------------------\n",
            "loss: 1.733294 [   64/ 1020]\n",
            "loss: 1.823572 [  384/ 1020]\n",
            "loss: 1.769292 [  704/ 1020]\n",
            "loss: 1.835035 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 42.6%, Avg loss: 2.950313 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 23 \n",
            " ---------------------------------------\n",
            "loss: 1.669276 [   64/ 1020]\n",
            "loss: 1.745319 [  384/ 1020]\n",
            "loss: 1.889679 [  704/ 1020]\n",
            "loss: 1.936314 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 42.2%, Avg loss: 2.967717 \n",
            "\n",
            "Epoch 24 \n",
            " ---------------------------------------\n",
            "loss: 1.498633 [   64/ 1020]\n",
            "loss: 1.577297 [  384/ 1020]\n",
            "loss: 1.592485 [  704/ 1020]\n",
            "loss: 1.754657 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 43.2%, Avg loss: 2.914215 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 25 \n",
            " ---------------------------------------\n",
            "loss: 1.683557 [   64/ 1020]\n",
            "loss: 1.757287 [  384/ 1020]\n",
            "loss: 1.624275 [  704/ 1020]\n",
            "loss: 1.579191 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 42.8%, Avg loss: 2.908744 \n",
            "\n",
            "Epoch 26 \n",
            " ---------------------------------------\n",
            "loss: 1.628669 [   64/ 1020]\n",
            "loss: 1.771233 [  384/ 1020]\n",
            "loss: 1.518949 [  704/ 1020]\n",
            "loss: 1.706707 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 42.9%, Avg loss: 2.917711 \n",
            "\n",
            "Epoch 27 \n",
            " ---------------------------------------\n",
            "loss: 1.458966 [   64/ 1020]\n",
            "loss: 1.579366 [  384/ 1020]\n",
            "loss: 1.597417 [  704/ 1020]\n",
            "loss: 1.445158 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 42.6%, Avg loss: 2.885813 \n",
            "\n",
            "Epoch 28 \n",
            " ---------------------------------------\n",
            "loss: 1.398992 [   64/ 1020]\n",
            "loss: 1.495121 [  384/ 1020]\n",
            "loss: 1.397970 [  704/ 1020]\n",
            "loss: 1.651483 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.3%, Avg loss: 2.854271 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 29 \n",
            " ---------------------------------------\n",
            "loss: 1.311045 [   64/ 1020]\n",
            "loss: 1.238549 [  384/ 1020]\n",
            "loss: 1.496593 [  704/ 1020]\n",
            "loss: 1.447259 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.2%, Avg loss: 2.892927 \n",
            "\n",
            "Epoch 30 \n",
            " ---------------------------------------\n",
            "loss: 1.539548 [   64/ 1020]\n",
            "loss: 1.314618 [  384/ 1020]\n",
            "loss: 1.506085 [  704/ 1020]\n",
            "loss: 1.424821 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 43.2%, Avg loss: 2.880439 \n",
            "\n",
            "Epoch 31 \n",
            " ---------------------------------------\n",
            "loss: 1.351440 [   64/ 1020]\n",
            "loss: 1.329909 [  384/ 1020]\n",
            "loss: 1.468726 [  704/ 1020]\n",
            "loss: 1.610762 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 43.2%, Avg loss: 2.856264 \n",
            "\n",
            "Epoch 32 \n",
            " ---------------------------------------\n",
            "loss: 1.362975 [   64/ 1020]\n",
            "loss: 1.378829 [  384/ 1020]\n",
            "loss: 1.284340 [  704/ 1020]\n",
            "loss: 1.361905 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.3%, Avg loss: 2.819041 \n",
            "\n",
            "Epoch 33 \n",
            " ---------------------------------------\n",
            "loss: 1.184821 [   64/ 1020]\n",
            "loss: 1.449908 [  384/ 1020]\n",
            "loss: 1.295066 [  704/ 1020]\n",
            "loss: 1.309576 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.9%, Avg loss: 2.847564 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 34 \n",
            " ---------------------------------------\n",
            "loss: 1.306466 [   64/ 1020]\n",
            "loss: 1.203949 [  384/ 1020]\n",
            "loss: 1.229854 [  704/ 1020]\n",
            "loss: 1.353405 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 45.5%, Avg loss: 2.818067 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 35 \n",
            " ---------------------------------------\n",
            "loss: 1.349098 [   64/ 1020]\n",
            "loss: 1.142653 [  384/ 1020]\n",
            "loss: 1.206083 [  704/ 1020]\n",
            "loss: 1.370738 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 45.6%, Avg loss: 2.790291 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 36 \n",
            " ---------------------------------------\n",
            "loss: 1.099345 [   64/ 1020]\n",
            "loss: 1.316143 [  384/ 1020]\n",
            "loss: 1.288183 [  704/ 1020]\n",
            "loss: 1.415176 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 46.3%, Avg loss: 2.790641 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 37 \n",
            " ---------------------------------------\n",
            "loss: 1.227125 [   64/ 1020]\n",
            "loss: 1.250335 [  384/ 1020]\n",
            "loss: 1.106921 [  704/ 1020]\n",
            "loss: 1.222296 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 44.7%, Avg loss: 2.824450 \n",
            "\n",
            "Epoch 38 \n",
            " ---------------------------------------\n",
            "loss: 1.140880 [   64/ 1020]\n",
            "loss: 1.248327 [  384/ 1020]\n",
            "loss: 1.136664 [  704/ 1020]\n",
            "loss: 1.277274 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 46.4%, Avg loss: 2.768268 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 39 \n",
            " ---------------------------------------\n",
            "loss: 1.099548 [   64/ 1020]\n",
            "loss: 1.088250 [  384/ 1020]\n",
            "loss: 1.229979 [  704/ 1020]\n",
            "loss: 1.125090 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 45.1%, Avg loss: 2.776871 \n",
            "\n",
            "Epoch 40 \n",
            " ---------------------------------------\n",
            "loss: 1.094603 [   64/ 1020]\n",
            "loss: 1.126527 [  384/ 1020]\n",
            "loss: 0.931972 [  704/ 1020]\n",
            "loss: 1.117356 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.3%, Avg loss: 2.773811 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 41 \n",
            " ---------------------------------------\n",
            "loss: 0.997364 [   64/ 1020]\n",
            "loss: 1.046621 [  384/ 1020]\n",
            "loss: 1.148098 [  704/ 1020]\n",
            "loss: 1.224213 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 46.9%, Avg loss: 2.762396 \n",
            "\n",
            "Epoch 42 \n",
            " ---------------------------------------\n",
            "loss: 1.055797 [   64/ 1020]\n",
            "loss: 0.965470 [  384/ 1020]\n",
            "loss: 1.043472 [  704/ 1020]\n",
            "loss: 1.060110 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 46.1%, Avg loss: 2.769281 \n",
            "\n",
            "Epoch 43 \n",
            " ---------------------------------------\n",
            "loss: 1.064791 [   64/ 1020]\n",
            "loss: 1.150985 [  384/ 1020]\n",
            "loss: 1.144592 [  704/ 1020]\n",
            "loss: 1.073618 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 46.2%, Avg loss: 2.735868 \n",
            "\n",
            "Epoch 44 \n",
            " ---------------------------------------\n",
            "loss: 1.003796 [   64/ 1020]\n",
            "loss: 1.138192 [  384/ 1020]\n",
            "loss: 1.088820 [  704/ 1020]\n",
            "loss: 1.025755 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.5%, Avg loss: 2.733844 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 45 \n",
            " ---------------------------------------\n",
            "loss: 0.991376 [   64/ 1020]\n",
            "loss: 0.952228 [  384/ 1020]\n",
            "loss: 1.033471 [  704/ 1020]\n",
            "loss: 1.098118 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.5%, Avg loss: 2.765796 \n",
            "\n",
            "Epoch 46 \n",
            " ---------------------------------------\n",
            "loss: 0.956128 [   64/ 1020]\n",
            "loss: 0.995011 [  384/ 1020]\n",
            "loss: 0.861619 [  704/ 1020]\n",
            "loss: 1.091085 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 46.4%, Avg loss: 2.718700 \n",
            "\n",
            "Epoch 47 \n",
            " ---------------------------------------\n",
            "loss: 0.964914 [   64/ 1020]\n",
            "loss: 0.906213 [  384/ 1020]\n",
            "loss: 0.998885 [  704/ 1020]\n",
            "loss: 0.997027 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.6%, Avg loss: 2.748045 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 48 \n",
            " ---------------------------------------\n",
            "loss: 1.018384 [   64/ 1020]\n",
            "loss: 0.955259 [  384/ 1020]\n",
            "loss: 0.862485 [  704/ 1020]\n",
            "loss: 0.859930 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 48.3%, Avg loss: 2.713068 \n",
            "\n",
            "Saved model at current state\n",
            "Epoch 49 \n",
            " ---------------------------------------\n",
            "loss: 1.031688 [   64/ 1020]\n",
            "loss: 0.947118 [  384/ 1020]\n",
            "loss: 0.720858 [  704/ 1020]\n",
            "loss: 0.914296 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 45.7%, Avg loss: 2.728079 \n",
            "\n",
            "Epoch 50 \n",
            " ---------------------------------------\n",
            "loss: 0.932988 [   64/ 1020]\n",
            "loss: 0.868350 [  384/ 1020]\n",
            "loss: 0.982319 [  704/ 1020]\n",
            "loss: 0.898777 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 46.8%, Avg loss: 2.735602 \n",
            "\n",
            "Epoch 51 \n",
            " ---------------------------------------\n",
            "loss: 0.886611 [   64/ 1020]\n",
            "loss: 0.991413 [  384/ 1020]\n",
            "loss: 0.834308 [  704/ 1020]\n",
            "loss: 0.892242 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 48.0%, Avg loss: 2.713812 \n",
            "\n",
            "Epoch 52 \n",
            " ---------------------------------------\n",
            "loss: 0.845135 [   64/ 1020]\n",
            "loss: 0.844562 [  384/ 1020]\n",
            "loss: 0.891528 [  704/ 1020]\n",
            "loss: 0.987789 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.6%, Avg loss: 2.720609 \n",
            "\n",
            "Epoch 53 \n",
            " ---------------------------------------\n",
            "loss: 0.749662 [   64/ 1020]\n",
            "loss: 0.908063 [  384/ 1020]\n",
            "loss: 0.789419 [  704/ 1020]\n",
            "loss: 1.024612 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.7%, Avg loss: 2.719569 \n",
            "\n",
            "Epoch 54 \n",
            " ---------------------------------------\n",
            "loss: 0.773432 [   64/ 1020]\n",
            "loss: 0.748863 [  384/ 1020]\n",
            "loss: 0.776347 [  704/ 1020]\n",
            "loss: 0.871510 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.5%, Avg loss: 2.676236 \n",
            "\n",
            "Epoch 55 \n",
            " ---------------------------------------\n",
            "loss: 0.776707 [   64/ 1020]\n",
            "loss: 0.853430 [  384/ 1020]\n",
            "loss: 0.737836 [  704/ 1020]\n",
            "loss: 0.873142 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.3%, Avg loss: 2.705192 \n",
            "\n",
            "Epoch 56 \n",
            " ---------------------------------------\n",
            "loss: 0.837001 [   64/ 1020]\n",
            "loss: 0.787840 [  384/ 1020]\n",
            "loss: 0.960191 [  704/ 1020]\n",
            "loss: 0.990315 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 48.2%, Avg loss: 2.690704 \n",
            "\n",
            "Epoch 57 \n",
            " ---------------------------------------\n",
            "loss: 0.763259 [   64/ 1020]\n",
            "loss: 0.784010 [  384/ 1020]\n",
            "loss: 0.747269 [  704/ 1020]\n",
            "loss: 0.874256 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.8%, Avg loss: 2.687648 \n",
            "\n",
            "Epoch 58 \n",
            " ---------------------------------------\n",
            "loss: 0.861058 [   64/ 1020]\n",
            "loss: 0.744919 [  384/ 1020]\n",
            "loss: 0.736640 [  704/ 1020]\n",
            "loss: 0.892021 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.6%, Avg loss: 2.694145 \n",
            "\n",
            "Epoch 59 \n",
            " ---------------------------------------\n",
            "loss: 0.810485 [   64/ 1020]\n",
            "loss: 0.639697 [  384/ 1020]\n",
            "loss: 0.694503 [  704/ 1020]\n",
            "loss: 0.799509 [  960/ 1020]\n",
            "Test Error: \n",
            " Accuracy: 47.7%, Avg loss: 2.685829 \n",
            "\n",
            "Stopping early\n",
            "Testing -----------------------\n",
            "Test Error: \n",
            " Accuracy: 44.6%, Avg loss: 2.837674 \n",
            "\n",
            "Done!!!!\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "\n",
        "best_accuracy = 0\n",
        "patience = 10\n",
        "triggers = 0\n",
        "\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1} \\n ---------------------------------------\")\n",
        "\n",
        "  \"\"\"#train on original data\n",
        "  train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\"\"\"\n",
        "\n",
        "  #train on augmented data\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "\n",
        "  #testing on evaluation data\n",
        "  accuracy, test_loss = test(val_dataloader, model, loss_fn)\n",
        "\n",
        "  scheduler.step(test_loss)\n",
        "\n",
        "  if accuracy > best_accuracy:\n",
        "    best_accuracy = accuracy\n",
        "    triggers = 0\n",
        "    torch.save(model.state_dict(), \"model.pt\")\n",
        "    print(\"Saved model at current state\")\n",
        "  else:\n",
        "    triggers += 1\n",
        "\n",
        "  if triggers > patience:\n",
        "    print(\"Stopping early\")\n",
        "    break\n",
        "\n",
        "print(\"Testing -----------------------\")\n",
        "model.load_state_dict(torch.load(\"model.pt\"))\n",
        "model.eval()\n",
        "test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!!!!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMqFgk8IezHtcmkeJ9pfD9H",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}